{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2130e5f8-9d57-42ab-9599-9955534dab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14508a86-4a9f-4263-9f3d-6d69b8b57264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79857730-659d-42c0-891a-cef0b8ab0092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'alpha': 0.0001,\n",
       " 'batch_size': 'auto',\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'early_stopping': False,\n",
       " 'epsilon': 1e-08,\n",
       " 'hidden_layer_sizes': (100,),\n",
       " 'learning_rate': 'constant',\n",
       " 'learning_rate_init': 0.001,\n",
       " 'max_fun': 15000,\n",
       " 'max_iter': 200,\n",
       " 'momentum': 0.9,\n",
       " 'n_iter_no_change': 10,\n",
       " 'nesterovs_momentum': True,\n",
       " 'power_t': 0.5,\n",
       " 'random_state': None,\n",
       " 'shuffle': True,\n",
       " 'solver': 'adam',\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': False,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import decision tree model\n",
    "NN = MLPClassifier()\n",
    "NN.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb741258-a261-46fe-968f-0886d3615a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evalutions\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eda199ec-8d20-4d5d-8d50-e776a4b51519",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(\"heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c35d8548-6fbd-4eb2-9bfb-653a2459c35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>234</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>226</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>282</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>152</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>118</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>138</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>282</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     69    1   0       160   234    1        2      131      0      0.1   \n",
       "1     69    0   0       140   239    0        0      151      0      1.8   \n",
       "2     66    0   0       150   226    0        0      114      0      2.6   \n",
       "3     65    1   0       138   282    1        2      174      0      1.4   \n",
       "4     64    1   0       110   211    0        2      144      1      1.8   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "292   40    1   3       152   223    0        0      181      0      0.0   \n",
       "293   39    1   3       118   219    0        0      140      0      1.2   \n",
       "294   35    1   3       120   198    0        0      130      1      1.6   \n",
       "295   35    0   3       138   183    0        0      182      0      1.4   \n",
       "296   35    1   3       126   282    0        2      156      1      0.0   \n",
       "\n",
       "     slope  ca  thal  condition  \n",
       "0        1   1     0          0  \n",
       "1        0   2     0          0  \n",
       "2        2   0     0          0  \n",
       "3        1   1     0          1  \n",
       "4        1   0     0          0  \n",
       "..     ...  ..   ...        ...  \n",
       "292      0   0     2          1  \n",
       "293      1   0     2          1  \n",
       "294      1   0     2          1  \n",
       "295      0   0     0          0  \n",
       "296      0   0     2          1  \n",
       "\n",
       "[297 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfb476de-1970-4dd2-a484-0bb2ae4b3c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into X and y\n",
    "X_1 = df_1.drop(\"condition\",axis=1)\n",
    "y_1= df_1[\"condition\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5b7cdf-300b-44d4-ad5f-b5a54b586d80",
   "metadata": {},
   "source": [
    "* split into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d90a08f-c7cb-4729-b2ac-055a4e4a6611",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "#split into train and test\n",
    "X1_train,X1_test,y1_train,y1_test=train_test_split(X_1,y_1,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94b3d4e6-cbfb-42fb-8774-7633d3f5767f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'alpha': 0.0001,\n",
       " 'batch_size': 'auto',\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'early_stopping': False,\n",
       " 'epsilon': 1e-08,\n",
       " 'hidden_layer_sizes': (100,),\n",
       " 'learning_rate': 'constant',\n",
       " 'learning_rate_init': 0.001,\n",
       " 'max_fun': 15000,\n",
       " 'max_iter': 200,\n",
       " 'momentum': 0.9,\n",
       " 'n_iter_no_change': 10,\n",
       " 'nesterovs_momentum': True,\n",
       " 'power_t': 0.5,\n",
       " 'random_state': None,\n",
       " 'shuffle': True,\n",
       " 'solver': 'adam',\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': False,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3213181d-4b8b-447e-9898-091011c8acc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_size = range(1,100,10)\n",
    "train_scores=[]\n",
    "test_scores=[]\n",
    "# loop through layers\n",
    "for i in layer_size:\n",
    "    NN.set_params(hidden_layer_sizes=i, max_iter=1000)\n",
    "    NN.fit(X1_train,y1_train)\n",
    "    # update the training scores list\n",
    "    train_scores.append(NN.score(X1_train,y1_train))\n",
    "    #update the test scores list\n",
    "    test_scores.append(NN.score(X1_test,y1_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f457d6d-8eec-49d2-9c67-10de290032d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.540084388185654,\n",
       " 0.8776371308016878,\n",
       " 0.8860759493670886,\n",
       " 0.8776371308016878,\n",
       " 0.8860759493670886,\n",
       " 0.8860759493670886,\n",
       " 0.890295358649789,\n",
       " 0.8860759493670886,\n",
       " 0.890295358649789,\n",
       " 0.890295358649789]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "73055279-7ffe-474d-9303-475fb2cb2149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5333333333333333,\n",
       " 0.7,\n",
       " 0.7,\n",
       " 0.6666666666666666,\n",
       " 0.75,\n",
       " 0.7166666666666667,\n",
       " 0.75,\n",
       " 0.75,\n",
       " 0.7166666666666667,\n",
       " 0.7333333333333333]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7f93ba7-5060-4f75-8895-cc8790932de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max neural network score on the test data: 75.00%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(layer_size, train_scores, label=\"Train score\")\n",
    "plt.plot(layer_size, test_scores, label=\"Test score\")\n",
    "plt.ylim(0,1)\n",
    "plt.xticks(np.arange(0,100,10))\n",
    "plt.xlabel(\"hidden_layer_sizes\")\n",
    "plt.ylabel(\"Model score\")\n",
    "plt.legend()\n",
    "\n",
    "print(f\"Max neural network score on the test data: {max(test_scores)*100:.2f}%\")\n",
    "# default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3616e9cc-8b45-4e40-8a6b-f52a7199211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f1_train_scores_relu=[]\n",
    "f1_test_scores_relu=[]\n",
    "\n",
    "for i in layer_size:\n",
    "    NN.set_params(hidden_layer_sizes=i, max_iter=1000,activation='relu')\n",
    "    NN.fit(X1_train,y1_train)\n",
    "    y1_train_pred = NN.predict(X1_train)\n",
    "    y1_test_pred = NN.predict(X1_test)\n",
    "    # update the training scores list\n",
    "    f1_train_scores_relu.append(f1_score(y1_train,y1_train_pred))\n",
    "    f1_test_scores_relu.append(f1_score(y1_test,y1_test_pred))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5c283b60-4f6a-40e2-8add-84a6e2748c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f1_train_scores_logistic=[]\n",
    "f1_test_scores_logistic=[]\n",
    "\n",
    "for i in layer_size:\n",
    "    NN.set_params(hidden_layer_sizes=i, max_iter=2000,activation='logistic')\n",
    "    NN.fit(X1_train,y1_train)\n",
    "    y1_train_pred = NN.predict(X1_train)\n",
    "    y1_test_pred = NN.predict(X1_test)\n",
    "    # update the training scores list\n",
    "    f1_train_scores_logistic.append(f1_score(y1_train,y1_train_pred))\n",
    "    f1_test_scores_logistic.append(f1_score(y1_test,y1_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2118ae4b-df53-4934-90cc-d7fcfc0d6e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1dac8055190>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(layer_size, f1_train_scores_relu, label=\"f1 train scores relu\",color='C3',)\n",
    "plt.plot(layer_size, f1_test_scores_relu, label=\"f1 test scores relu\",color='C3', linestyle='--',)\n",
    "plt.plot(layer_size, f1_train_scores_logistic, label=\"f1 train scores logistic\",color='C0',)\n",
    "plt.plot(layer_size, f1_test_scores_logistic, label=\"f1 test scores logistic\",color='C0', linestyle='--',)\n",
    "plt.xticks(np.arange(0,100,10))\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel(\"layer size\")\n",
    "plt.ylabel(\"f1 score\")\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "07993c55-b936-4915-8c6e-7049e519f128",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = {\n",
    "    'activation': ['identity','logistic', 'tanh', 'relu'],\n",
    "    'hidden_layer_sizes': range(1,110,10),\n",
    "    'solver':['lbfgs', 'sgd', 'adam'],\n",
    "    'alpha':[0.0001,0.001],\n",
    "    'max_iter':[5000],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "296d4af1-1f45-453f-84bf-725be12de554",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=NN,\n",
    "    param_grid=params_grid,\n",
    "    return_train_score=True,\n",
    "    cv=4,\n",
    "    verbose=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "62055a11-9904-4caa-9292-938fc4462dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 264 candidates, totalling 1056 fits\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.870, test=0.867) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.854, test=0.881) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.427, test=0.508) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.904, test=0.814) total time=   0.1s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.458, test=0.467) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.376, test=0.322) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.685, test=0.627) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.624, test=0.644) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.621, test=0.733) total time=   0.1s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.669, test=0.644) total time=   0.1s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.461, test=0.458) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.596, test=0.644) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.870, test=0.867) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.871, test=0.881) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.871, test=0.864) total time=   0.1s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.904, test=0.814) total time=   0.1s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.542, test=0.533) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.775, test=0.780) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.713, test=0.746) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.764, test=0.763) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.542, test=0.533) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.876, test=0.881) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.904, test=0.814) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.870, test=0.867) total time=   0.1s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.854, test=0.881) total time=   0.1s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.871, test=0.864) total time=   0.1s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.904, test=0.814) total time=   0.1s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.706, test=0.800) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.702, test=0.678) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.758, test=0.746) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.753, test=0.763) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.475, test=0.483) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.522, test=0.542) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.871, test=0.881) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.618, test=0.644) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.542, test=0.533) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.854, test=0.881) total time=   0.2s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.871, test=0.864) total time=   0.2s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.904, test=0.814) total time=   0.1s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.740, test=0.767) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.708, test=0.661) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.691, test=0.661) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.708, test=0.729) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.458, test=0.467) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.449, test=0.424) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.876, test=0.915) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.657, test=0.627) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.870, test=0.867) total time=   0.2s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.854, test=0.881) total time=   0.2s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.871, test=0.864) total time=   0.2s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.904, test=0.814) total time=   0.2s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.633, test=0.617) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.674, test=0.627) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.708, test=0.661) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.753, test=0.712) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.548, test=0.550) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.876, test=0.864) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.876, test=0.898) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.910, test=0.831) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.870, test=0.867) total time=   0.2s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.854, test=0.881) total time=   0.3s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.871, test=0.864) total time=   0.2s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.904, test=0.814) total time=   0.2s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.701, test=0.733) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.736, test=0.746) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.702, test=0.627) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.742, test=0.729) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.864, test=0.867) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.652, test=0.610) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.876, test=0.847) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.916, test=0.814) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.870, test=0.867) total time=   0.2s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.860, test=0.881) total time=   0.2s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.871, test=0.864) total time=   0.2s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.904, test=0.814) total time=   0.2s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.672, test=0.783) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.725, test=0.712) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.736, test=0.712) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.657, test=0.644) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.870, test=0.900) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.871, test=0.898) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.888, test=0.831) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.904, test=0.797) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.870, test=0.867) total time=   0.2s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.539, test=0.542) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.871, test=0.864) total time=   0.1s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.904, test=0.814) total time=   0.2s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.712, test=0.767) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.669, test=0.678) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.478, test=0.475) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.663, test=0.712) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.870, test=0.900) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.871, test=0.881) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.871, test=0.898) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.916, test=0.814) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.876, test=0.867) total time=   0.3s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.854, test=0.881) total time=   0.2s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.871, test=0.864) total time=   0.2s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.904, test=0.814) total time=   0.2s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.684, test=0.767) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.680, test=0.661) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.747, test=0.644) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.624, test=0.593) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.881, test=0.900) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.427, test=0.390) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.522, test=0.525) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.910, test=0.814) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.870, test=0.867) total time=   0.5s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.854, test=0.881) total time=   0.3s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.871, test=0.864) total time=   0.2s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.904, test=0.814) total time=   0.2s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.593, test=0.733) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.730, test=0.695) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.713, test=0.678) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.618, test=0.661) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.384, test=0.300) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.876, test=0.915) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.865, test=0.847) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.899, test=0.797) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.876, test=0.867) total time=   0.2s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.854, test=0.881) total time=   0.2s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.871, test=0.864) total time=   0.2s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.904, test=0.814) total time=   0.3s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.684, test=0.750) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.657, test=0.712) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.708, test=0.729) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.725, test=0.763) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.876, test=0.917) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.775, test=0.780) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.787, test=0.814) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.399, test=0.424) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.870, test=0.867) total time=   0.1s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.854, test=0.881) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.758, test=0.712) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.904, test=0.814) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.729, test=0.750) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.528, test=0.525) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.421, test=0.407) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.802, test=0.800) total time=   0.2s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.702, test=0.661) total time=   0.1s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.360, test=0.424) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.870, test=0.867) total time=   0.1s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.854, test=0.881) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.904, test=0.814) total time=   0.1s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.542, test=0.533) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.461, test=0.458) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.584, test=0.593) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.674, test=0.678) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.542, test=0.533) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.320, test=0.356) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.640, test=0.627) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.870, test=0.867) total time=   0.1s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.854, test=0.881) total time=   0.1s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.871, test=0.864) total time=   0.1s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.904, test=0.814) total time=   0.1s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.559, test=0.583) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.742, test=0.695) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.652, test=0.593) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.607, test=0.576) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.571, test=0.583) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.652, test=0.644) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.882, test=0.881) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.551, test=0.627) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.542, test=0.533) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.539, test=0.542) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.871, test=0.864) total time=   0.2s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.904, test=0.814) total time=   0.1s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.684, test=0.717) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.713, test=0.661) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.708, test=0.678) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.674, test=0.678) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.492, test=0.317) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.882, test=0.881) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.876, test=0.831) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.904, test=0.814) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.870, test=0.867) total time=   0.1s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.854, test=0.881) total time=   0.2s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.871, test=0.864) total time=   0.1s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.904, test=0.814) total time=   0.2s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.548, test=0.567) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.685, test=0.661) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.781, test=0.831) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.669, test=0.678) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.458, test=0.467) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.882, test=0.864) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.882, test=0.881) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.933, test=0.814) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.542, test=0.533) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.854, test=0.881) total time=   0.2s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.871, test=0.864) total time=   0.2s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.904, test=0.814) total time=   0.2s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.672, test=0.667) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.691, test=0.695) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.534, test=0.475) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.635, test=0.610) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.582, test=0.600) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.876, test=0.898) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.916, test=0.814) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.876, test=0.867) total time=   0.2s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.854, test=0.881) total time=   0.2s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.871, test=0.864) total time=   0.2s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.904, test=0.814) total time=   0.2s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.689, test=0.733) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.691, test=0.678) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.742, test=0.763) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.713, test=0.661) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.876, test=0.900) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.876, test=0.881) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.534, test=0.441) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.360, test=0.373) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.870, test=0.867) total time=   0.2s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.854, test=0.881) total time=   0.3s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.871, test=0.864) total time=   0.2s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.904, test=0.814) total time=   0.2s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.695, test=0.817) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.607, test=0.610) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.640, test=0.610) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.612, test=0.661) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.881, test=0.900) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.882, test=0.864) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.882, test=0.898) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.921, test=0.814) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.876, test=0.850) total time=   0.2s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.854, test=0.881) total time=   0.3s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.871, test=0.864) total time=   0.3s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.904, test=0.814) total time=   0.2s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.678, test=0.700) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.640, test=0.627) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.702, test=0.678) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.691, test=0.678) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.616, test=0.650) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.876, test=0.864) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.876, test=0.898) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.612, test=0.593) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.870, test=0.867) total time=   0.3s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.854, test=0.881) total time=   0.3s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.871, test=0.864) total time=   0.2s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.904, test=0.814) total time=   0.2s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.542, test=0.533) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.562, test=0.576) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.736, test=0.695) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.556, test=0.542) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.881, test=0.917) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.876, test=0.864) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.674, test=0.559) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.921, test=0.814) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.870, test=0.867) total time=   0.3s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.854, test=0.881) total time=   0.3s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.871, test=0.864) total time=   0.2s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.904, test=0.814) total time=   0.2s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.678, test=0.783) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.640, test=0.678) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.736, test=0.695) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.646, test=0.695) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.881, test=0.900) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.775, test=0.746) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.888, test=0.864) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.916, test=0.831) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.542, test=0.533) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.910, test=0.831) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.638, test=0.700) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.461, test=0.458) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.542, test=0.533) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.888, test=0.881) total time=   0.2s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.899, test=0.881) total time=   0.2s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.554, test=0.517) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.860, test=0.797) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.961, test=0.814) total time=   0.7s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.678, test=0.683) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.742, test=0.712) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.629, test=0.644) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.938, test=0.867) total time=   0.2s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.539, test=0.576) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.927, test=0.797) total time=   0.1s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.802, test=0.800) total time=   0.1s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.910, test=0.814) total time=   0.9s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.781, test=0.678) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.966, test=0.814) total time=   0.8s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.751, test=0.750) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.742, test=0.695) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.713, test=0.678) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.747, test=0.729) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.955, test=0.850) total time=   0.3s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.961, test=0.847) total time=   0.3s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.955, test=0.881) total time=   0.3s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.961, test=0.780) total time=   0.2s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.949, test=0.867) total time=   0.6s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.820, test=0.729) total time=   0.3s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.938, test=0.746) total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.955, test=0.797) total time=   1.5s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.548, test=0.517) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.719, test=0.661) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.753, test=0.712) total time=   0.1s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.989, test=0.867) total time=   0.3s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.978, test=0.831) total time=   0.4s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.972, test=0.881) total time=   0.4s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.966, test=0.780) total time=   0.4s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.949, test=0.767) total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.933, test=0.797) total time=   1.9s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.860, test=0.746) total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.955, test=0.780) total time=   1.8s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.548, test=0.533) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.742, test=0.712) total time=   0.1s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.736, test=0.695) total time=   0.1s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.764, test=0.712) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.994, test=0.850) total time=   0.3s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.983, test=0.814) total time=   0.3s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.983, test=0.847) total time=   0.4s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.989, test=0.797) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.921, test=0.733) total time=   2.2s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.955, test=0.695) total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.966, test=0.712) total time=   1.7s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.944, test=0.814) total time=   1.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.757, test=0.767) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.747, test=0.729) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.730, test=0.695) total time=   0.1s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.753, test=0.729) total time=   0.1s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.989, test=0.817) total time=   0.4s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=1.000, test=0.847) total time=   0.4s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.989, test=0.864) total time=   0.4s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.994, test=0.780) total time=   0.3s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.921, test=0.767) total time=   0.8s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.966, test=0.746) total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.944, test=0.864) total time=   2.3s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.955, test=0.763) total time=   1.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.740, test=0.717) total time=   0.1s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.753, test=0.712) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.742, test=0.712) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.770, test=0.729) total time=   0.1s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.994, test=0.817) total time=   0.4s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=1.000, test=0.814) total time=   0.4s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=1.000, test=0.847) total time=   0.4s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.994, test=0.780) total time=   0.4s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.797, test=0.733) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.966, test=0.712) total time=   2.3s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.927, test=0.847) total time=   1.1s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.983, test=0.797) total time=   2.5s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.757, test=0.717) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.764, test=0.712) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.742, test=0.712) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.770, test=0.712) total time=   0.1s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=1.000, test=0.800) total time=   0.4s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=1.000, test=0.814) total time=   0.4s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=1.000, test=0.847) total time=   0.5s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.994, test=0.797) total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=1.000, test=0.767) total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.966, test=0.797) total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.978, test=0.712) total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.994, test=0.712) total time=   2.6s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.751, test=0.750) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.753, test=0.746) total time=   0.1s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.747, test=0.729) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.753, test=0.712) total time=   0.1s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.994, test=0.833) total time=   0.4s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=1.000, test=0.831) total time=   0.4s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=1.000, test=0.831) total time=   0.5s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=1.000, test=0.780) total time=   0.4s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.989, test=0.817) total time=   2.2s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.994, test=0.729) total time=   2.1s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.966, test=0.661) total time=   1.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.989, test=0.797) total time=   1.9s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.740, test=0.767) total time=   0.1s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.764, test=0.746) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.758, test=0.712) total time=   0.1s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.753, test=0.712) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.994, test=0.817) total time=   0.5s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=1.000, test=0.831) total time=   0.5s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.994, test=0.847) total time=   0.6s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=1.000, test=0.780) total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.955, test=0.783) total time=   3.1s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.972, test=0.763) total time=   2.2s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.978, test=0.847) total time=   2.7s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.989, test=0.797) total time=   2.1s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.746, test=0.750) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.747, test=0.746) total time=   0.1s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.742, test=0.678) total time=   0.1s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.753, test=0.712) total time=   0.1s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.994, test=0.850) total time=   0.4s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=1.000, test=0.831) total time=   0.4s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=1.000, test=0.847) total time=   0.5s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=1.000, test=0.780) total time=   0.4s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.542, test=0.533) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.458, test=0.467) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.461, test=0.458) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.461, test=0.458) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.461, test=0.458) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.542, test=0.533) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.461, test=0.458) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.539, test=0.542) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.949, test=0.817) total time=   0.8s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.725, test=0.661) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.539, test=0.542) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.966, test=0.780) total time=   0.9s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.740, test=0.700) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.545, test=0.542) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.713, test=0.661) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.904, test=0.917) total time=   0.1s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.921, test=0.847) total time=   0.2s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.904, test=0.864) total time=   0.1s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.927, test=0.797) total time=   0.1s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.870, test=0.883) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.961, test=0.746) total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.944, test=0.831) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.927, test=0.746) total time=   1.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.542, test=0.533) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.719, test=0.695) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.719, test=0.593) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.758, test=0.763) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.977, test=0.867) total time=   0.3s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.955, test=0.797) total time=   0.3s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.972, test=0.864) total time=   0.3s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.966, test=0.797) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.944, test=0.800) total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.949, test=0.831) total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.944, test=0.780) total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.972, test=0.712) total time=   1.5s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.757, test=0.717) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.747, test=0.712) total time=   0.1s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.753, test=0.678) total time=   0.1s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.730, test=0.712) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.983, test=0.833) total time=   0.4s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.983, test=0.847) total time=   0.4s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.972, test=0.847) total time=   0.4s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.978, test=0.814) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.994, test=0.733) total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.989, test=0.729) total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.966, test=0.814) total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.966, test=0.797) total time=   1.6s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.746, test=0.717) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.747, test=0.746) total time=   0.1s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.736, test=0.712) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.747, test=0.712) total time=   0.1s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.994, test=0.817) total time=   0.4s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=1.000, test=0.831) total time=   0.4s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.989, test=0.864) total time=   0.4s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.989, test=0.797) total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.966, test=0.783) total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.983, test=0.678) total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.955, test=0.780) total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.966, test=0.780) total time=   2.1s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.763, test=0.750) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.753, test=0.746) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.747, test=0.712) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.764, test=0.712) total time=   0.1s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.994, test=0.817) total time=   0.4s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=1.000, test=0.831) total time=   0.4s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.989, test=0.847) total time=   0.4s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.994, test=0.780) total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=1.000, test=0.750) total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.955, test=0.746) total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.972, test=0.780) total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.994, test=0.746) total time=   2.2s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.757, test=0.717) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.742, test=0.746) total time=   0.1s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.742, test=0.729) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.775, test=0.729) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.989, test=0.850) total time=   0.5s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=1.000, test=0.847) total time=   0.4s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.989, test=0.847) total time=   0.5s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.994, test=0.763) total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.977, test=0.833) total time=   2.2s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.904, test=0.797) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.989, test=0.763) total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.989, test=0.763) total time=   2.2s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.751, test=0.767) total time=   0.1s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.753, test=0.712) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.747, test=0.712) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.742, test=0.712) total time=   0.1s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.994, test=0.833) total time=   0.4s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=1.000, test=0.831) total time=   0.4s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=1.000, test=0.847) total time=   0.5s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.994, test=0.797) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.983, test=0.800) total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.983, test=0.780) total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.989, test=0.763) total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=1.000, test=0.780) total time=   2.5s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.757, test=0.717) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.758, test=0.746) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.736, test=0.712) total time=   0.1s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.742, test=0.712) total time=   0.1s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.989, test=0.800) total time=   0.5s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=1.000, test=0.831) total time=   0.5s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=1.000, test=0.847) total time=   0.6s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.994, test=0.797) total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.983, test=0.850) total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=1.000, test=0.814) total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.955, test=0.831) total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=1.000, test=0.729) total time=   3.3s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.757, test=0.750) total time=   0.1s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.747, test=0.746) total time=   0.1s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.747, test=0.746) total time=   0.1s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.753, test=0.729) total time=   0.1s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.994, test=0.850) total time=   0.5s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=1.000, test=0.797) total time=   0.6s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=1.000, test=0.847) total time=   0.6s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.994, test=0.780) total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=1.000, test=0.850) total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.961, test=0.780) total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=1.000, test=0.695) total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=1.000, test=0.763) total time=   4.4s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.751, test=0.750) total time=   0.1s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.764, test=0.746) total time=   0.1s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.742, test=0.729) total time=   0.1s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.742, test=0.712) total time=   0.1s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.994, test=0.833) total time=   0.6s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=1.000, test=0.831) total time=   0.6s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=1.000, test=0.831) total time=   0.6s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.994, test=0.763) total time=   0.6s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.542, test=0.517) total time=   0.0s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.542, test=0.533) total time=   0.0s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.461, test=0.458) total time=   0.0s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.461, test=0.458) total time=   0.0s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.542, test=0.533) total time=   0.0s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.461, test=0.458) total time=   0.0s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.522, test=0.542) total time=   0.1s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.461, test=0.458) total time=   0.0s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.599, test=0.567) total time=   0.0s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.916, test=0.780) total time=   0.4s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.949, test=0.797) total time=   0.4s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.542, test=0.483) total time=   0.0s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.539, test=0.576) total time=   0.0s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.534, test=0.542) total time=   0.0s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.736, test=0.712) total time=   0.0s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.542, test=0.533) total time=   0.0s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.893, test=0.814) total time=   0.3s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.966, test=0.898) total time=   0.3s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.825, test=0.783) total time=   0.1s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.652, test=0.627) total time=   0.0s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.854, test=0.661) total time=   0.5s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.938, test=0.729) total time=   0.9s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.751, test=0.750) total time=   0.0s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.747, test=0.661) total time=   0.1s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.534, test=0.542) total time=   0.0s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.545, test=0.542) total time=   0.0s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.972, test=0.900) total time=   0.4s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.961, test=0.797) total time=   0.4s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.972, test=0.864) total time=   0.4s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.961, test=0.814) total time=   0.4s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.898, test=0.733) total time=   2.7s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.713, test=0.661) total time=   0.2s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.916, test=0.678) total time=   2.2s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.848, test=0.763) total time=   2.8s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.582, test=0.733) total time=   0.0s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.764, test=0.712) total time=   0.2s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.781, test=0.712) total time=   0.1s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.719, test=0.712) total time=   0.1s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.650, test=0.617) total time=   0.0s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.983, test=0.797) total time=   0.8s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.978, test=0.831) total time=   0.7s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.994, test=0.797) total time=   0.6s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.944, test=0.833) total time=   2.4s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.770, test=0.661) total time=   0.0s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.927, test=0.729) total time=   1.9s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.730, test=0.661) total time=   0.1s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.763, test=0.683) total time=   0.2s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.781, test=0.695) total time=   0.1s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.669, test=0.610) total time=   0.0s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.758, test=0.763) total time=   0.1s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.983, test=0.833) total time=   0.9s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.994, test=0.814) total time=   0.9s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.994, test=0.864) total time=   0.9s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.927, test=0.831) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.932, test=0.700) total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.893, test=0.831) total time=   4.7s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.921, test=0.831) total time=   3.0s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.927, test=0.780) total time=   2.3s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.746, test=0.750) total time=   0.1s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.770, test=0.712) total time=   0.1s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.742, test=0.678) total time=   0.1s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.747, test=0.746) total time=   0.1s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=1.000, test=0.883) total time=   1.0s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=1.000, test=0.814) total time=   0.7s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.994, test=0.898) total time=   1.0s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=1.000, test=0.780) total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.938, test=0.767) total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.972, test=0.695) total time=   4.9s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.972, test=0.814) total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.966, test=0.780) total time=   5.0s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.768, test=0.733) total time=   0.6s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.764, test=0.661) total time=   0.1s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.753, test=0.695) total time=   0.2s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.747, test=0.763) total time=   0.2s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.994, test=0.800) total time=   0.9s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=1.000, test=0.831) total time=   0.8s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.989, test=0.864) total time=   1.3s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=1.000, test=0.780) total time=   0.8s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.960, test=0.817) total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.955, test=0.847) total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.961, test=0.814) total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.972, test=0.780) total time=   5.7s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.757, test=0.767) total time=   0.2s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.747, test=0.644) total time=   0.5s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.742, test=0.763) total time=   0.3s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.753, test=0.729) total time=   0.1s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=1.000, test=0.917) total time=   0.8s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=1.000, test=0.814) total time=   1.1s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=1.000, test=0.864) total time=   1.1s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=1.000, test=0.780) total time=   0.9s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.949, test=0.767) total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.972, test=0.763) total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.944, test=0.797) total time=   6.3s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.989, test=0.780) total time=   3.2s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.746, test=0.767) total time=   0.2s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.781, test=0.644) total time=   0.3s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.753, test=0.763) total time=   0.2s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.764, test=0.729) total time=   0.2s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=1.000, test=0.867) total time=   1.0s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=1.000, test=0.814) total time=   0.9s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=1.000, test=0.847) total time=   1.1s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=1.000, test=0.814) total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.977, test=0.783) total time=   6.5s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=1.000, test=0.831) total time=   4.8s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.860, test=0.678) total time=   1.5s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.983, test=0.678) total time=   7.1s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.734, test=0.700) total time=   0.4s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.781, test=0.712) total time=   0.3s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.787, test=0.678) total time=   0.2s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.753, test=0.678) total time=   0.3s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=1.000, test=0.850) total time=   0.9s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=1.000, test=0.847) total time=   1.0s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=1.000, test=0.898) total time=   1.2s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=1.000, test=0.763) total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.960, test=0.717) total time=   7.1s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.949, test=0.797) total time=   4.4s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.989, test=0.831) total time=   5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=1.000, test=0.661) total time=   8.4s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.763, test=0.750) total time=   0.3s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.758, test=0.729) total time=   0.4s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.753, test=0.729) total time=   0.4s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.742, test=0.729) total time=   0.4s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=1.000, test=0.850) total time=   1.4s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=1.000, test=0.797) total time=   1.0s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=1.000, test=0.864) total time=   1.5s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=1.000, test=0.780) total time=   1.2s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.542, test=0.533) total time=   0.0s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.729, test=0.683) total time=   0.1s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.708, test=0.644) total time=   0.0s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.461, test=0.458) total time=   0.0s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.542, test=0.533) total time=   0.0s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.562, test=0.542) total time=   0.0s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.506, test=0.508) total time=   0.0s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.898, test=0.783) total time=   1.3s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.927, test=0.831) total time=   0.6s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.944, test=0.797) total time=   0.8s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.757, test=0.750) total time=   0.0s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.949, test=0.917) total time=   0.3s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.921, test=0.864) total time=   0.3s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.910, test=0.814) total time=   0.2s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.961, test=0.797) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.938, test=0.767) total time=   1.6s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.629, test=0.610) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.938, test=0.814) total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.966, test=0.763) total time=   1.9s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.655, test=0.667) total time=   0.0s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.775, test=0.729) total time=   0.1s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.764, test=0.678) total time=   0.0s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.579, test=0.542) total time=   0.0s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.616, test=0.633) total time=   0.0s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.978, test=0.797) total time=   0.5s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.978, test=0.847) total time=   0.6s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.994, test=0.780) total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.955, test=0.783) total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.921, test=0.763) total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.916, test=0.797) total time=   3.7s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.955, test=0.797) total time=   2.1s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.768, test=0.733) total time=   0.3s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.736, test=0.593) total time=   0.2s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.629, test=0.559) total time=   0.0s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.730, test=0.712) total time=   0.1s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.994, test=0.850) total time=   0.9s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.955, test=0.831) total time=   0.8s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.972, test=0.831) total time=   0.9s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.994, test=0.797) total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.972, test=0.683) total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.921, test=0.814) total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.955, test=0.695) total time=   3.9s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.938, test=0.780) total time=   2.4s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.734, test=0.683) total time=   0.0s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.730, test=0.661) total time=   0.3s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.730, test=0.610) total time=   0.1s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.646, test=0.593) total time=   0.0s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=1.000, test=0.850) total time=   0.7s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=1.000, test=0.797) total time=   0.7s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=1.000, test=0.847) total time=   0.9s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=1.000, test=0.763) total time=   0.6s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.921, test=0.817) total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.972, test=0.780) total time=   4.4s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.921, test=0.864) total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=1.000, test=0.780) total time=   4.3s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.763, test=0.700) total time=   0.3s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.522, test=0.475) total time=   0.0s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.770, test=0.661) total time=   0.1s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.747, test=0.678) total time=   0.1s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=1.000, test=0.850) total time=   0.7s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=1.000, test=0.847) total time=   0.8s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.994, test=0.847) total time=   0.9s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=1.000, test=0.797) total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.898, test=0.700) total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.989, test=0.797) total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.949, test=0.763) total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.989, test=0.797) total time=   5.0s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.740, test=0.733) total time=   0.2s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.758, test=0.712) total time=   0.3s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.764, test=0.729) total time=   0.2s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.764, test=0.695) total time=   0.2s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.994, test=0.867) total time=   0.9s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=1.000, test=0.831) total time=   0.9s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=1.000, test=0.864) total time=   0.9s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=1.000, test=0.780) total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.983, test=0.800) total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.927, test=0.797) total time=   5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.978, test=0.797) total time=   5.8s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.978, test=0.763) total time=   4.8s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.734, test=0.717) total time=   0.2s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.579, test=0.525) total time=   0.0s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.730, test=0.627) total time=   0.2s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.775, test=0.729) total time=   0.1s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.994, test=0.850) total time=   0.9s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=1.000, test=0.847) total time=   1.0s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=1.000, test=0.881) total time=   0.9s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=1.000, test=0.780) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.955, test=0.767) total time=   6.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.949, test=0.780) total time=   7.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.978, test=0.729) total time=   6.1s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.910, test=0.729) total time=   2.9s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.774, test=0.700) total time=   0.4s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.747, test=0.712) total time=   0.2s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.770, test=0.729) total time=   0.3s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.747, test=0.661) total time=   0.4s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=1.000, test=0.817) total time=   0.8s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=1.000, test=0.831) total time=   1.1s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.994, test=0.847) total time=   1.1s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=1.000, test=0.780) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=1.000, test=0.683) total time=   6.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.961, test=0.712) total time=   6.6s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.983, test=0.780) total time=   6.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.989, test=0.763) total time=   8.3s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.774, test=0.717) total time=   0.5s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.775, test=0.576) total time=   0.3s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.753, test=0.695) total time=   0.3s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.747, test=0.746) total time=   0.3s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=1.000, test=0.833) total time=   1.0s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=1.000, test=0.847) total time=   0.9s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=1.000, test=0.898) total time=   1.2s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=1.000, test=0.780) total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=1.000, test=0.683) total time=   7.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=1.000, test=0.814) total time=   7.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=1.000, test=0.780) total time=   7.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.978, test=0.763) total time=   7.5s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.768, test=0.717) total time=   0.6s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.764, test=0.610) total time=   0.4s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.770, test=0.780) total time=   0.3s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.775, test=0.729) total time=   0.5s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=1.000, test=0.833) total time=   1.3s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=1.000, test=0.814) total time=   1.1s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=1.000, test=0.864) total time=   1.3s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=1.000, test=0.763) total time=   1.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.542, test=0.533) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.542, test=0.533) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.461, test=0.458) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.542, test=0.533) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.461, test=0.458) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.461, test=0.458) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.864, test=0.900) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.831, test=0.831) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.860, test=0.898) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.888, test=0.814) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.588, test=0.783) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.736, test=0.644) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.742, test=0.746) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.691, test=0.695) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.458, test=0.467) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.882, test=0.831) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.657, test=0.576) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.870, test=0.933) total time=   0.2s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.882, test=0.847) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.888, test=0.864) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.567, test=0.525) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.751, test=0.750) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.747, test=0.712) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.657, test=0.695) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.556, test=0.525) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.542, test=0.533) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.393, test=0.356) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.893, test=0.867) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.882, test=0.847) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.871, test=0.898) total time=   0.3s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.899, test=0.814) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.718, test=0.633) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.646, test=0.712) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.758, test=0.695) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.887, test=0.917) total time=   0.1s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.624, test=0.610) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.910, test=0.814) total time=   0.1s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.893, test=0.850) total time=   0.1s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.899, test=0.864) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.910, test=0.780) total time=   0.1s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.684, test=0.533) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.758, test=0.678) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.640, test=0.576) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.770, test=0.712) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.525, test=0.500) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.663, test=0.695) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.629, test=0.661) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.932, test=0.817) total time=   0.6s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.888, test=0.847) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.904, test=0.898) total time=   0.2s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.910, test=0.797) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.751, test=0.750) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.663, test=0.661) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.764, test=0.695) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.618, test=0.627) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.989, test=0.767) total time=   0.9s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.640, test=0.610) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.624, test=0.542) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.916, test=0.780) total time=   0.1s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.921, test=0.850) total time=   0.2s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.910, test=0.814) total time=   0.2s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.860, test=0.864) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.904, test=0.814) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.734, test=0.733) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.680, test=0.661) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.669, test=0.610) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.758, test=0.678) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.876, test=0.883) total time=   0.1s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.562, test=0.525) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.882, test=0.847) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.674, test=0.695) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.542, test=0.533) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.899, test=0.847) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.893, test=0.847) total time=   0.2s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.949, test=0.746) total time=   0.5s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.774, test=0.750) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.669, test=0.695) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.753, test=0.712) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.758, test=0.678) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.876, test=0.867) total time=   0.1s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.646, test=0.695) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.573, test=0.576) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.915, test=0.850) total time=   0.5s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.916, test=0.797) total time=   0.3s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.539, test=0.542) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.944, test=0.746) total time=   0.6s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.661, test=0.600) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.719, test=0.610) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.753, test=0.729) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.753, test=0.729) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.972, test=0.817) total time=   0.8s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.944, test=0.797) total time=   0.5s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.921, test=0.797) total time=   0.2s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.881, test=0.883) total time=   0.1s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.916, test=0.797) total time=   0.4s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.893, test=0.864) total time=   0.3s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.933, test=0.763) total time=   0.2s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.729, test=0.667) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.663, test=0.627) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.736, test=0.695) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.747, test=0.763) total time=   0.1s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.712, test=0.633) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.916, test=0.847) total time=   0.5s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.910, test=0.847) total time=   0.3s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.652, test=0.678) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.977, test=0.750) total time=   1.5s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.893, test=0.847) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.893, test=0.864) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.978, test=0.780) total time=   1.1s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.763, test=0.750) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.713, test=0.712) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.685, test=0.678) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.775, test=0.746) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.977, test=0.883) total time=   1.1s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.972, test=0.814) total time=   0.6s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=1.000, test=0.864) total time=   1.2s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.910, test=0.797) total time=   0.2s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.542, test=0.533) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.542, test=0.533) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.461, test=0.458) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.542, test=0.533) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.545, test=0.559) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.539, test=0.542) total time=   0.1s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.876, test=0.883) total time=   0.2s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.882, test=0.831) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.904, test=0.814) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.655, test=0.617) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.758, test=0.678) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.461, test=0.458) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.685, test=0.678) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.864, test=0.883) total time=   0.1s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.360, test=0.407) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.865, test=0.847) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.910, test=0.814) total time=   0.1s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.870, test=0.850) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.888, test=0.847) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.871, test=0.898) total time=   0.2s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.899, test=0.814) total time=   0.1s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.740, test=0.733) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.657, test=0.695) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.461, test=0.458) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.539, test=0.525) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.972, test=0.833) total time=   0.4s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.899, test=0.831) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.725, test=0.661) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.618, test=0.695) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.870, test=0.917) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.871, test=0.881) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.882, test=0.881) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.916, test=0.797) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.678, test=0.617) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.652, test=0.627) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.652, test=0.492) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.697, test=0.610) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.582, test=0.583) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.899, test=0.814) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.882, test=0.915) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.360, test=0.356) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.881, test=0.867) total time=   0.1s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.882, test=0.814) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.876, test=0.847) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.949, test=0.797) total time=   0.3s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.678, test=0.617) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.646, test=0.729) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.725, test=0.644) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.764, test=0.729) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.531, test=0.617) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.551, test=0.610) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.927, test=0.881) total time=   0.4s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.876, test=0.867) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.893, test=0.847) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.865, test=0.881) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.927, test=0.814) total time=   0.2s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.729, test=0.750) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.719, test=0.729) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.697, test=0.746) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.534, test=0.542) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.605, test=0.617) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.893, test=0.898) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.360, test=0.339) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.887, test=0.867) total time=   0.2s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.865, test=0.881) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.893, test=0.847) total time=   0.2s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.904, test=0.797) total time=   0.1s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.701, test=0.683) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.742, test=0.661) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.697, test=0.678) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.691, test=0.678) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.531, test=0.550) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.882, test=0.847) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.910, test=0.898) total time=   0.2s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.657, test=0.678) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.542, test=0.533) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.910, test=0.831) total time=   0.2s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.539, test=0.542) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.904, test=0.814) total time=   0.3s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.751, test=0.733) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.584, test=0.475) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.669, test=0.644) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.691, test=0.678) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.887, test=0.867) total time=   0.3s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.921, test=0.814) total time=   0.3s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.904, test=0.864) total time=   0.2s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.921, test=0.797) total time=   0.1s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.921, test=0.833) total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.860, test=0.831) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.876, test=0.881) total time=   0.2s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.933, test=0.797) total time=   0.4s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.746, test=0.733) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.691, test=0.712) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.736, test=0.695) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.764, test=0.746) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.870, test=0.900) total time=   0.2s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.994, test=0.797) total time=   0.9s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.893, test=0.864) total time=   0.3s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.539, test=0.542) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.887, test=0.867) total time=   0.1s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.876, test=0.864) total time=   0.2s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.904, test=0.847) total time=   0.3s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.910, test=0.797) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.689, test=0.700) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.736, test=0.712) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.685, test=0.610) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.753, test=0.729) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.932, test=0.817) total time=   0.4s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.747, test=0.746) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.893, test=0.881) total time=   0.2s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.989, test=0.797) total time=   0.8s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.915, test=0.800) total time=   0.3s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.899, test=0.831) total time=   0.2s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.893, test=0.864) total time=   0.3s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.927, test=0.814) total time=   0.2s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.684, test=0.700) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.674, test=0.627) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.787, test=0.712) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.753, test=0.729) total time=   0.1s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.684, test=0.783) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.719, test=0.644) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.506, test=0.508) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=1.000, test=0.729) total time=   1.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4,\n",
       "             estimator=MLPClassifier(activation=&#x27;logistic&#x27;,\n",
       "                                     hidden_layer_sizes=91, max_iter=2000),\n",
       "             param_grid={&#x27;activation&#x27;: [&#x27;identity&#x27;, &#x27;logistic&#x27;, &#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                         &#x27;alpha&#x27;: [0.0001, 0.001],\n",
       "                         &#x27;hidden_layer_sizes&#x27;: range(1, 110, 10),\n",
       "                         &#x27;max_iter&#x27;: [5000],\n",
       "                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;sgd&#x27;, &#x27;adam&#x27;]},\n",
       "             return_train_score=True, verbose=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=4,\n",
       "             estimator=MLPClassifier(activation=&#x27;logistic&#x27;,\n",
       "                                     hidden_layer_sizes=91, max_iter=2000),\n",
       "             param_grid={&#x27;activation&#x27;: [&#x27;identity&#x27;, &#x27;logistic&#x27;, &#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                         &#x27;alpha&#x27;: [0.0001, 0.001],\n",
       "                         &#x27;hidden_layer_sizes&#x27;: range(1, 110, 10),\n",
       "                         &#x27;max_iter&#x27;: [5000],\n",
       "                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;sgd&#x27;, &#x27;adam&#x27;]},\n",
       "             return_train_score=True, verbose=5)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: MLPClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, hidden_layer_sizes=91, max_iter=2000)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MLPClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, hidden_layer_sizes=91, max_iter=2000)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=4,\n",
       "             estimator=MLPClassifier(activation='logistic',\n",
       "                                     hidden_layer_sizes=91, max_iter=2000),\n",
       "             param_grid={'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
       "                         'alpha': [0.0001, 0.001],\n",
       "                         'hidden_layer_sizes': range(1, 110, 10),\n",
       "                         'max_iter': [5000],\n",
       "                         'solver': ['lbfgs', 'sgd', 'adam']},\n",
       "             return_train_score=True, verbose=5)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X1_train,y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4ca7a1a3-1895-42eb-8225-05c782c86220",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = grid_search.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fb0dd580-cd0a-480b-a592-8293cf2eb690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([8.98492932e-02, 5.49870729e-03, 1.21106684e-01, 1.39191866e-01,\n",
       "        1.34462118e-02, 4.59565520e-02, 1.99156582e-01, 1.47513151e-02,\n",
       "        2.96459198e-02, 1.99461699e-01, 8.49813223e-03, 2.76260376e-02,\n",
       "        2.86845863e-01, 8.51052999e-03, 6.63836598e-02, 3.21537852e-01,\n",
       "        9.75924730e-03, 6.59257174e-02, 2.91605830e-01, 8.50212574e-03,\n",
       "        9.88062620e-02, 2.18320847e-01, 9.26971436e-03, 9.00700092e-02,\n",
       "        3.33061218e-01, 9.89538431e-03, 4.89181876e-02, 3.86943400e-01,\n",
       "        8.97306204e-03, 7.14095235e-02, 3.33912909e-01, 9.62650776e-03,\n",
       "        3.41545939e-02, 1.21409714e-01, 1.17014050e-02, 1.41742706e-01,\n",
       "        1.71827853e-01, 6.54721260e-03, 4.99838591e-03, 2.20187008e-01,\n",
       "        5.97858429e-03, 2.21683979e-02, 1.31535709e-01, 9.25028324e-03,\n",
       "        8.10391307e-02, 2.50433445e-01, 1.62531137e-02, 7.33922124e-02,\n",
       "        2.24968970e-01, 9.25517082e-03, 4.29040194e-02, 3.07201266e-01,\n",
       "        7.50774145e-03, 4.39205766e-02, 3.40955138e-01, 9.15086269e-03,\n",
       "        7.69644976e-02, 3.19156885e-01, 1.07427835e-02, 4.96300459e-02,\n",
       "        3.39659989e-01, 8.86046886e-03, 6.44742846e-02, 3.45389187e-01,\n",
       "        1.98884010e-02, 6.86355233e-02, 1.68775320e-02, 6.75117970e-03,\n",
       "        1.31718695e-01, 2.27613688e-01, 2.69183517e-02, 1.37258291e-01,\n",
       "        5.18157184e-01, 1.02409840e-01, 3.71301174e-01, 1.01580119e+00,\n",
       "        8.01419020e-02, 4.92807746e-01, 1.36636937e+00, 1.36026621e-01,\n",
       "        4.62319493e-01, 1.71190971e+00, 1.50596917e-01, 4.88179982e-01,\n",
       "        1.58080792e+00, 1.43625021e-01, 4.87720788e-01, 1.55592424e+00,\n",
       "        1.38659418e-01, 5.21254301e-01, 2.99296111e+00, 1.43292010e-01,\n",
       "        5.16082704e-01, 1.87059718e+00, 1.56617224e-01, 5.97384393e-01,\n",
       "        2.64529443e+00, 1.53908968e-01, 5.28277755e-01, 2.50011683e-03,\n",
       "        1.98766589e-02, 4.25794125e-02, 4.85757768e-01, 5.78107238e-02,\n",
       "        2.38240957e-01, 9.08453107e-01, 8.00591111e-02, 3.91763568e-01,\n",
       "        1.68699372e+00, 1.55292809e-01, 4.87183750e-01, 1.71982688e+00,\n",
       "        1.39256597e-01, 5.03711164e-01, 2.15293014e+00, 1.44448280e-01,\n",
       "        4.85203207e-01, 2.24596220e+00, 1.26943588e-01, 5.41346610e-01,\n",
       "        2.02838540e+00, 1.45664036e-01, 5.21610737e-01, 2.70086163e+00,\n",
       "        1.57834291e-01, 6.03157401e-01, 3.23696816e+00, 1.85633898e-01,\n",
       "        6.55272245e-01, 4.26643229e+00, 2.15434134e-01, 7.03927994e-01,\n",
       "        3.99529934e-03, 3.86814475e-02, 9.23971534e-02, 2.78604388e-01,\n",
       "        2.97406912e-02, 2.29853034e-01, 4.65403736e-01, 8.09012055e-02,\n",
       "        4.79885459e-01, 2.09050578e+00, 1.56465471e-01, 6.17421031e-01,\n",
       "        1.22270304e+00, 1.97157025e-01, 8.18896353e-01, 3.74499416e+00,\n",
       "        1.97618246e-01, 9.45906341e-01, 5.06888437e+00, 3.96783054e-01,\n",
       "        1.02684468e+00, 5.67124164e+00, 3.82348895e-01, 1.09875047e+00,\n",
       "        4.91385472e+00, 3.22569609e-01, 1.06098354e+00, 5.09120023e+00,\n",
       "        3.95633817e-01, 1.11753982e+00, 6.56470978e+00, 4.79710102e-01,\n",
       "        1.35036373e+00, 3.75002623e-03, 9.04424191e-02, 2.06444263e-02,\n",
       "        7.35400200e-01, 4.99753356e-02, 3.76104057e-01, 1.40004194e+00,\n",
       "        6.88393712e-02, 4.29055631e-01, 3.35806519e+00, 2.29469419e-01,\n",
       "        8.91554356e-01, 3.69378787e+00, 1.78841114e-01, 8.38293731e-01,\n",
       "        3.79362184e+00, 2.10367560e-01, 8.72517109e-01, 5.18551397e+00,\n",
       "        3.24224234e-01, 9.97853041e-01, 5.52607912e+00, 2.05100954e-01,\n",
       "        1.04055727e+00, 5.64823061e+00, 4.15993989e-01, 1.05129874e+00,\n",
       "        7.21159130e+00, 4.35776472e-01, 1.13487905e+00, 7.39217377e+00,\n",
       "        5.31524122e-01, 1.24964142e+00, 3.74960899e-03, 7.74445534e-02,\n",
       "        4.93069291e-02, 4.66452241e-02, 2.59951353e-02, 4.87484932e-02,\n",
       "        1.24085963e-01, 1.47507191e-02, 5.37955761e-03, 1.41523361e-01,\n",
       "        2.53484249e-02, 1.01406634e-01, 1.57662868e-01, 3.02700400e-02,\n",
       "        1.15016103e-02, 2.95916796e-01, 6.79725409e-02, 3.07601392e-01,\n",
       "        2.06737876e-01, 4.57585454e-02, 1.01792216e-01, 2.73830891e-01,\n",
       "        6.36336207e-02, 5.32560349e-02, 4.28618252e-01, 4.62822914e-02,\n",
       "        4.64870095e-01, 3.67829263e-01, 9.47771668e-02, 2.55449414e-01,\n",
       "        8.12027097e-01, 6.26677871e-02, 8.60114455e-01, 3.75074148e-03,\n",
       "        5.87992072e-02, 9.03143287e-02, 1.22232735e-01, 1.59522891e-02,\n",
       "        1.28486991e-01, 1.56731486e-01, 1.71257854e-02, 1.63618684e-01,\n",
       "        1.53442442e-01, 9.68801975e-03, 1.10513747e-01, 2.24822879e-01,\n",
       "        2.05016732e-02, 1.36065423e-01, 1.67252243e-01, 2.13724375e-02,\n",
       "        5.02604842e-02, 2.37176657e-01, 1.83776021e-02, 1.53330088e-01,\n",
       "        1.78794742e-01, 2.66306400e-02, 3.30785036e-01, 3.74897659e-01,\n",
       "        3.93472314e-02, 4.23632920e-01, 2.63891280e-01, 6.09817505e-02,\n",
       "        4.32171881e-01, 3.44018221e-01, 1.05846345e-01, 2.85444021e-01]),\n",
       " 'std_fit_time': array([5.36959554e-02, 4.98594913e-04, 9.73106479e-02, 5.01709868e-02,\n",
       "        8.56172384e-03, 4.33054081e-02, 1.56622760e-02, 1.34955444e-02,\n",
       "        3.86196346e-02, 1.10473926e-01, 1.11782023e-03, 3.86234484e-02,\n",
       "        1.84192630e-02, 1.10608212e-03, 3.38159830e-02, 5.01987801e-02,\n",
       "        2.26971549e-03, 3.92100976e-02, 3.37527330e-02, 4.97939058e-04,\n",
       "        9.31849250e-03, 1.26183897e-01, 1.92537625e-03, 1.43273196e-02,\n",
       "        3.69819058e-02, 2.63373794e-03, 3.93498130e-02, 1.04386909e-01,\n",
       "        7.18812293e-04, 3.83098988e-02, 3.30342082e-02, 4.13544585e-04,\n",
       "        2.78930262e-02, 8.08508721e-02, 1.39248606e-02, 1.42073409e-01,\n",
       "        9.69762426e-02, 1.16197419e-03, 2.12194199e-03, 1.37176900e-02,\n",
       "        7.04399713e-04, 2.68611669e-02, 1.24845998e-01, 1.08920836e-03,\n",
       "        4.08667527e-02, 2.40492483e-02, 1.19847819e-02, 4.18149110e-02,\n",
       "        1.26832932e-01, 1.08985841e-03, 3.71785217e-02, 2.61586390e-02,\n",
       "        2.05263214e-03, 3.48628243e-02, 1.54177371e-02, 5.16900236e-04,\n",
       "        1.43804260e-02, 4.65068174e-02, 4.27775240e-04, 4.23267112e-02,\n",
       "        2.98529570e-02, 1.04610288e-03, 3.33428159e-02, 2.16737062e-02,\n",
       "        1.36527959e-02, 2.36816253e-02, 2.40361412e-02, 4.76155617e-03,\n",
       "        1.27303137e-01, 3.08285688e-01, 2.09480401e-02, 1.34233059e-01,\n",
       "        4.13681512e-01, 1.12315294e-02, 3.39418331e-02, 4.47962300e-01,\n",
       "        6.61974032e-02, 3.59460059e-02, 6.10872620e-01, 7.17247364e-02,\n",
       "        4.81153033e-02, 4.37496972e-01, 1.71013950e-02, 4.30040436e-02,\n",
       "        6.02719000e-01, 1.27798513e-02, 2.96692701e-02, 9.95809735e-01,\n",
       "        1.71979352e-02, 2.70539675e-02, 4.34302553e-01, 2.67859565e-02,\n",
       "        4.63553722e-02, 4.86632931e-01, 3.61435087e-02, 4.95858518e-02,\n",
       "        3.99847621e-01, 1.61834920e-02, 2.91727793e-02, 4.99546990e-04,\n",
       "        1.44947484e-02, 4.26625608e-02, 4.73440948e-01, 5.27852217e-02,\n",
       "        5.06768966e-02, 3.94823001e-01, 4.18744248e-02, 2.02648960e-02,\n",
       "        3.84049124e-02, 3.29051685e-02, 5.12412395e-02, 1.99648603e-02,\n",
       "        1.84966604e-02, 2.67415720e-02, 9.00918098e-02, 1.49359374e-02,\n",
       "        3.12309795e-02, 6.98428194e-02, 2.46450344e-02, 6.74774301e-02,\n",
       "        4.78376985e-01, 3.41996920e-02, 6.04501354e-02, 3.39563514e-01,\n",
       "        1.81059618e-02, 3.50907673e-02, 9.63331466e-02, 1.80593841e-02,\n",
       "        6.54618676e-02, 1.74833938e-01, 2.46101687e-02, 3.34116804e-02,\n",
       "        1.37979281e-05, 3.42017852e-02, 7.84781551e-02, 2.40175471e-01,\n",
       "        8.40380618e-03, 1.92817761e-01, 3.59101305e-01, 6.53455318e-02,\n",
       "        7.52491257e-03, 1.04157820e+00, 9.29263295e-02, 3.44408660e-01,\n",
       "        1.08783106e+00, 8.81037009e-02, 2.46755231e-01, 9.85920348e-01,\n",
       "        2.92178178e-02, 1.51191114e-01, 8.61883431e-02, 1.78675749e-01,\n",
       "        1.91655968e-01, 1.20732169e-01, 1.43213647e-01, 1.35374419e-01,\n",
       "        1.43345030e+00, 4.70104650e-02, 9.82942633e-02, 2.15896534e+00,\n",
       "        1.00093113e-01, 1.12122007e-01, 1.48270371e+00, 4.26472359e-02,\n",
       "        1.87161794e-01, 8.29114079e-04, 5.48294060e-02, 1.86784995e-02,\n",
       "        4.88497416e-01, 4.95758195e-02, 3.52031959e-02, 7.81880675e-01,\n",
       "        6.10711848e-02, 2.43659419e-01, 7.04884305e-01, 1.18587388e-01,\n",
       "        1.02760471e-01, 7.10679246e-01, 1.21290761e-01, 8.36607475e-02,\n",
       "        6.57220252e-01, 1.18692302e-01, 9.91282623e-02, 1.27375394e-01,\n",
       "        2.89681827e-02, 3.56323233e-02, 4.29649473e-01, 1.13281636e-01,\n",
       "        2.16374603e-02, 1.58353835e+00, 1.03741540e-01, 1.35189190e-01,\n",
       "        7.11229733e-01, 9.89134626e-02, 1.21055042e-01, 1.90619180e-01,\n",
       "        8.82360642e-02, 1.04395923e-01, 4.31951007e-04, 4.62428807e-02,\n",
       "        5.55216073e-02, 1.86770465e-02, 1.85352159e-02, 7.23350524e-02,\n",
       "        8.72146599e-02, 7.56343200e-03, 9.55657841e-04, 1.24821964e-01,\n",
       "        2.49729089e-02, 9.35707527e-02, 8.65395309e-02, 2.12971394e-02,\n",
       "        3.56884554e-03, 2.44863172e-01, 6.29962522e-02, 3.94882151e-01,\n",
       "        1.03922540e-01, 4.10429364e-02, 8.85447183e-02, 2.20377082e-01,\n",
       "        3.66129830e-02, 6.45334269e-02, 2.72058362e-01, 3.84253505e-02,\n",
       "        3.36724260e-01, 1.11887848e-01, 9.45031161e-02, 2.51568499e-01,\n",
       "        6.04288710e-01, 5.13352709e-02, 3.90381020e-01, 4.31501876e-04,\n",
       "        4.81674772e-02, 9.43609438e-02, 1.15145469e-01, 1.60647291e-02,\n",
       "        7.60169125e-02, 9.87636605e-02, 1.87374555e-02, 1.79423990e-01,\n",
       "        4.93733824e-02, 9.36410489e-04, 9.94236623e-02, 1.06006394e-01,\n",
       "        1.07814110e-02, 2.14044800e-01, 9.62718852e-02, 1.71644294e-02,\n",
       "        6.86229813e-02, 1.20411991e-01, 1.19116671e-02, 1.43403439e-01,\n",
       "        1.63570546e-01, 2.53509299e-02, 5.87499306e-02, 1.52174975e-01,\n",
       "        2.52696272e-02, 3.55092629e-01, 1.02759625e-01, 5.17626684e-02,\n",
       "        3.17791674e-01, 5.80963726e-02, 8.88505678e-02, 4.55215650e-01]),\n",
       " 'mean_score_time': array([0.00127673, 0.00100064, 0.0017519 , 0.0012635 , 0.00100332,\n",
       "        0.00099504, 0.00128877, 0.00124508, 0.00100207, 0.00149882,\n",
       "        0.00100189, 0.00150031, 0.00125426, 0.00099558, 0.00099546,\n",
       "        0.0017485 , 0.00112772, 0.00137794, 0.00124979, 0.00137734,\n",
       "        0.00125015, 0.00125253, 0.00086421, 0.00147277, 0.00099993,\n",
       "        0.00114781, 0.00187719, 0.00163156, 0.00119728, 0.00201875,\n",
       "        0.00150287, 0.00100029, 0.00103539, 0.00125694, 0.00097847,\n",
       "        0.00127232, 0.0009979 , 0.00049835, 0.00099593, 0.00150079,\n",
       "        0.00076509, 0.00097471, 0.00149971, 0.00125033, 0.00174981,\n",
       "        0.00124961, 0.00124705, 0.00174958, 0.00124943, 0.00099576,\n",
       "        0.00149965, 0.00099969, 0.0012483 , 0.00199515, 0.00150108,\n",
       "        0.00100005, 0.0015077 , 0.00149286, 0.00100046, 0.00162762,\n",
       "        0.00176311, 0.00099832, 0.00124943, 0.0017674 , 0.00099939,\n",
       "        0.00150281, 0.00100017, 0.00099856, 0.00126368, 0.00099969,\n",
       "        0.00123984, 0.00124842, 0.00176847, 0.0017575 , 0.00150353,\n",
       "        0.00174481, 0.00100005, 0.00124872, 0.00174993, 0.00124788,\n",
       "        0.00147349, 0.00200039, 0.00125009, 0.00175023, 0.00174981,\n",
       "        0.0012663 , 0.00162548, 0.00148851, 0.00137657, 0.00124544,\n",
       "        0.00124687, 0.00150585, 0.00149471, 0.00150031, 0.00149703,\n",
       "        0.0015015 , 0.00175345, 0.00149894, 0.00200152, 0.00075001,\n",
       "        0.0010007 , 0.00124902, 0.00101006, 0.00101554, 0.0010184 ,\n",
       "        0.00166243, 0.00104332, 0.00147784, 0.00175059, 0.00175685,\n",
       "        0.00175554, 0.00174987, 0.00150156, 0.00100756, 0.00150323,\n",
       "        0.00163084, 0.00199962, 0.00162655, 0.0012489 , 0.0016495 ,\n",
       "        0.00200003, 0.0012551 , 0.00149989, 0.00197828, 0.00162691,\n",
       "        0.00174767, 0.00200027, 0.00199801, 0.00174993, 0.00250006,\n",
       "        0.00225729, 0.00224394, 0.0010004 , 0.001495  , 0.00103569,\n",
       "        0.00125605, 0.00126553, 0.00149953, 0.00125718, 0.00149995,\n",
       "        0.00125265, 0.00201911, 0.00200021, 0.00200045, 0.00207961,\n",
       "        0.00125068, 0.00200009, 0.00175005, 0.00224912, 0.00224483,\n",
       "        0.00199634, 0.00225073, 0.00199944, 0.00224924, 0.00200009,\n",
       "        0.00175476, 0.00174886, 0.00199842, 0.00200027, 0.00200188,\n",
       "        0.0017516 , 0.00199986, 0.00237679, 0.00227267, 0.00249898,\n",
       "        0.00174987, 0.00215149, 0.00150335, 0.00103366, 0.00125176,\n",
       "        0.00124973, 0.00200701, 0.00099838, 0.00200641, 0.00200069,\n",
       "        0.00225419, 0.00200331, 0.00200099, 0.00200504, 0.0019998 ,\n",
       "        0.00201625, 0.00200045, 0.00175107, 0.00222635, 0.00199825,\n",
       "        0.00225222, 0.00225002, 0.00149012, 0.00200438, 0.00200135,\n",
       "        0.0019998 , 0.00225043, 0.00224984, 0.0018754 , 0.00200045,\n",
       "        0.0027498 , 0.00225151, 0.00174975, 0.00125045, 0.00149846,\n",
       "        0.00100207, 0.00102144, 0.00100178, 0.00148267, 0.00102037,\n",
       "        0.00100172, 0.00100058, 0.00150096, 0.00175792, 0.00174969,\n",
       "        0.00212651, 0.00149935, 0.00174975, 0.00200349, 0.00150228,\n",
       "        0.00175047, 0.00176632, 0.00149983, 0.00150007, 0.00200057,\n",
       "        0.00149953, 0.00150001, 0.00225633, 0.00199687, 0.00200099,\n",
       "        0.00225627, 0.00175011, 0.00180024, 0.00200444, 0.00147241,\n",
       "        0.00212693, 0.00199878, 0.0015018 , 0.0009951 , 0.00150132,\n",
       "        0.00099874, 0.00120836, 0.00151169, 0.00151426, 0.0010069 ,\n",
       "        0.00172496, 0.00155896, 0.00124657, 0.00149935, 0.00137705,\n",
       "        0.00175071, 0.00174785, 0.00125015, 0.00150579, 0.00200176,\n",
       "        0.00175148, 0.00175208, 0.00174516, 0.00100052, 0.00187647,\n",
       "        0.00200927, 0.00200123, 0.00201899, 0.00199741, 0.00175077,\n",
       "        0.00202137, 0.00250667, 0.00200248, 0.00252283]),\n",
       " 'std_score_time': array([4.71468807e-04, 3.76972873e-07, 4.35668253e-04, 4.74466645e-04,\n",
       "        8.02584897e-06, 5.50302929e-06, 4.25061296e-04, 4.35969165e-04,\n",
       "        1.13755898e-05, 5.01038034e-04, 1.20837301e-06, 4.99785010e-04,\n",
       "        4.30611952e-04, 6.76952389e-06, 1.22285433e-05, 4.34530513e-04,\n",
       "        5.28250811e-04, 4.13528847e-04, 4.32912569e-04, 4.15373578e-04,\n",
       "        4.32982138e-04, 4.31489892e-04, 2.07847977e-04, 4.74284593e-04,\n",
       "        7.15255737e-07, 2.55734428e-04, 2.14530788e-04, 4.07944583e-04,\n",
       "        4.07157662e-04, 5.33885627e-05, 5.06726496e-04, 1.67318211e-06,\n",
       "        3.87026044e-05, 4.36929449e-04, 4.03832795e-05, 4.22839719e-04,\n",
       "        1.70681728e-06, 4.98357008e-04, 8.91184124e-06, 4.65745656e-04,\n",
       "        4.41988983e-04, 4.37218251e-05, 5.00381170e-04, 4.33428727e-04,\n",
       "        4.33084589e-04, 4.33153458e-04, 4.26650847e-04, 4.32946981e-04,\n",
       "        4.32155411e-04, 8.82873366e-06, 4.99129423e-04, 2.92001932e-07,\n",
       "        4.33963547e-04, 7.75937103e-06, 5.02827101e-04, 9.15663928e-07,\n",
       "        5.07763860e-04, 4.93020813e-04, 7.97455797e-07, 4.11421755e-04,\n",
       "        4.40823542e-04, 1.61153148e-06, 4.33256762e-04, 4.44031193e-04,\n",
       "        1.37349589e-06, 8.71021359e-04, 7.07308427e-04, 2.63544213e-06,\n",
       "        4.48248689e-04, 1.28392334e-06, 4.40360031e-04, 4.32269860e-04,\n",
       "        3.92348089e-04, 7.72214048e-04, 5.01814683e-04, 4.31638035e-04,\n",
       "        1.65610838e-06, 4.33671189e-04, 4.33153523e-04, 4.33880187e-04,\n",
       "        5.21683234e-04, 1.57586385e-06, 4.32878178e-04, 4.33187892e-04,\n",
       "        4.32946916e-04, 4.23691059e-04, 4.14369583e-04, 4.88506909e-04,\n",
       "        4.14986573e-04, 4.37906409e-04, 4.33644216e-04, 5.05994442e-04,\n",
       "        4.94484081e-04, 5.00142610e-04, 4.97359129e-04, 5.01218896e-04,\n",
       "        4.34921513e-04, 5.00084746e-04, 2.34209093e-06, 4.33016201e-04,\n",
       "        1.77917618e-06, 4.33827333e-04, 1.24258173e-05, 2.03079594e-05,\n",
       "        2.67361217e-05, 3.87601608e-04, 3.45859001e-05, 5.19064529e-04,\n",
       "        4.33120587e-04, 4.33903617e-04, 4.36323632e-04, 4.33394303e-04,\n",
       "        4.98300420e-04, 1.41251690e-05, 5.03922385e-04, 6.51437973e-04,\n",
       "        1.68587394e-07, 4.12391520e-04, 4.33569525e-04, 4.09517988e-04,\n",
       "        3.52625834e-07, 4.30200920e-04, 4.99963789e-04, 3.88137465e-05,\n",
       "        4.14300644e-04, 4.32128376e-04, 4.57831964e-07, 7.06892499e-04,\n",
       "        4.33015741e-04, 4.98772836e-04, 8.34515389e-04, 4.36634333e-04,\n",
       "        3.25596339e-06, 4.93710292e-04, 4.21242517e-05, 4.34030182e-04,\n",
       "        4.24684428e-04, 5.00574569e-04, 4.25815716e-04, 4.97881201e-04,\n",
       "        4.34841012e-04, 3.67336322e-05, 2.66560075e-07, 2.66560075e-07,\n",
       "        1.06295648e-03, 4.32399762e-04, 7.07139839e-04, 4.33084785e-04,\n",
       "        4.32709113e-04, 4.35957108e-04, 8.64965880e-06, 4.34254600e-04,\n",
       "        8.82068192e-07, 8.28846768e-04, 1.64318666e-06, 4.36010482e-04,\n",
       "        4.32262200e-04, 2.47771855e-06, 1.05787750e-06, 7.07396030e-04,\n",
       "        4.33981427e-04, 1.95880851e-06, 4.14936184e-04, 4.21701489e-04,\n",
       "        4.99487506e-04, 4.32981350e-04, 1.47870692e-03, 5.04519417e-04,\n",
       "        2.08056926e-05, 4.31230452e-04, 4.33437973e-04, 7.06534402e-04,\n",
       "        4.65527158e-06, 6.96715029e-04, 2.82855285e-06, 4.31612815e-04,\n",
       "        3.34848688e-06, 7.79431869e-07, 7.07608356e-04, 1.14806654e-06,\n",
       "        6.75051491e-04, 6.84805232e-07, 4.33535899e-04, 4.39288480e-04,\n",
       "        3.47705114e-06, 4.31754439e-04, 4.33153523e-04, 4.97183747e-04,\n",
       "        7.85154047e-06, 2.85294007e-06, 3.90853794e-07, 4.34296637e-04,\n",
       "        4.33119045e-04, 2.15011064e-04, 7.63311891e-07, 8.28521020e-04,\n",
       "        4.32023363e-04, 4.32912634e-04, 4.33222349e-04, 5.01294524e-04,\n",
       "        5.37896832e-06, 4.14668019e-05, 3.74467100e-06, 5.21970459e-04,\n",
       "        3.54119316e-05, 5.60790705e-06, 4.25662305e-07, 5.01158590e-04,\n",
       "        4.40877967e-04, 4.32602854e-04, 2.19932602e-04, 5.00383840e-04,\n",
       "        4.32912897e-04, 2.98440165e-06, 4.97703595e-04, 4.33325981e-04,\n",
       "        3.96519934e-04, 5.00142581e-04, 4.99665773e-04, 1.94424467e-06,\n",
       "        4.99367856e-04, 4.99963775e-04, 4.29628373e-04, 4.06187178e-06,\n",
       "        1.00270533e-06, 4.48131852e-04, 4.33493546e-04, 4.69272009e-04,\n",
       "        8.80919547e-06, 4.74067523e-04, 2.19691304e-04, 7.08320102e-04,\n",
       "        4.97739114e-04, 8.81564585e-06, 4.90861096e-04, 6.02449358e-06,\n",
       "        4.08270754e-04, 4.94323093e-04, 5.12164268e-04, 1.39126741e-05,\n",
       "        4.76960852e-04, 5.46115681e-04, 4.34940790e-04, 4.99427667e-04,\n",
       "        6.52637979e-04, 4.33465238e-04, 4.33606286e-04, 4.32568496e-04,\n",
       "        5.06174642e-04, 3.94292722e-06, 8.27286315e-04, 4.34274038e-04,\n",
       "        4.30203695e-04, 4.91512492e-07, 5.47226800e-04, 7.07574619e-04,\n",
       "        1.57586385e-06, 4.57084467e-05, 3.12853419e-06, 4.33773805e-04,\n",
       "        3.72701605e-05, 4.93677992e-04, 7.07820855e-04, 8.53857014e-04]),\n",
       " 'param_activation': masked_array(data=['identity', 'identity', 'identity', 'identity',\n",
       "                    'identity', 'identity', 'identity', 'identity',\n",
       "                    'identity', 'identity', 'identity', 'identity',\n",
       "                    'identity', 'identity', 'identity', 'identity',\n",
       "                    'identity', 'identity', 'identity', 'identity',\n",
       "                    'identity', 'identity', 'identity', 'identity',\n",
       "                    'identity', 'identity', 'identity', 'identity',\n",
       "                    'identity', 'identity', 'identity', 'identity',\n",
       "                    'identity', 'identity', 'identity', 'identity',\n",
       "                    'identity', 'identity', 'identity', 'identity',\n",
       "                    'identity', 'identity', 'identity', 'identity',\n",
       "                    'identity', 'identity', 'identity', 'identity',\n",
       "                    'identity', 'identity', 'identity', 'identity',\n",
       "                    'identity', 'identity', 'identity', 'identity',\n",
       "                    'identity', 'identity', 'identity', 'identity',\n",
       "                    'identity', 'identity', 'identity', 'identity',\n",
       "                    'identity', 'identity', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_alpha': masked_array(data=[0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_hidden_layer_sizes': masked_array(data=[1, 1, 1, 11, 11, 11, 21, 21, 21, 31, 31, 31, 41, 41,\n",
       "                    41, 51, 51, 51, 61, 61, 61, 71, 71, 71, 81, 81, 81, 91,\n",
       "                    91, 91, 101, 101, 101, 1, 1, 1, 11, 11, 11, 21, 21, 21,\n",
       "                    31, 31, 31, 41, 41, 41, 51, 51, 51, 61, 61, 61, 71, 71,\n",
       "                    71, 81, 81, 81, 91, 91, 91, 101, 101, 101, 1, 1, 1, 11,\n",
       "                    11, 11, 21, 21, 21, 31, 31, 31, 41, 41, 41, 51, 51, 51,\n",
       "                    61, 61, 61, 71, 71, 71, 81, 81, 81, 91, 91, 91, 101,\n",
       "                    101, 101, 1, 1, 1, 11, 11, 11, 21, 21, 21, 31, 31, 31,\n",
       "                    41, 41, 41, 51, 51, 51, 61, 61, 61, 71, 71, 71, 81, 81,\n",
       "                    81, 91, 91, 91, 101, 101, 101, 1, 1, 1, 11, 11, 11, 21,\n",
       "                    21, 21, 31, 31, 31, 41, 41, 41, 51, 51, 51, 61, 61, 61,\n",
       "                    71, 71, 71, 81, 81, 81, 91, 91, 91, 101, 101, 101, 1,\n",
       "                    1, 1, 11, 11, 11, 21, 21, 21, 31, 31, 31, 41, 41, 41,\n",
       "                    51, 51, 51, 61, 61, 61, 71, 71, 71, 81, 81, 81, 91, 91,\n",
       "                    91, 101, 101, 101, 1, 1, 1, 11, 11, 11, 21, 21, 21, 31,\n",
       "                    31, 31, 41, 41, 41, 51, 51, 51, 61, 61, 61, 71, 71, 71,\n",
       "                    81, 81, 81, 91, 91, 91, 101, 101, 101, 1, 1, 1, 11, 11,\n",
       "                    11, 21, 21, 21, 31, 31, 31, 41, 41, 41, 51, 51, 51, 61,\n",
       "                    61, 61, 71, 71, 71, 81, 81, 81, 91, 91, 91, 101, 101,\n",
       "                    101],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_iter': masked_array(data=[5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_solver': masked_array(data=['lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'}],\n",
       " 'split0_test_score': array([0.86666667, 0.46666667, 0.73333333, 0.86666667, 0.53333333,\n",
       "        0.53333333, 0.86666667, 0.8       , 0.48333333, 0.53333333,\n",
       "        0.76666667, 0.46666667, 0.86666667, 0.61666667, 0.55      ,\n",
       "        0.86666667, 0.73333333, 0.86666667, 0.86666667, 0.78333333,\n",
       "        0.9       , 0.86666667, 0.76666667, 0.9       , 0.86666667,\n",
       "        0.76666667, 0.9       , 0.86666667, 0.73333333, 0.3       ,\n",
       "        0.86666667, 0.75      , 0.91666667, 0.86666667, 0.75      ,\n",
       "        0.8       , 0.86666667, 0.53333333, 0.53333333, 0.86666667,\n",
       "        0.58333333, 0.58333333, 0.53333333, 0.71666667, 0.31666667,\n",
       "        0.86666667, 0.56666667, 0.46666667, 0.53333333, 0.66666667,\n",
       "        0.6       , 0.86666667, 0.73333333, 0.9       , 0.86666667,\n",
       "        0.81666667, 0.9       , 0.85      , 0.7       , 0.65      ,\n",
       "        0.86666667, 0.53333333, 0.91666667, 0.86666667, 0.78333333,\n",
       "        0.9       , 0.53333333, 0.7       , 0.53333333, 0.51666667,\n",
       "        0.68333333, 0.86666667, 0.8       , 0.75      , 0.85      ,\n",
       "        0.86666667, 0.51666667, 0.86666667, 0.76666667, 0.53333333,\n",
       "        0.85      , 0.73333333, 0.76666667, 0.81666667, 0.76666667,\n",
       "        0.71666667, 0.81666667, 0.73333333, 0.71666667, 0.8       ,\n",
       "        0.76666667, 0.75      , 0.83333333, 0.81666667, 0.76666667,\n",
       "        0.81666667, 0.78333333, 0.75      , 0.85      , 0.53333333,\n",
       "        0.46666667, 0.53333333, 0.81666667, 0.7       , 0.91666667,\n",
       "        0.88333333, 0.53333333, 0.86666667, 0.8       , 0.71666667,\n",
       "        0.83333333, 0.73333333, 0.71666667, 0.81666667, 0.78333333,\n",
       "        0.75      , 0.81666667, 0.75      , 0.71666667, 0.85      ,\n",
       "        0.83333333, 0.76666667, 0.83333333, 0.8       , 0.71666667,\n",
       "        0.8       , 0.85      , 0.75      , 0.85      , 0.85      ,\n",
       "        0.75      , 0.83333333, 0.51666667, 0.53333333, 0.53333333,\n",
       "        0.56666667, 0.48333333, 0.53333333, 0.78333333, 0.75      ,\n",
       "        0.9       , 0.73333333, 0.73333333, 0.61666667, 0.83333333,\n",
       "        0.68333333, 0.83333333, 0.7       , 0.75      , 0.88333333,\n",
       "        0.76666667, 0.73333333, 0.8       , 0.81666667, 0.76666667,\n",
       "        0.91666667, 0.76666667, 0.76666667, 0.86666667, 0.78333333,\n",
       "        0.7       , 0.85      , 0.71666667, 0.75      , 0.85      ,\n",
       "        0.53333333, 0.68333333, 0.53333333, 0.78333333, 0.75      ,\n",
       "        0.91666667, 0.76666667, 0.66666667, 0.63333333, 0.78333333,\n",
       "        0.73333333, 0.85      , 0.68333333, 0.68333333, 0.85      ,\n",
       "        0.81666667, 0.7       , 0.85      , 0.7       , 0.73333333,\n",
       "        0.86666667, 0.8       , 0.71666667, 0.85      , 0.76666667,\n",
       "        0.7       , 0.81666667, 0.68333333, 0.71666667, 0.83333333,\n",
       "        0.68333333, 0.71666667, 0.83333333, 0.53333333, 0.53333333,\n",
       "        0.53333333, 0.9       , 0.78333333, 0.46666667, 0.93333333,\n",
       "        0.75      , 0.53333333, 0.86666667, 0.63333333, 0.91666667,\n",
       "        0.85      , 0.53333333, 0.5       , 0.81666667, 0.75      ,\n",
       "        0.76666667, 0.85      , 0.73333333, 0.88333333, 0.53333333,\n",
       "        0.75      , 0.86666667, 0.85      , 0.6       , 0.81666667,\n",
       "        0.88333333, 0.66666667, 0.63333333, 0.75      , 0.75      ,\n",
       "        0.88333333, 0.53333333, 0.53333333, 0.53333333, 0.88333333,\n",
       "        0.61666667, 0.88333333, 0.85      , 0.73333333, 0.83333333,\n",
       "        0.91666667, 0.61666667, 0.58333333, 0.86666667, 0.61666667,\n",
       "        0.61666667, 0.86666667, 0.75      , 0.61666667, 0.86666667,\n",
       "        0.68333333, 0.55      , 0.53333333, 0.73333333, 0.86666667,\n",
       "        0.83333333, 0.73333333, 0.9       , 0.86666667, 0.7       ,\n",
       "        0.81666667, 0.8       , 0.7       , 0.78333333]),\n",
       " 'split1_test_score': array([0.88135593, 0.3220339 , 0.6440678 , 0.88135593, 0.77966102,\n",
       "        0.54237288, 0.88135593, 0.6779661 , 0.54237288, 0.88135593,\n",
       "        0.66101695, 0.42372881, 0.88135593, 0.62711864, 0.86440678,\n",
       "        0.88135593, 0.74576271, 0.61016949, 0.88135593, 0.71186441,\n",
       "        0.89830508, 0.54237288, 0.6779661 , 0.88135593, 0.88135593,\n",
       "        0.66101695, 0.38983051, 0.88135593, 0.69491525, 0.91525424,\n",
       "        0.88135593, 0.71186441, 0.77966102, 0.88135593, 0.52542373,\n",
       "        0.66101695, 0.88135593, 0.45762712, 0.54237288, 0.88135593,\n",
       "        0.69491525, 0.6440678 , 0.54237288, 0.66101695, 0.88135593,\n",
       "        0.88135593, 0.66101695, 0.86440678, 0.88135593, 0.69491525,\n",
       "        0.89830508, 0.88135593, 0.6779661 , 0.88135593, 0.88135593,\n",
       "        0.61016949, 0.86440678, 0.88135593, 0.62711864, 0.86440678,\n",
       "        0.88135593, 0.57627119, 0.86440678, 0.88135593, 0.6779661 ,\n",
       "        0.74576271, 0.83050847, 0.54237288, 0.88135593, 0.54237288,\n",
       "        0.71186441, 0.57627119, 0.81355932, 0.69491525, 0.84745763,\n",
       "        0.72881356, 0.54237288, 0.83050847, 0.79661017, 0.71186441,\n",
       "        0.81355932, 0.69491525, 0.72881356, 0.84745763, 0.74576271,\n",
       "        0.71186441, 0.81355932, 0.71186441, 0.71186441, 0.81355932,\n",
       "        0.79661017, 0.74576271, 0.83050847, 0.72881356, 0.74576271,\n",
       "        0.83050847, 0.76271186, 0.74576271, 0.83050847, 0.54237288,\n",
       "        0.45762712, 0.45762712, 0.66101695, 0.54237288, 0.84745763,\n",
       "        0.74576271, 0.69491525, 0.79661017, 0.83050847, 0.71186441,\n",
       "        0.84745763, 0.72881356, 0.74576271, 0.83050847, 0.6779661 ,\n",
       "        0.74576271, 0.83050847, 0.74576271, 0.74576271, 0.84745763,\n",
       "        0.79661017, 0.71186441, 0.83050847, 0.77966102, 0.74576271,\n",
       "        0.83050847, 0.81355932, 0.74576271, 0.79661017, 0.77966102,\n",
       "        0.74576271, 0.83050847, 0.54237288, 0.54237288, 0.45762712,\n",
       "        0.77966102, 0.57627119, 0.81355932, 0.62711864, 0.66101695,\n",
       "        0.79661017, 0.66101695, 0.71186441, 0.79661017, 0.66101695,\n",
       "        0.69491525, 0.81355932, 0.83050847, 0.71186441, 0.81355932,\n",
       "        0.69491525, 0.66101695, 0.83050847, 0.84745763, 0.6440678 ,\n",
       "        0.81355932, 0.76271186, 0.6440678 , 0.81355932, 0.83050847,\n",
       "        0.71186441, 0.84745763, 0.79661017, 0.72881356, 0.79661017,\n",
       "        0.54237288, 0.6440678 , 0.54237288, 0.83050847, 0.54237288,\n",
       "        0.86440678, 0.61016949, 0.72881356, 0.79661017, 0.76271186,\n",
       "        0.59322034, 0.83050847, 0.81355932, 0.66101695, 0.79661017,\n",
       "        0.77966102, 0.47457627, 0.84745763, 0.79661017, 0.71186441,\n",
       "        0.83050847, 0.79661017, 0.52542373, 0.84745763, 0.77966102,\n",
       "        0.71186441, 0.83050847, 0.71186441, 0.57627119, 0.84745763,\n",
       "        0.81355932, 0.61016949, 0.81355932, 0.54237288, 0.54237288,\n",
       "        0.45762712, 0.83050847, 0.6440678 , 0.83050847, 0.84745763,\n",
       "        0.71186441, 0.3559322 , 0.84745763, 0.71186441, 0.61016949,\n",
       "        0.86440678, 0.6779661 , 0.69491525, 0.84745763, 0.66101695,\n",
       "        0.61016949, 0.81355932, 0.66101695, 0.52542373, 0.84745763,\n",
       "        0.69491525, 0.69491525, 0.79661017, 0.61016949, 0.79661017,\n",
       "        0.79661017, 0.62711864, 0.84745763, 0.84745763, 0.71186441,\n",
       "        0.81355932, 0.54237288, 0.54237288, 0.55932203, 0.83050847,\n",
       "        0.6779661 , 0.40677966, 0.84745763, 0.69491525, 0.83050847,\n",
       "        0.88135593, 0.62711864, 0.81355932, 0.81355932, 0.72881356,\n",
       "        0.61016949, 0.84745763, 0.72881356, 0.54237288, 0.88135593,\n",
       "        0.66101695, 0.84745763, 0.83050847, 0.47457627, 0.81355932,\n",
       "        0.83050847, 0.71186441, 0.79661017, 0.86440678, 0.71186441,\n",
       "        0.74576271, 0.83050847, 0.62711864, 0.6440678 ]),\n",
       " 'split2_test_score': array([0.50847458, 0.62711864, 0.45762712, 0.86440678, 0.74576271,\n",
       "        0.88135593, 0.86440678, 0.74576271, 0.88135593, 0.86440678,\n",
       "        0.66101695, 0.91525424, 0.86440678, 0.66101695, 0.89830508,\n",
       "        0.86440678, 0.62711864, 0.84745763, 0.86440678, 0.71186441,\n",
       "        0.83050847, 0.86440678, 0.47457627, 0.89830508, 0.86440678,\n",
       "        0.6440678 , 0.52542373, 0.86440678, 0.6779661 , 0.84745763,\n",
       "        0.86440678, 0.72881356, 0.81355932, 0.71186441, 0.54237288,\n",
       "        0.54237288, 0.54237288, 0.59322034, 0.3559322 , 0.86440678,\n",
       "        0.59322034, 0.88135593, 0.86440678, 0.6779661 , 0.83050847,\n",
       "        0.86440678, 0.83050847, 0.88135593, 0.86440678, 0.47457627,\n",
       "        0.54237288, 0.86440678, 0.76271186, 0.44067797, 0.86440678,\n",
       "        0.61016949, 0.89830508, 0.86440678, 0.6779661 , 0.89830508,\n",
       "        0.86440678, 0.69491525, 0.55932203, 0.86440678, 0.69491525,\n",
       "        0.86440678, 0.54237288, 0.45762712, 0.88135593, 0.79661017,\n",
       "        0.54237288, 0.54237288, 0.6779661 , 0.6779661 , 0.88135593,\n",
       "        0.74576271, 0.66101695, 0.88135593, 0.74576271, 0.69491525,\n",
       "        0.84745763, 0.71186441, 0.69491525, 0.86440678, 0.86440678,\n",
       "        0.71186441, 0.84745763, 0.84745763, 0.71186441, 0.84745763,\n",
       "        0.71186441, 0.72881356, 0.83050847, 0.66101695, 0.71186441,\n",
       "        0.84745763, 0.84745763, 0.6779661 , 0.84745763, 0.54237288,\n",
       "        0.45762712, 0.54237288, 0.54237288, 0.66101695, 0.86440678,\n",
       "        0.83050847, 0.59322034, 0.86440678, 0.77966102, 0.6779661 ,\n",
       "        0.84745763, 0.81355932, 0.71186441, 0.86440678, 0.77966102,\n",
       "        0.71186441, 0.84745763, 0.77966102, 0.72881356, 0.84745763,\n",
       "        0.76271186, 0.71186441, 0.84745763, 0.76271186, 0.71186441,\n",
       "        0.84745763, 0.83050847, 0.74576271, 0.84745763, 0.69491525,\n",
       "        0.72881356, 0.83050847, 0.54237288, 0.45762712, 0.54237288,\n",
       "        0.54237288, 0.54237288, 0.89830508, 0.66101695, 0.54237288,\n",
       "        0.86440678, 0.6779661 , 0.71186441, 0.83050847, 0.72881356,\n",
       "        0.61016949, 0.86440678, 0.83050847, 0.6779661 , 0.89830508,\n",
       "        0.81355932, 0.69491525, 0.86440678, 0.81355932, 0.76271186,\n",
       "        0.86440678, 0.79661017, 0.76271186, 0.84745763, 0.6779661 ,\n",
       "        0.6779661 , 0.89830508, 0.83050847, 0.72881356, 0.86440678,\n",
       "        0.54237288, 0.45762712, 0.54237288, 0.54237288, 0.54237288,\n",
       "        0.81355932, 0.81355932, 0.6779661 , 0.84745763, 0.79661017,\n",
       "        0.55932203, 0.83050847, 0.69491525, 0.61016949, 0.84745763,\n",
       "        0.86440678, 0.66101695, 0.84745763, 0.76271186, 0.72881356,\n",
       "        0.86440678, 0.79661017, 0.62711864, 0.88135593, 0.72881356,\n",
       "        0.72881356, 0.84745763, 0.77966102, 0.69491525, 0.89830508,\n",
       "        0.77966102, 0.77966102, 0.86440678, 0.54237288, 0.45762712,\n",
       "        0.54237288, 0.89830508, 0.74576271, 0.57627119, 0.86440678,\n",
       "        0.69491525, 0.54237288, 0.89830508, 0.69491525, 0.54237288,\n",
       "        0.54237288, 0.57627119, 0.54237288, 0.89830508, 0.69491525,\n",
       "        0.54237288, 0.86440678, 0.61016949, 0.84745763, 0.84745763,\n",
       "        0.71186441, 0.54237288, 0.54237288, 0.72881356, 0.54237288,\n",
       "        0.86440678, 0.69491525, 0.84745763, 0.86440678, 0.6779661 ,\n",
       "        0.86440678, 0.54237288, 0.54237288, 0.54237288, 0.54237288,\n",
       "        0.45762712, 0.84745763, 0.89830508, 0.45762712, 0.66101695,\n",
       "        0.88135593, 0.49152542, 0.91525424, 0.84745763, 0.6440678 ,\n",
       "        0.88135593, 0.88135593, 0.74576271, 0.89830508, 0.84745763,\n",
       "        0.6779661 , 0.89830508, 0.54237288, 0.6440678 , 0.86440678,\n",
       "        0.88135593, 0.69491525, 0.86440678, 0.84745763, 0.61016949,\n",
       "        0.88135593, 0.86440678, 0.71186441, 0.50847458]),\n",
       " 'split3_test_score': array([0.81355932, 0.6440678 , 0.6440678 , 0.81355932, 0.76271186,\n",
       "        0.81355932, 0.81355932, 0.76271186, 0.6440678 , 0.81355932,\n",
       "        0.72881356, 0.62711864, 0.81355932, 0.71186441, 0.83050847,\n",
       "        0.81355932, 0.72881356, 0.81355932, 0.81355932, 0.6440678 ,\n",
       "        0.79661017, 0.81355932, 0.71186441, 0.81355932, 0.81355932,\n",
       "        0.59322034, 0.81355932, 0.81355932, 0.66101695, 0.79661017,\n",
       "        0.81355932, 0.76271186, 0.42372881, 0.81355932, 0.40677966,\n",
       "        0.42372881, 0.81355932, 0.6779661 , 0.62711864, 0.81355932,\n",
       "        0.57627119, 0.62711864, 0.81355932, 0.6779661 , 0.81355932,\n",
       "        0.81355932, 0.6779661 , 0.81355932, 0.81355932, 0.61016949,\n",
       "        0.81355932, 0.81355932, 0.66101695, 0.37288136, 0.81355932,\n",
       "        0.66101695, 0.81355932, 0.81355932, 0.6779661 , 0.59322034,\n",
       "        0.81355932, 0.54237288, 0.81355932, 0.81355932, 0.69491525,\n",
       "        0.83050847, 0.54237288, 0.54237288, 0.54237288, 0.81355932,\n",
       "        0.6440678 , 0.79661017, 0.81355932, 0.72881356, 0.77966102,\n",
       "        0.79661017, 0.71186441, 0.77966102, 0.77966102, 0.71186441,\n",
       "        0.79661017, 0.81355932, 0.72881356, 0.77966102, 0.76271186,\n",
       "        0.72881356, 0.77966102, 0.79661017, 0.71186441, 0.79661017,\n",
       "        0.71186441, 0.71186441, 0.77966102, 0.79661017, 0.71186441,\n",
       "        0.77966102, 0.79661017, 0.71186441, 0.77966102, 0.54237288,\n",
       "        0.45762712, 0.54237288, 0.77966102, 0.54237288, 0.79661017,\n",
       "        0.74576271, 0.76271186, 0.79661017, 0.71186441, 0.71186441,\n",
       "        0.81355932, 0.79661017, 0.71186441, 0.79661017, 0.77966102,\n",
       "        0.71186441, 0.77966102, 0.74576271, 0.72881356, 0.76271186,\n",
       "        0.76271186, 0.71186441, 0.79661017, 0.77966102, 0.71186441,\n",
       "        0.79661017, 0.72881356, 0.72881356, 0.77966102, 0.76271186,\n",
       "        0.71186441, 0.76271186, 0.54237288, 0.45762712, 0.45762712,\n",
       "        0.79661017, 0.71186441, 0.54237288, 0.72881356, 0.54237288,\n",
       "        0.81355932, 0.76271186, 0.71186441, 0.79661017, 0.66101695,\n",
       "        0.76271186, 0.83050847, 0.77966102, 0.74576271, 0.77966102,\n",
       "        0.77966102, 0.76271186, 0.77966102, 0.77966102, 0.72881356,\n",
       "        0.77966102, 0.77966102, 0.72881356, 0.81355932, 0.6779661 ,\n",
       "        0.6779661 , 0.76271186, 0.66101695, 0.72881356, 0.77966102,\n",
       "        0.54237288, 0.54237288, 0.50847458, 0.79661017, 0.54237288,\n",
       "        0.79661017, 0.76271186, 0.54237288, 0.77966102, 0.79661017,\n",
       "        0.71186441, 0.79661017, 0.77966102, 0.59322034, 0.76271186,\n",
       "        0.77966102, 0.6779661 , 0.79661017, 0.79661017, 0.69491525,\n",
       "        0.77966102, 0.76271186, 0.72881356, 0.77966102, 0.72881356,\n",
       "        0.66101695, 0.77966102, 0.76271186, 0.74576271, 0.77966102,\n",
       "        0.76271186, 0.72881356, 0.76271186, 0.54237288, 0.54237288,\n",
       "        0.45762712, 0.81355932, 0.69491525, 0.54237288, 0.52542373,\n",
       "        0.52542373, 0.54237288, 0.81355932, 0.54237288, 0.81355932,\n",
       "        0.77966102, 0.71186441, 0.66101695, 0.79661017, 0.62711864,\n",
       "        0.77966102, 0.81355932, 0.6779661 , 0.69491525, 0.74576271,\n",
       "        0.6779661 , 0.57627119, 0.74576271, 0.72881356, 0.79661017,\n",
       "        0.76271186, 0.76271186, 0.6779661 , 0.77966102, 0.74576271,\n",
       "        0.79661017, 0.54237288, 0.45762712, 0.54237288, 0.81355932,\n",
       "        0.6779661 , 0.81355932, 0.81355932, 0.52542373, 0.69491525,\n",
       "        0.79661017, 0.61016949, 0.3559322 , 0.79661017, 0.72881356,\n",
       "        0.54237288, 0.81355932, 0.54237288, 0.33898305, 0.79661017,\n",
       "        0.6779661 , 0.6779661 , 0.81355932, 0.6779661 , 0.79661017,\n",
       "        0.79661017, 0.74576271, 0.54237288, 0.79661017, 0.72881356,\n",
       "        0.79661017, 0.81355932, 0.72881356, 0.72881356]),\n",
       " 'mean_test_score': array([0.76751412, 0.51497175, 0.61977401, 0.85649718, 0.70536723,\n",
       "        0.69265537, 0.85649718, 0.74661017, 0.63778249, 0.77316384,\n",
       "        0.70437853, 0.60819209, 0.85649718, 0.65416667, 0.78580508,\n",
       "        0.85649718, 0.70875706, 0.78446328, 0.85649718, 0.71278249,\n",
       "        0.85635593, 0.77175141, 0.65776836, 0.87330508, 0.85649718,\n",
       "        0.66624294, 0.65720339, 0.85649718, 0.69180791, 0.71483051,\n",
       "        0.85649718, 0.73834746, 0.73340395, 0.81836158, 0.55614407,\n",
       "        0.60677966, 0.7759887 , 0.56553672, 0.51468927, 0.85649718,\n",
       "        0.61193503, 0.68396893, 0.68841808, 0.68340395, 0.7105226 ,\n",
       "        0.85649718, 0.68403955, 0.75649718, 0.77316384, 0.61158192,\n",
       "        0.71355932, 0.85649718, 0.70875706, 0.64872881, 0.85649718,\n",
       "        0.67450565, 0.8690678 , 0.85233051, 0.67076271, 0.75148305,\n",
       "        0.85649718, 0.58672316, 0.7884887 , 0.85649718, 0.71278249,\n",
       "        0.83516949, 0.61214689, 0.56059322, 0.70960452, 0.66730226,\n",
       "        0.6454096 , 0.69548023, 0.77627119, 0.71292373, 0.83961864,\n",
       "        0.78446328, 0.60798023, 0.83954802, 0.77217514, 0.66299435,\n",
       "        0.82690678, 0.73841808, 0.72980226, 0.82704802, 0.78488701,\n",
       "        0.71730226, 0.81433616, 0.77231638, 0.71306497, 0.81440678,\n",
       "        0.74675141, 0.73411017, 0.81850282, 0.75077684, 0.73403955,\n",
       "        0.81857345, 0.79752825, 0.72139831, 0.82690678, 0.54011299,\n",
       "        0.45988701, 0.51892655, 0.69992938, 0.61144068, 0.85628531,\n",
       "        0.80134181, 0.6460452 , 0.83107345, 0.78050847, 0.7045904 ,\n",
       "        0.83545198, 0.7680791 , 0.72153955, 0.82704802, 0.75515537,\n",
       "        0.72987288, 0.81857345, 0.75529661, 0.73001412, 0.82690678,\n",
       "        0.78884181, 0.72556497, 0.8269774 , 0.78050847, 0.72153955,\n",
       "        0.81864407, 0.80572034, 0.74258475, 0.8184322 , 0.77182203,\n",
       "        0.73411017, 0.81426554, 0.53594633, 0.49774011, 0.49774011,\n",
       "        0.67132768, 0.57846045, 0.69689266, 0.70007062, 0.62394068,\n",
       "        0.84364407, 0.70875706, 0.71723164, 0.76009887, 0.7210452 ,\n",
       "        0.68778249, 0.83545198, 0.78516949, 0.72139831, 0.84371469,\n",
       "        0.76370056, 0.71299435, 0.81864407, 0.81433616, 0.72556497,\n",
       "        0.84357345, 0.77641243, 0.72556497, 0.83531073, 0.7424435 ,\n",
       "        0.69194915, 0.83961864, 0.75120056, 0.73411017, 0.82266949,\n",
       "        0.54011299, 0.58185028, 0.53163842, 0.73820621, 0.59427966,\n",
       "        0.84781073, 0.73827684, 0.6539548 , 0.76426554, 0.78481638,\n",
       "        0.64943503, 0.82690678, 0.74286723, 0.63693503, 0.81419492,\n",
       "        0.81009887, 0.62838983, 0.83538136, 0.76398305, 0.71723164,\n",
       "        0.83531073, 0.78898305, 0.64950565, 0.83961864, 0.7509887 ,\n",
       "        0.70042373, 0.81857345, 0.73439266, 0.68340395, 0.83968927,\n",
       "        0.75981638, 0.70882768, 0.81850282, 0.54011299, 0.51892655,\n",
       "        0.49774011, 0.86059322, 0.71701977, 0.6039548 , 0.79265537,\n",
       "        0.67055085, 0.49350282, 0.85649718, 0.64562147, 0.72069209,\n",
       "        0.75911017, 0.62485876, 0.59957627, 0.83975989, 0.68326271,\n",
       "        0.67471751, 0.83538136, 0.67062147, 0.73778249, 0.74350282,\n",
       "        0.70868644, 0.6700565 , 0.73368644, 0.66694915, 0.73806497,\n",
       "        0.82676554, 0.68785311, 0.75155367, 0.81038136, 0.72139831,\n",
       "        0.8394774 , 0.54011299, 0.51892655, 0.54435028, 0.7674435 ,\n",
       "        0.6075565 , 0.73778249, 0.85233051, 0.60282486, 0.7549435 ,\n",
       "        0.86899718, 0.58637006, 0.66701977, 0.83107345, 0.6795904 ,\n",
       "        0.66264124, 0.85225989, 0.69173729, 0.59908192, 0.8480226 ,\n",
       "        0.67507062, 0.7434322 , 0.6799435 , 0.63248588, 0.83531073,\n",
       "        0.83545198, 0.72146893, 0.77584746, 0.84378531, 0.68771186,\n",
       "        0.81009887, 0.82711864, 0.69194915, 0.66617232]),\n",
       " 'std_test_score': array([0.15166808, 0.13114983, 0.10045859, 0.02563005, 0.10004428,\n",
       "        0.15667961, 0.02563005, 0.04422235, 0.1519252 , 0.14069583,\n",
       "        0.04537989, 0.19280918, 0.02563005, 0.03712749, 0.13823613,\n",
       "        0.02563005, 0.04754079, 0.10240921, 0.02563005, 0.04924636,\n",
       "        0.04444711, 0.13412339, 0.11039986, 0.03525617, 0.02563005,\n",
       "        0.06311948, 0.20751597, 0.02563005, 0.02680343, 0.24317272,\n",
       "        0.02563005, 0.01950419, 0.1857744 , 0.06645747, 0.12351441,\n",
       "        0.13958119, 0.13721575, 0.08075935, 0.0986891 , 0.02563005,\n",
       "        0.04828541, 0.11609609, 0.15166808, 0.02041278, 0.22875735,\n",
       "        0.02563005, 0.09459977, 0.16918334, 0.14069583, 0.08478107,\n",
       "        0.14691112, 0.02563005, 0.0410558 , 0.24322292, 0.02563005,\n",
       "        0.08466106, 0.03505188, 0.02498473, 0.02675538, 0.13196058,\n",
       "        0.02563005, 0.06448293, 0.13723979, 0.02563005, 0.04131609,\n",
       "        0.05716885, 0.12612512, 0.08760741, 0.17178115, 0.13821188,\n",
       "        0.06417324, 0.13891069, 0.05702578, 0.02816681, 0.03710169,\n",
       "        0.05361802, 0.0810051 , 0.03921571, 0.01858137, 0.07517893,\n",
       "        0.0226477 , 0.04546882, 0.02538721, 0.03227046, 0.04657742,\n",
       "        0.00692919, 0.02400746, 0.05341   , 0.00207944, 0.02010815,\n",
       "        0.03645792, 0.01509302, 0.02245496, 0.06119924, 0.02337432,\n",
       "        0.02497275, 0.03125485, 0.02910727, 0.02828767, 0.00391424,\n",
       "        0.00391424, 0.03558313, 0.10761384, 0.07042954, 0.04286874,\n",
       "        0.05863313, 0.0887325 , 0.03447254, 0.04356789, 0.01549606,\n",
       "        0.01389288, 0.03752174, 0.014122  , 0.02470773, 0.04459045,\n",
       "        0.01807068, 0.02497275, 0.01417276, 0.01035683, 0.03707748,\n",
       "        0.02917786, 0.02373007, 0.01867133, 0.01321056, 0.014122  ,\n",
       "        0.02123723, 0.04623646, 0.00813681, 0.03089663, 0.05516088,\n",
       "        0.01509302, 0.02978686, 0.01113112, 0.04024011, 0.04024011,\n",
       "        0.11727647, 0.08389411, 0.16186884, 0.06042768, 0.08742456,\n",
       "        0.0410011 , 0.0410558 , 0.00929632, 0.08395901, 0.0704907 ,\n",
       "        0.05410374, 0.018348  , 0.0533747 , 0.02910727, 0.04889266,\n",
       "        0.04324595, 0.0384513 , 0.03202448, 0.02400746, 0.04929905,\n",
       "        0.05187074, 0.01323997, 0.04929905, 0.022787  , 0.06659971,\n",
       "        0.01459867, 0.04880567, 0.06647829, 0.009174  , 0.03541813,\n",
       "        0.00391424, 0.08826054, 0.01387348, 0.11436551, 0.08990518,\n",
       "        0.04693406, 0.07661918, 0.06854286, 0.07960427, 0.01386539,\n",
       "        0.0745265 , 0.0192167 , 0.05521511, 0.03660638, 0.03656549,\n",
       "        0.03480449, 0.08987347, 0.0224086 , 0.03944776, 0.01516768,\n",
       "        0.03517715, 0.01523068, 0.08169738, 0.03710169, 0.02264605,\n",
       "        0.02494968, 0.02497275, 0.03861923, 0.06443012, 0.04224911,\n",
       "        0.04780208, 0.06166783, 0.03696007, 0.00391424, 0.03558313,\n",
       "        0.04024011, 0.03902678, 0.05252201, 0.13668697, 0.15760282,\n",
       "        0.08613142, 0.07951212, 0.0307274 , 0.06638764, 0.15086695,\n",
       "        0.12917597, 0.07267742, 0.08070338, 0.03834707, 0.04537807,\n",
       "        0.10142649, 0.0224086 , 0.0439699 , 0.14155169, 0.12824734,\n",
       "        0.02669407, 0.12685849, 0.116442  , 0.0619688 , 0.11327919,\n",
       "        0.04906373, 0.04947537, 0.09719351, 0.04712495, 0.02910727,\n",
       "        0.03554632, 0.00391424, 0.03558313, 0.00939876, 0.13246801,\n",
       "        0.09010666, 0.19269061, 0.03019124, 0.11465865, 0.0779112 ,\n",
       "        0.04420898, 0.0550914 , 0.2161441 , 0.02752172, 0.05016745,\n",
       "        0.12958351, 0.02537189, 0.08659917, 0.20044392, 0.03202448,\n",
       "        0.00840455, 0.13830105, 0.14225261, 0.09657671, 0.03082463,\n",
       "        0.03018603, 0.01954672, 0.13981959, 0.02823022, 0.04592524,\n",
       "        0.04858444, 0.02408927, 0.03880532, 0.10369163]),\n",
       " 'rank_test_score': array([102, 258, 227,   6, 172, 180,   6, 120, 221,  95, 174, 232,   6,\n",
       "        213,  83,   6, 168,  87,   6, 163,  20, 100, 211,   1,   6, 207,\n",
       "        212,   6, 183, 158,   6, 127, 139,  67, 247, 235,  93, 245, 259,\n",
       "          6, 229, 190, 185, 191, 165,   6, 189, 110,  95, 230, 159,   6,\n",
       "        168, 217,   6, 198,   2,  23, 200, 115,   6, 241,  82,   6, 164,\n",
       "         46, 228, 246, 166, 204, 220, 179,  92, 162,  33,  87, 233,  36,\n",
       "         98, 209,  53, 126, 142,  50,  85, 154,  69,  97, 160,  68, 119,\n",
       "        134,  64, 118, 137,  61,  78, 149,  53, 249, 264, 256, 177, 231,\n",
       "         21,  77, 218,  47,  90, 173,  38, 101, 146,  50, 112, 141,  61,\n",
       "        111, 140,  53,  81, 143,  52,  89, 146,  60,  76, 124,  66,  99,\n",
       "        134,  71, 253, 260, 260, 199, 244, 178, 176, 226,  29, 168, 155,\n",
       "        107, 152, 187,  38,  84, 149,  28, 106, 161,  59,  69, 144,  30,\n",
       "         91, 144,  43, 125, 181,  33, 116, 136,  58, 249, 243, 254, 129,\n",
       "        240,  26, 128, 214, 104,  86, 216,  53, 123, 222,  72,  74, 224,\n",
       "         41, 105, 155,  43,  80, 215,  33, 117, 175,  61, 133, 191,  32,\n",
       "        108, 167,  64, 249, 256, 260,   4, 157, 236,  79, 202, 263,   5,\n",
       "        219, 153, 109, 225, 238,  31, 193, 197,  41, 201, 131, 121, 171,\n",
       "        203, 138, 206, 130,  57, 186, 114,  73, 149,  37, 249, 255, 248,\n",
       "        103, 234, 131,  22, 237, 113,   3, 242, 205,  47, 195, 210,  24,\n",
       "        184, 239,  25, 196, 122, 194, 223,  43,  38, 148,  94,  27, 188,\n",
       "         74,  49, 182, 208]),\n",
       " 'split0_train_score': array([0.8700565 , 0.45762712, 0.62146893, 0.8700565 , 0.54237288,\n",
       "        0.54237288, 0.8700565 , 0.70621469, 0.47457627, 0.54237288,\n",
       "        0.74011299, 0.45762712, 0.8700565 , 0.63276836, 0.5480226 ,\n",
       "        0.8700565 , 0.70056497, 0.86440678, 0.8700565 , 0.67231638,\n",
       "        0.8700565 , 0.8700565 , 0.71186441, 0.8700565 , 0.87570621,\n",
       "        0.68361582, 0.88135593, 0.8700565 , 0.59322034, 0.38418079,\n",
       "        0.87570621, 0.68361582, 0.87570621, 0.8700565 , 0.72881356,\n",
       "        0.80225989, 0.8700565 , 0.54237288, 0.54237288, 0.8700565 ,\n",
       "        0.55932203, 0.57062147, 0.54237288, 0.68361582, 0.49152542,\n",
       "        0.8700565 , 0.5480226 , 0.45762712, 0.54237288, 0.67231638,\n",
       "        0.5819209 , 0.87570621, 0.68926554, 0.87570621, 0.8700565 ,\n",
       "        0.69491525, 0.88135593, 0.87570621, 0.6779661 , 0.61581921,\n",
       "        0.8700565 , 0.54237288, 0.88135593, 0.8700565 , 0.6779661 ,\n",
       "        0.88135593, 0.54237288, 0.63841808, 0.54237288, 0.55367232,\n",
       "        0.6779661 , 0.93785311, 0.80225989, 0.75141243, 0.95480226,\n",
       "        0.94915254, 0.5480226 , 0.98870056, 0.94915254, 0.5480226 ,\n",
       "        0.99435028, 0.92090395, 0.75706215, 0.98870056, 0.92090395,\n",
       "        0.74011299, 0.99435028, 0.79661017, 0.75706215, 1.        ,\n",
       "        1.        , 0.75141243, 0.99435028, 0.98870056, 0.74011299,\n",
       "        0.99435028, 0.95480226, 0.74576271, 0.99435028, 0.54237288,\n",
       "        0.45762712, 0.54237288, 0.94915254, 0.74011299, 0.9039548 ,\n",
       "        0.8700565 , 0.54237288, 0.97740113, 0.94350282, 0.75706215,\n",
       "        0.98305085, 0.99435028, 0.74576271, 0.99435028, 0.96610169,\n",
       "        0.76271186, 0.99435028, 1.        , 0.75706215, 0.98870056,\n",
       "        0.97740113, 0.75141243, 0.99435028, 0.98305085, 0.75706215,\n",
       "        0.98870056, 0.98305085, 0.75706215, 0.99435028, 1.        ,\n",
       "        0.75141243, 0.99435028, 0.54237288, 0.54237288, 0.54237288,\n",
       "        0.59887006, 0.54237288, 0.54237288, 0.82485876, 0.75141243,\n",
       "        0.97175141, 0.89830508, 0.5819209 , 0.64971751, 0.94350282,\n",
       "        0.76271186, 0.98305085, 0.93220339, 0.74576271, 1.        ,\n",
       "        0.93785311, 0.76836158, 0.99435028, 0.96045198, 0.75706215,\n",
       "        1.        , 0.94915254, 0.74576271, 1.        , 0.97740113,\n",
       "        0.73446328, 1.        , 0.96045198, 0.76271186, 1.        ,\n",
       "        0.54237288, 0.72881356, 0.54237288, 0.89830508, 0.75706215,\n",
       "        0.94915254, 0.93785311, 0.65536723, 0.61581921, 0.95480226,\n",
       "        0.76836158, 0.99435028, 0.97175141, 0.73446328, 1.        ,\n",
       "        0.92090395, 0.76271186, 1.        , 0.89830508, 0.74011299,\n",
       "        0.99435028, 0.98305085, 0.73446328, 0.99435028, 0.95480226,\n",
       "        0.7740113 , 1.        , 1.        , 0.7740113 , 1.        ,\n",
       "        1.        , 0.76836158, 1.        , 0.54237288, 0.54237288,\n",
       "        0.54237288, 0.86440678, 0.58757062, 0.45762712, 0.8700565 ,\n",
       "        0.75141243, 0.54237288, 0.89265537, 0.71751412, 0.88700565,\n",
       "        0.89265537, 0.68361582, 0.52542373, 0.93220339, 0.75141243,\n",
       "        0.98870056, 0.92090395, 0.73446328, 0.87570621, 0.54237288,\n",
       "        0.7740113 , 0.87570621, 0.91525424, 0.66101695, 0.97175141,\n",
       "        0.88135593, 0.72881356, 0.71186441, 0.97740113, 0.76271186,\n",
       "        0.97740113, 0.54237288, 0.54237288, 0.54237288, 0.87570621,\n",
       "        0.65536723, 0.86440678, 0.8700565 , 0.74011299, 0.97175141,\n",
       "        0.8700565 , 0.6779661 , 0.5819209 , 0.88135593, 0.6779661 ,\n",
       "        0.53107345, 0.87570621, 0.72881356, 0.60451977, 0.88700565,\n",
       "        0.70056497, 0.53107345, 0.54237288, 0.75141243, 0.88700565,\n",
       "        0.92090395, 0.74576271, 0.8700565 , 0.88700565, 0.68926554,\n",
       "        0.93220339, 0.91525424, 0.68361582, 0.68361582]),\n",
       " 'split1_train_score': array([0.85393258, 0.37640449, 0.66853933, 0.87078652, 0.7752809 ,\n",
       "        0.53932584, 0.85393258, 0.70224719, 0.52247191, 0.85393258,\n",
       "        0.70786517, 0.4494382 , 0.85393258, 0.6741573 , 0.87640449,\n",
       "        0.85393258, 0.73595506, 0.65168539, 0.85955056, 0.7247191 ,\n",
       "        0.87078652, 0.53932584, 0.66853933, 0.87078652, 0.85393258,\n",
       "        0.67977528, 0.42696629, 0.85393258, 0.73033708, 0.87640449,\n",
       "        0.85393258, 0.65730337, 0.7752809 , 0.85393258, 0.52808989,\n",
       "        0.70224719, 0.85393258, 0.46067416, 0.53932584, 0.85393258,\n",
       "        0.74157303, 0.65168539, 0.53932584, 0.71348315, 0.88202247,\n",
       "        0.85393258, 0.68539326, 0.88202247, 0.85393258, 0.69101124,\n",
       "        0.87640449, 0.85393258, 0.69101124, 0.87640449, 0.85393258,\n",
       "        0.60674157, 0.88202247, 0.85393258, 0.64044944, 0.87640449,\n",
       "        0.85393258, 0.56179775, 0.87640449, 0.85393258, 0.64044944,\n",
       "        0.7752809 , 0.91011236, 0.53932584, 0.88764045, 0.53932584,\n",
       "        0.74157303, 0.53932584, 0.91011236, 0.74157303, 0.96067416,\n",
       "        0.82022472, 0.53932584, 0.97752809, 0.93258427, 0.74157303,\n",
       "        0.98314607, 0.95505618, 0.74719101, 1.        , 0.96629213,\n",
       "        0.75280899, 1.        , 0.96629213, 0.76404494, 1.        ,\n",
       "        0.96629213, 0.75280899, 1.        , 0.99438202, 0.76404494,\n",
       "        1.        , 0.97191011, 0.74719101, 1.        , 0.53932584,\n",
       "        0.46067416, 0.46067416, 0.7247191 , 0.54494382, 0.92134831,\n",
       "        0.96067416, 0.71910112, 0.95505618, 0.9494382 , 0.74719101,\n",
       "        0.98314607, 0.98876404, 0.74719101, 1.        , 0.98314607,\n",
       "        0.75280899, 1.        , 0.95505618, 0.74157303, 1.        ,\n",
       "        0.90449438, 0.75280899, 1.        , 0.98314607, 0.75842697,\n",
       "        1.        , 1.        , 0.74719101, 1.        , 0.96067416,\n",
       "        0.76404494, 1.        , 0.53932584, 0.53932584, 0.46067416,\n",
       "        0.91573034, 0.53932584, 0.89325843, 0.65168539, 0.74719101,\n",
       "        0.96067416, 0.71348315, 0.76404494, 0.98314607, 0.76966292,\n",
       "        0.78089888, 0.99438202, 0.89325843, 0.76966292, 1.        ,\n",
       "        0.97191011, 0.76404494, 1.        , 0.95505618, 0.74719101,\n",
       "        1.        , 0.97191011, 0.78089888, 1.        , 1.        ,\n",
       "        0.78089888, 1.        , 0.9494382 , 0.75842697, 1.        ,\n",
       "        0.53932584, 0.70786517, 0.53932584, 0.92696629, 0.53932584,\n",
       "        0.92134831, 0.62921348, 0.7752809 , 0.97752809, 0.92134831,\n",
       "        0.73595506, 0.95505618, 0.92134831, 0.73033708, 1.        ,\n",
       "        0.97191011, 0.52247191, 1.        , 0.98876404, 0.75842697,\n",
       "        1.        , 0.92696629, 0.57865169, 1.        , 0.9494382 ,\n",
       "        0.74719101, 1.        , 0.96067416, 0.7752809 , 1.        ,\n",
       "        1.        , 0.76404494, 1.        , 0.53932584, 0.53932584,\n",
       "        0.46067416, 0.83146067, 0.73595506, 0.88202247, 0.88202247,\n",
       "        0.74719101, 0.39325843, 0.88202247, 0.64606742, 0.62359551,\n",
       "        0.8988764 , 0.75842697, 0.66292135, 0.88764045, 0.66292135,\n",
       "        0.64044944, 0.91011236, 0.67977528, 0.56179775, 0.8988764 ,\n",
       "        0.66853933, 0.64606742, 0.91573034, 0.71910112, 0.94382022,\n",
       "        0.91573034, 0.66292135, 0.91573034, 0.89325843, 0.71348315,\n",
       "        0.97191011, 0.53932584, 0.53932584, 0.54494382, 0.88202247,\n",
       "        0.75842697, 0.35955056, 0.88764045, 0.65730337, 0.8988764 ,\n",
       "        0.87078652, 0.65168539, 0.8988764 , 0.88202247, 0.64606742,\n",
       "        0.5505618 , 0.89325843, 0.71910112, 0.53932584, 0.86516854,\n",
       "        0.74157303, 0.88202247, 0.91011236, 0.58426966, 0.92134831,\n",
       "        0.85955056, 0.69101124, 0.99438202, 0.87640449, 0.73595506,\n",
       "        0.74719101, 0.8988764 , 0.6741573 , 0.71910112]),\n",
       " 'split2_train_score': array([0.42696629, 0.68539326, 0.46067416, 0.87078652, 0.71348315,\n",
       "        0.87640449, 0.87078652, 0.75842697, 0.87078652, 0.87078652,\n",
       "        0.69101124, 0.87640449, 0.87078652, 0.70786517, 0.87640449,\n",
       "        0.87078652, 0.70224719, 0.87640449, 0.87078652, 0.73595506,\n",
       "        0.88764045, 0.87078652, 0.47752809, 0.87078652, 0.87078652,\n",
       "        0.74719101, 0.52247191, 0.87078652, 0.71348315, 0.86516854,\n",
       "        0.87078652, 0.70786517, 0.78651685, 0.75842697, 0.53932584,\n",
       "        0.53932584, 0.53932584, 0.58426966, 0.32022472, 0.87078652,\n",
       "        0.65168539, 0.88202247, 0.87078652, 0.70786517, 0.87640449,\n",
       "        0.87078652, 0.78089888, 0.88202247, 0.87078652, 0.53370787,\n",
       "        0.53932584, 0.87078652, 0.74157303, 0.53370787, 0.87078652,\n",
       "        0.64044944, 0.88202247, 0.87078652, 0.70224719, 0.87640449,\n",
       "        0.87078652, 0.73595506, 0.6741573 , 0.87078652, 0.73595506,\n",
       "        0.88764045, 0.53932584, 0.46067416, 0.8988764 , 0.85955056,\n",
       "        0.53932584, 0.53932584, 0.78089888, 0.71348315, 0.95505618,\n",
       "        0.93820225, 0.71910112, 0.97191011, 0.85955056, 0.73595506,\n",
       "        0.98314607, 0.96629213, 0.73033708, 0.98876404, 0.94382022,\n",
       "        0.74157303, 1.        , 0.92696629, 0.74157303, 1.        ,\n",
       "        0.97752809, 0.74719101, 1.        , 0.96629213, 0.75842697,\n",
       "        0.99438202, 0.97752809, 0.74157303, 1.        , 0.53932584,\n",
       "        0.46067416, 0.53932584, 0.53932584, 0.71348315, 0.90449438,\n",
       "        0.94382022, 0.71910112, 0.97191011, 0.94382022, 0.75280899,\n",
       "        0.97191011, 0.96629213, 0.73595506, 0.98876404, 0.95505618,\n",
       "        0.74719101, 0.98876404, 0.97191011, 0.74157303, 0.98876404,\n",
       "        0.98876404, 0.74719101, 1.        , 0.98876404, 0.73595506,\n",
       "        1.        , 0.95505618, 0.74719101, 1.        , 1.        ,\n",
       "        0.74157303, 1.        , 0.53932584, 0.46067416, 0.52247191,\n",
       "        0.53932584, 0.53370787, 0.96629213, 0.85393258, 0.53370787,\n",
       "        0.97191011, 0.91573034, 0.78089888, 0.97752809, 0.92696629,\n",
       "        0.66853933, 0.99438202, 0.92134831, 0.74157303, 0.99438202,\n",
       "        0.97191011, 0.75280899, 0.98876404, 0.96067416, 0.74157303,\n",
       "        1.        , 0.94382022, 0.75280899, 1.        , 0.85955056,\n",
       "        0.78651685, 1.        , 0.98876404, 0.75280899, 1.        ,\n",
       "        0.53932584, 0.46067416, 0.56179775, 0.53932584, 0.53932584,\n",
       "        0.91011236, 0.93820225, 0.76404494, 0.97752809, 0.91573034,\n",
       "        0.62921348, 0.97191011, 0.95505618, 0.73033708, 1.        ,\n",
       "        0.92134831, 0.76966292, 0.99438202, 0.9494382 , 0.76404494,\n",
       "        1.        , 0.97752809, 0.73033708, 1.        , 0.97752809,\n",
       "        0.76966292, 0.99438202, 0.98314607, 0.75280899, 1.        ,\n",
       "        1.        , 0.76966292, 1.        , 0.53932584, 0.46067416,\n",
       "        0.53932584, 0.85955056, 0.74157303, 0.65730337, 0.88764045,\n",
       "        0.65730337, 0.53932584, 0.87078652, 0.75842697, 0.53932584,\n",
       "        0.53932584, 0.64044944, 0.53932584, 0.90449438, 0.76404494,\n",
       "        0.62359551, 0.85955056, 0.66853933, 0.88202247, 0.89325843,\n",
       "        0.75280899, 0.53932584, 0.53932584, 0.75280899, 0.53932584,\n",
       "        0.89325843, 0.73595506, 0.91011236, 0.89325843, 0.68539326,\n",
       "        1.        , 0.53932584, 0.53932584, 0.53932584, 0.53932584,\n",
       "        0.46067416, 0.86516854, 0.87078652, 0.46067416, 0.7247191 ,\n",
       "        0.88202247, 0.65168539, 0.88202247, 0.87640449, 0.7247191 ,\n",
       "        0.92696629, 0.86516854, 0.69662921, 0.89325843, 0.89325843,\n",
       "        0.69662921, 0.91011236, 0.53932584, 0.66853933, 0.90449438,\n",
       "        0.87640449, 0.73595506, 0.89325843, 0.90449438, 0.68539326,\n",
       "        0.89325843, 0.89325843, 0.78651685, 0.50561798]),\n",
       " 'split3_train_score': array([0.90449438, 0.62359551, 0.59550562, 0.90449438, 0.76404494,\n",
       "        0.90449438, 0.90449438, 0.75280899, 0.61797753, 0.90449438,\n",
       "        0.70786517, 0.65730337, 0.90449438, 0.75280899, 0.91011236,\n",
       "        0.90449438, 0.74157303, 0.91573034, 0.90449438, 0.65730337,\n",
       "        0.90449438, 0.90449438, 0.66292135, 0.91573034, 0.90449438,\n",
       "        0.62359551, 0.91011236, 0.90449438, 0.61797753, 0.8988764 ,\n",
       "        0.90449438, 0.7247191 , 0.3988764 , 0.90449438, 0.42134831,\n",
       "        0.35955056, 0.90449438, 0.6741573 , 0.64044944, 0.90449438,\n",
       "        0.60674157, 0.5505618 , 0.90449438, 0.6741573 , 0.90449438,\n",
       "        0.90449438, 0.66853933, 0.93258427, 0.90449438, 0.63483146,\n",
       "        0.91573034, 0.90449438, 0.71348315, 0.35955056, 0.90449438,\n",
       "        0.61235955, 0.92134831, 0.90449438, 0.69101124, 0.61235955,\n",
       "        0.90449438, 0.55617978, 0.92134831, 0.90449438, 0.64606742,\n",
       "        0.91573034, 0.53932584, 0.53932584, 0.53932584, 0.96067416,\n",
       "        0.62921348, 0.92696629, 0.96629213, 0.74719101, 0.96067416,\n",
       "        0.95505618, 0.75280899, 0.96629213, 0.95505618, 0.76404494,\n",
       "        0.98876404, 0.94382022, 0.75280899, 0.99438202, 0.95505618,\n",
       "        0.76966292, 0.99438202, 0.98314607, 0.76966292, 0.99438202,\n",
       "        0.99438202, 0.75280899, 1.        , 0.98876404, 0.75280899,\n",
       "        1.        , 0.98876404, 0.75280899, 1.        , 0.53932584,\n",
       "        0.46067416, 0.53932584, 0.96629213, 0.53932584, 0.92696629,\n",
       "        0.92696629, 0.75842697, 0.96629213, 0.97191011, 0.73033708,\n",
       "        0.97752809, 0.96629213, 0.74719101, 0.98876404, 0.96629213,\n",
       "        0.76404494, 0.99438202, 0.99438202, 0.7752809 , 0.99438202,\n",
       "        0.98876404, 0.74157303, 0.99438202, 1.        , 0.74157303,\n",
       "        0.99438202, 1.        , 0.75280899, 0.99438202, 1.        ,\n",
       "        0.74157303, 0.99438202, 0.53932584, 0.46067416, 0.46067416,\n",
       "        0.9494382 , 0.73595506, 0.53932584, 0.93820225, 0.54494382,\n",
       "        0.96067416, 0.84831461, 0.71910112, 0.99438202, 0.73033708,\n",
       "        0.75842697, 0.92696629, 0.92696629, 0.74719101, 1.        ,\n",
       "        0.96629213, 0.74719101, 1.        , 0.97191011, 0.75280899,\n",
       "        1.        , 0.98876404, 0.76404494, 1.        , 0.98314607,\n",
       "        0.75280899, 1.        , 1.        , 0.74157303, 1.        ,\n",
       "        0.53932584, 0.53932584, 0.50561798, 0.94382022, 0.53932584,\n",
       "        0.96067416, 0.96629213, 0.57865169, 0.99438202, 0.95505618,\n",
       "        0.73033708, 0.99438202, 0.93820225, 0.64606742, 1.        ,\n",
       "        1.        , 0.74719101, 1.        , 0.98876404, 0.76404494,\n",
       "        1.        , 0.97752809, 0.7752809 , 1.        , 0.91011236,\n",
       "        0.74719101, 1.        , 0.98876404, 0.74719101, 1.        ,\n",
       "        0.97752809, 0.7752809 , 1.        , 0.53932584, 0.53932584,\n",
       "        0.46067416, 0.88764045, 0.69101124, 0.53932584, 0.56741573,\n",
       "        0.55617978, 0.53932584, 0.8988764 , 0.53932584, 0.91011236,\n",
       "        0.91011236, 0.76966292, 0.62921348, 0.91011236, 0.61797753,\n",
       "        0.91573034, 0.90449438, 0.75842697, 0.6741573 , 0.9494382 ,\n",
       "        0.75842697, 0.57303371, 0.94382022, 0.75280899, 0.92134831,\n",
       "        0.93258427, 0.74719101, 0.65168539, 0.97752809, 0.7752809 ,\n",
       "        0.91011236, 0.53932584, 0.46067416, 0.53932584, 0.90449438,\n",
       "        0.68539326, 0.91011236, 0.8988764 , 0.53932584, 0.61797753,\n",
       "        0.91573034, 0.69662921, 0.35955056, 0.9494382 , 0.76404494,\n",
       "        0.53932584, 0.92696629, 0.53370787, 0.35955056, 0.90449438,\n",
       "        0.69101124, 0.65730337, 0.90449438, 0.69101124, 0.92134831,\n",
       "        0.93258427, 0.76404494, 0.53932584, 0.91011236, 0.75280899,\n",
       "        0.98876404, 0.92696629, 0.75280899, 1.        ]),\n",
       " 'mean_train_score': array([0.76386244, 0.53575509, 0.58654701, 0.87903098, 0.69879547,\n",
       "        0.7156494 , 0.8748175 , 0.72992446, 0.62145306, 0.79289659,\n",
       "        0.71171364, 0.6101933 , 0.8748175 , 0.69189996, 0.80273599,\n",
       "        0.8748175 , 0.72008506, 0.82705675, 0.87622199, 0.69757348,\n",
       "        0.88324446, 0.79616581, 0.63021329, 0.88183997, 0.87622992,\n",
       "        0.6835444 , 0.68522662, 0.8748175 , 0.66375452, 0.75615756,\n",
       "        0.87622992, 0.69337586, 0.70909509, 0.84672761, 0.5543944 ,\n",
       "        0.60084587, 0.79195233, 0.5653685 , 0.51059322, 0.8748175 ,\n",
       "        0.63983051, 0.66372278, 0.71424491, 0.69478036, 0.78861169,\n",
       "        0.8748175 , 0.67071351, 0.78856408, 0.79289659, 0.63296674,\n",
       "        0.72834539, 0.87622992, 0.70883324, 0.66134228, 0.8748175 ,\n",
       "        0.63861645, 0.8916873 , 0.87622992, 0.67791849, 0.74524694,\n",
       "        0.8748175 , 0.59907637, 0.83831651, 0.8748175 , 0.6751095 ,\n",
       "        0.8650019 , 0.63278423, 0.54443598, 0.71705389, 0.72830572,\n",
       "        0.64701962, 0.73586777, 0.86489081, 0.73841491, 0.95780169,\n",
       "        0.91565892, 0.63981464, 0.97610773, 0.92408589, 0.69739891,\n",
       "        0.98735162, 0.94651812, 0.74684981, 0.99296166, 0.94651812,\n",
       "        0.75103948, 0.99718308, 0.91825367, 0.75808576, 0.99859551,\n",
       "        0.98455056, 0.75105535, 0.99858757, 0.98453469, 0.75384847,\n",
       "        0.99718308, 0.97325113, 0.74683394, 0.99858757, 0.5400876 ,\n",
       "        0.4599124 , 0.52042468, 0.79487241, 0.63446645, 0.91419095,\n",
       "        0.92537929, 0.68475052, 0.96766489, 0.95216784, 0.74684981,\n",
       "        0.97890878, 0.97892465, 0.74402495, 0.99296959, 0.96764902,\n",
       "        0.7566892 , 0.99437409, 0.98033708, 0.75387228, 0.99296166,\n",
       "        0.9648559 , 0.74824637, 0.99718308, 0.98874024, 0.7482543 ,\n",
       "        0.99577065, 0.98452676, 0.75106329, 0.99718308, 0.99016854,\n",
       "        0.74965086, 0.99718308, 0.5400876 , 0.50076176, 0.49654828,\n",
       "        0.75084111, 0.58784041, 0.73531232, 0.81716975, 0.64431378,\n",
       "        0.96625246, 0.84395829, 0.71149146, 0.90119342, 0.84261728,\n",
       "        0.74264426, 0.9746953 , 0.91844411, 0.75104742, 0.99859551,\n",
       "        0.96199137, 0.75810163, 0.99577858, 0.96202311, 0.7496588 ,\n",
       "        1.        , 0.96341173, 0.76087888, 1.        , 0.95502444,\n",
       "        0.763672  , 1.        , 0.97466356, 0.75388021, 1.        ,\n",
       "        0.5400876 , 0.60916968, 0.53727861, 0.82710436, 0.59375992,\n",
       "        0.93532184, 0.86789024, 0.69333619, 0.89131435, 0.93673427,\n",
       "        0.7159668 , 0.97892465, 0.94658954, 0.71030121, 1.        ,\n",
       "        0.9535406 , 0.70050943, 0.99859551, 0.95631784, 0.75665746,\n",
       "        0.99858757, 0.96626833, 0.70468323, 0.99858757, 0.94797023,\n",
       "        0.75951406, 0.99859551, 0.98314607, 0.76232305, 1.        ,\n",
       "        0.99438202, 0.76933759, 1.        , 0.5400876 , 0.52042468,\n",
       "        0.50076176, 0.86076462, 0.68902749, 0.6340697 , 0.80178379,\n",
       "        0.67802165, 0.50357075, 0.88608519, 0.66533359, 0.74000984,\n",
       "        0.81024249, 0.71303879, 0.5892211 , 0.90861265, 0.69908906,\n",
       "        0.79211896, 0.89876531, 0.71030121, 0.74842094, 0.82098648,\n",
       "        0.73844665, 0.6585333 , 0.82853266, 0.72143401, 0.84406145,\n",
       "        0.90573224, 0.71872024, 0.79734812, 0.93536152, 0.73421729,\n",
       "        0.9648559 , 0.5400876 , 0.52042468, 0.5414921 , 0.80038723,\n",
       "        0.6399654 , 0.74980956, 0.88183997, 0.59935409, 0.80333111,\n",
       "        0.88464896, 0.66949153, 0.68059259, 0.89730528, 0.70319939,\n",
       "        0.63698184, 0.89027487, 0.66956294, 0.59916365, 0.88748175,\n",
       "        0.70744461, 0.74512791, 0.72407637, 0.67380816, 0.90854917,\n",
       "        0.89736082, 0.73419349, 0.8242557 , 0.89450422, 0.71585571,\n",
       "        0.89035422, 0.90858884, 0.72427474, 0.72708373]),\n",
       " 'std_train_score': array([0.19536259, 0.12410088, 0.07724395, 0.01470432, 0.09326209,\n",
       "        0.17508525, 0.01841068, 0.02580833, 0.15292916, 0.14578103,\n",
       "        0.01778155, 0.17479016, 0.01841068, 0.04409123, 0.1477013 ,\n",
       "        0.01841068, 0.0187937 , 0.10301498, 0.01691761, 0.03342766,\n",
       "        0.01414219, 0.14893785, 0.09016426, 0.01956888, 0.01820684,\n",
       "        0.04375778, 0.21344074, 0.01841068, 0.05911171, 0.21510352,\n",
       "        0.01820684, 0.02544023, 0.18328229, 0.05415291, 0.11072747,\n",
       "        0.1679717 , 0.14699292, 0.07694472, 0.11719462, 0.01841068,\n",
       "        0.06720969, 0.13159874, 0.17380795, 0.01636279, 0.17184455,\n",
       "        0.01841068, 0.08278601, 0.19217832, 0.14578103, 0.06077285,\n",
       "        0.16896977, 0.01820684, 0.02117802, 0.22336766, 0.01841068,\n",
       "        0.03492258, 0.01712696, 0.01820684, 0.0232768 , 0.13116326,\n",
       "        0.01841068, 0.07934241, 0.09636598, 0.01841068, 0.0379312 ,\n",
       "        0.05339286, 0.1601203 , 0.0630494 , 0.1762526 , 0.18535811,\n",
       "        0.07384619, 0.19657961, 0.07632905, 0.0148115 , 0.00287387,\n",
       "        0.05542981, 0.09692503, 0.00828497, 0.03815929, 0.08688053,\n",
       "        0.00464622, 0.01678745, 0.01015616, 0.00467259, 0.01678745,\n",
       "        0.01182122, 0.00281695, 0.07312963, 0.01052688, 0.00243266,\n",
       "        0.01339802, 0.00230278, 0.0024464 , 0.01078196, 0.00886953,\n",
       "        0.00281695, 0.01225869, 0.00402037, 0.0024464 , 0.00131941,\n",
       "        0.00131941, 0.0345194 , 0.17565066, 0.09283166, 0.01016415,\n",
       "        0.03409152, 0.08375491, 0.00827164, 0.01164016, 0.01015616,\n",
       "        0.00463678, 0.01278598, 0.0046955 , 0.00465581, 0.0100371 ,\n",
       "        0.00699377, 0.00397253, 0.0179863 , 0.01388387, 0.00467259,\n",
       "        0.03515713, 0.00437289, 0.00281695, 0.00690012, 0.00970788,\n",
       "        0.00468213, 0.01836801, 0.004154  , 0.00281695, 0.01702859,\n",
       "        0.00923032, 0.00281695, 0.00131941, 0.04010207, 0.03655761,\n",
       "        0.1833461 , 0.0855705 , 0.19617274, 0.1042168 , 0.10507367,\n",
       "        0.00557858, 0.07928988, 0.07814361, 0.14531643, 0.0938374 ,\n",
       "        0.04360837, 0.02794194, 0.0150391 , 0.01094419, 0.00243266,\n",
       "        0.0141237 , 0.00848002, 0.00466059, 0.00613553, 0.0058353 ,\n",
       "        0.        , 0.01804241, 0.0132707 , 0.        , 0.05574407,\n",
       "        0.02115306, 0.        , 0.02048809, 0.00792599, 0.        ,\n",
       "        0.00131941, 0.11289878, 0.02020969, 0.16694387, 0.09428259,\n",
       "        0.02040101, 0.13828242, 0.0811    , 0.15920595, 0.01830326,\n",
       "        0.05214735, 0.01655135, 0.01879009, 0.03712364, 0.        ,\n",
       "        0.0339021 , 0.10311144, 0.00243266, 0.0371427 , 0.00982345,\n",
       "        0.0024464 , 0.02280278, 0.07485478, 0.0024464 , 0.02426786,\n",
       "        0.01241858, 0.00243266, 0.01432309, 0.01249017, 0.        ,\n",
       "        0.00973062, 0.00401228, 0.        , 0.00131941, 0.0345194 ,\n",
       "        0.04010207, 0.01997355, 0.06176703, 0.15978796, 0.1354614 ,\n",
       "        0.07975791, 0.063701  , 0.01069273, 0.08312389, 0.16153096,\n",
       "        0.15653887, 0.05338844, 0.0582897 , 0.01593397, 0.06091836,\n",
       "        0.1622713 , 0.02339601, 0.03733558, 0.13637651, 0.16233873,\n",
       "        0.04110161, 0.13118696, 0.16737374, 0.03749814, 0.17684286,\n",
       "        0.01981662, 0.03287482, 0.11753214, 0.04210312, 0.03644123,\n",
       "        0.03331331, 0.00131941, 0.0345194 , 0.00234923, 0.15110312,\n",
       "        0.11009019, 0.22607482, 0.01209251, 0.10724587, 0.13966934,\n",
       "        0.0185611 , 0.0189894 , 0.22417956, 0.0301771 , 0.04490563,\n",
       "        0.16756543, 0.02344001, 0.07929983, 0.19203868, 0.01432573,\n",
       "        0.01999442, 0.15771212, 0.18324094, 0.05992343, 0.01421444,\n",
       "        0.03026448, 0.02689222, 0.17101687, 0.01348375, 0.02917416,\n",
       "        0.08935881, 0.01333708, 0.04704569, 0.17711829])}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a266acdf-bf49-4bf0-a5b9-c06aa993e69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'identity',\n",
       " 'alpha': 0.0001,\n",
       " 'hidden_layer_sizes': 71,\n",
       " 'max_iter': 5000,\n",
       " 'solver': 'adam'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1dc7f9a4-3aa2-412c-9674-d5402a4bb88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(X1_test,y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2290d0ba-f439-4f7e-8d59-e41158e8a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.score(X1_train,y1_train)\n",
    "model=grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ec4154a4-2b7b-4e76-bda4-cbcf68f51004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve, validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "893d2be4-79e0-49f0-89e9-d92f2170267a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_best = MLPClassifier(activation='identity', alpha=0.0001, hidden_layer_sizes = 71, max_iter=5000, solver='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a0e45cce-e78b-4bf4-b855-7a540d8cb693",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores, fit_times, score_times = learning_curve(\n",
    "        estimator=NN_best,\n",
    "        X=X1_train,\n",
    "        y=y1_train,\n",
    "        train_sizes=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,1 ],\n",
    "        return_times = True \n",
    ")\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "fit_time_mean = np.mean(fit_times, axis=1)\n",
    "fit_time_std = np.std(fit_times, axis=1)\n",
    "score_time_mean = np.mean(score_times, axis=1)\n",
    "score_time_std = np.std(score_times, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "28fe35c4-8ca6-4b99-87c7-df579eec7f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAG2CAYAAACDLKdOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAACiaUlEQVR4nOzdd5xcVf3/8ddt02e291Qg9CIklARCT2hSRVAURMGviF/9AjaQ7/f3BUSxUhRB/ILSLChVJJKE3pGOQKjp2d7b1HvP74+7M9nN7ia7yezO7OTz5JEHu3ennL07u/c953zOOZpSSiGEEEIIUSD0XDdACCGEECKbJNwIIYQQoqBIuBFCCCFEQZFwI4QQQoiCIuFGCCGEEAVFwo0QQgghCoqEGyGEEEIUFAk3QgghhCgoEm6EEEIIUVAk3AghhBCioOQ03DzzzDOceOKJ1NbWomkaDz744Bbv8/TTTzN37lx8Ph877LADv/3tbye+oUIIIYSYMnIabvr6+thnn3248cYbx3T7VatWcfzxx7Nw4ULeeOMNfvCDH/Ctb32L++67b4JbKoQQQoipQsuXjTM1TeOBBx7glFNOGfU23//+9/n73//OihUrMscuuOAC3nrrLV588cVJaKUQQggh8p2Z6waMx4svvsjixYuHHDvmmGO47bbbSCaTWJY17D7xeJx4PJ753HEc2tvbKSsrQ9O0CW+zEEIIIbadUoqenh5qa2vR9c0PPE2pcNPY2EhVVdWQY1VVVaRSKVpbW6mpqRl2n2uuuYYrr7xyspoohBBCiAm0bt06pk2bttnbTKlwAwzrbUmPqo3WC3PZZZdxySWXZD7v6upixowZrFq1inA4vM3tueXtW/jzh3/GVvaIX6/yV3HRvhcxMzJzzI/ppBw+eOUDdtl/F3Rzak5o60/0k3SSVAYqKfOXYejGuB8jmUzy5JNPcsQRR4zYK7e9kPPgkvPgkvPgkvPg2p7OQ09PD7Nnzx7TtXtKhZvq6moaGxuHHGtubsY0TcrKyka8j9frxev1DjteWlpKJBLZ5jZ9Ye4XuGfdPTBK5VIrrfz3G//NwrqFnLXrWUwLbz5tAtgpm0AgQFFJEYY5/lCQD4opJm7H6U5047N81IZr8RrDfw6bk0wmCQQClJWVFfwv7ebIeXDJeXDJeXDJeXBtT+ch/f2NpaRkSnULzJ8/n+XLlw85tmzZMubNm5ezH+rMyEyuXHAluqZjaEbm/xoaZ+x8BgvrFgLw7IZn+cbj3+D616+nqa8pJ22dbF7DS6m3lLZYG6s6V9Gb6M11k4QQQmwHctpz09vby8cff5z5fNWqVbz55puUlpYyY8YMLrvsMjZs2MCdd94JuDOjbrzxRi655BK++tWv8uKLL3Lbbbfx5z//OVffAgCn7HQK+1Xux/0f3U99bz21oVoWz1pM0kliaRaf3fmz/HHFH3m58WUeX/s4T697mkWzFnHmzmdS5h+5x6lQGLpBma+MzngnK7tWUheqo9RXKsXcQgghJkxOw82rr77KEUcckfk8XRvzpS99idtvv52GhgbWrl2b+frs2bNZsmQJF198Mb/5zW+ora3lV7/6FZ/5zGcmve2bmhGZwUVzLxpyrLmvmXW965gWnsZ/H/TffND+AXevuJs3W97kn6v+yeNrHuf4HY7n9DmnU+Qtyk3DJ4GmaZT4SuhL9rGmew1xO05loBJTn1KjokIIIaaInF5dDj/8cDa3zM7tt98+7Nhhhx3G66+/PoGtyp7yQDkxO0ZzXzOl/lJ2Kd2FHx78Q/7d+m/ueu8uVrSv4MGPH2Tp6qWctMNJnLLTKYQ8oVw3e8IErSCWblHfW088Fd+qOhwhhBBiS6ZUzc1Uo2s6NcEainxFdMY7M8f3Kt+Lny78Kf87/3/ZsWhHoqko93x4D19d/lX+9uHfiKViuWv0BPMYHkq8JbTH2lnVuYqeRE+umySEEKLASLiZYJZhURuqxdKtIQW1mqYxr2oe1x1+HZcdcBnTw9PpTfZy53t38rUnvsYLsRdI2IkctnziGLpBqa+UmB1jVdcqWqOtm+3BE0IIIcZDws0kCFpB6sJ1JJzEsMCiaRoLahfw6yN/zSVzL6EmWENXooslsSV8/cmv8+jqR0k5qRy1fOJomkaxtxhTM1nTtYYNvRsK8vsUQoixittxehO99Cf7iaaiJOwEKSeFo5xcN23KkYrOSVLiLSEWjFHfW0+JrwRDG7p+jaEZHDH9CBbWLWT5quXc/c7dtMXa+M2bv+G+D+/j87t+nsOmHzbsflNdwApg6iYNfQ3E7Th1oTp8pi/XzRJCiAmnlCKaitKf6qc73k1fso+Ek0DXdHRNR0MbsryIZViYmompmxi6gamb2Cl3AdmeRA8e5XFvrxvo6BsfZzucnSrhZpJomkZloJJoKkpnvJMy38hTwE3dZPHMxVSsrWDDtA3c+/G9NPY3ct3r13HvR/fyhV2/wPza+eha4XS6eQwPpb5SOuOdJOwEdeE6Ip5tX2BRiGxL2knidpyEk0BDw2t48RrerVqBW2yfbMd2A02yn85EJ9FUlKSdxNItvIaXkBXCwcFRDkopHOV+bCubpJPMfJ7uzXFS7v8/7vgY0zLRNC0ThjLrr+l6JhRZuuWGn4Hgk16fbfDn6ceYytcZCTeTyNRNakO1xFNxuuJdm53+bWkWn579aY6ZfQwPr3yY+z+6n3U96/jJKz9hh6IdOHu3s5lbNbdgErmhGZR6S+lOdLO6a7VbiG0W7vR4kf9SToqEnSBux4mlYvQme4mlYpkLDLj1Y17dS9ATJGgF8RpefIYPyyjslWLF+CSdJP3JfjfQxDuJ2TEcx8FjeAgYASzP0NeLgTHmXno7ZVNPPWX+MnRD3xh+2BiCUqkUURVF4YYlhXJX1dfIrK6v6xt7inRNz/T8DA5Epm4OXax2UAja9Fiur00SbiaZ3/RTF65jVdcqYqnYFodgfKaPz+78WY6bdRwPffIQD33yECu7VnLlS1eyW+lufHG3L7J3xd6T1PqJpWkaRd4i+pP9rOleQ7mnPNdNEtsJRzluj8xAmOlN9Lo1D04C27HR0PAYHizdImAFMheedADqiHXQEm1xb6d7CFgBQlYIn+nL9O7k+o+9mFxxO05/sp+eRA89iR53FqwGPsNHxIpMSG9fOlgYjP+xB/cIDektSiXpU32ZY5qm4eCgKc0NRzAsEOmaTsAMMCMyI2evewk3OVDkLaImWMO6nnWYujmmxexCnhBf2O0LfHqHT3PfR/fxyMpHWNG+gsufv5x9Kvbhi7t9kV1Ld52E1k+8gBXA0i2a+5sBiKViBb9nipg8SikSTiITZvqSffQn+0k4bvGmhnuB8BieLV6E0r+/AQKAe4FIP2Z6+QdLt/DoHiLeCH7TL0NZBWrE+hnbrZ/xmT5KfCV5PcyTDiXjpZQa0kuklCJmx1BKoVBoSLjZrlQEKoilYrREWyjzlY053RZ5i/jKnl/hlJ1O4a8f/JWlq5fyVstbvNXyFvtX7c8Xd/siOxTvMMGtn3iWYVHsK6aBBlZ3rWaGPqOgV3EWEyddJxO340RTUXoTvSScBEk7CbhDSx7dQ8B0Q/W2SF/IfLg9skopkk6ShJ2gsa8RpRS6rg8ZyvIZbu+ODGVNPen6mb5kH12JriH1Mz7TR8gKFXyPnaZpw4bR8mF2l4SbHNE1nZpQDTE7Rme8kxJfybjuX+or5YJ9LuDUnU7lng/u4fG1j/NK0yu80vQKh9Qdwlm7nsX08PQJav3kGNz1v7p7NTWBGsoD5Xn97kfk1ubqZJRS6JruXngMH2ErPOEXHk1zh7M8hmdYG9NDWTp6ZrhLhrLyX7p+pi/ZR1e8a2j9jDm8fkbkhoSbHPIYHupCbv1NX7KPoBUc92NUBav41n7f4jM7f4Y/rfgTz2x4huc2PMcLG17g8OmH8/ldP091sHoCWj95It4IcRVnXe864nac6lD1Nr/DFlPf4DqZWCpGX7IvUyfjOO47x3SdTNAK5k0o3tJQllLKDUQylJU3BtfPdCe6iafiE14/I7aNhJscC3lC1IRqWNO1xh2bH/QObzzqQnV8d//vcvrOp2d2IH9i3RM8vf5pFs9czJm7TO0dyNN1OI39jcSdOLXBWgJWINfNEpNEKZVZALMt1kY8Gh9SJwNgauaY6mTyzXiHsryaux9b0k5KLdoE2bR+pjfZS9JOTpn6GSHhJi+U+cqIpWI09jWOe3hqU7OLZvPfB/03H3Z8yF3v3eXuQL76nzy+9nGOn308p+88dXcgtwyLMl8ZHfEO4qk408LTpuz3IjZvpDqZWMLdc21d1zosj5W1Opl8s7mhrPZoO8mUWyv0UcdHhPyhzFCWz/Th0T0ylLWVBtfPdMbd9WdSTipTPzMZw5gieyTc5AFN06gKVhG343TGOyk2i7f5MXcu2Xn4DuSfPMjSNVN7B3Jd0ynzldGd6GZV1ypqgjVUBCrkXdQUNtY6mfQO8qX+Ugxz6vTMZENmKMsKYKdsGmjA1E16E70ylLUNknaS/tTG+ploKoqjHLyGl6AVLLjgvD2RcJMnLN2iJlhDLBXL6k7Z6R3IX29+nbtX3M3HnR9zz4f38I9V/+C0nU7jxB1PxG/6s/Z8kyXiiRBNRVnfu564HacmWCOzTaYA27Eze6yNt04mvcy8cPlMXybkjTSUlZ4FJrOyhtq0fiaWiqFpGj7DR5GnSMJggZBwk0cCVoC6UB2ftH+S1cfVNI25VXPZr3I/Xmp4ibtX3M3anrXcteIu/v7J3zl959M5fvbxeAwP9b31LF+znOb+ZioDlSyauYjaUG1W25MtftOPqZs09zdn9qWSOpzcS19oU06KpJMk6SSJpWLuMFMqTlIlp3ydTL7Z0lBWelaWx/DgN/1DhrIs3UJDK9ghl8H1M13xrsz6M4Zm4DN9lPpKpec3S5RtQywOvZ1g25DDMk8JN3mm2FdMVbCK9azHduytWmlyNJqmMb92PgfUHMCz65/lT+//iYa+Bm575zYe/PhB9q7Ym6fWPYWmaSil0DSN+z66j2/t+y2Onnl01tqRTZZuZfalWtW1irpQHcW+4lw3a7swOLwk7Y0hJj2klFIDuxkrMsu4G5pRkHUy+WjwUBZsnJXVm+ilK96Fo9zpy6ZmZi7upm6OuLS+oRuZADR4Q0dgyOeapm38eOD2g782WbZUPyN712WHUgriCYjHUb19qJ4+9/NoD4QCKMcBIzfBUcJNHir3udsOdMY7qbAqsv5HwdAMDp9+OIfUHcLjax/nLx/8hdZoK0+uexIYeMEO+v+v3vgVu5ftnrc9OLqmU+orpSfRw6ruVdTYNVQGKuXdWBY4yhkSXlJOimgq6i5WNvC57WwcLkpfUD2Gh4AeKLhd7KeyzKwsc+isrJST2rgHkZPCwcmsLjv4/+k3PcDGjwf2JtK0oUEG2BiGGBR6dDc4DQ5Pg/cmGjEcDTzGkDCladi2+7qzHRtTmaSc1LD6mXQtktTPZI9K2RCLofqjqO5eiMcgkQRdA48HIkEwHDKbVuWIhJs8lO6eD1pBuhJdFHuLJ+R5TN3kmFnHcMT0I7jqpat4q+WtEW+naRrL1yznS3t8aULakS1hT5hYKsb6nvUk7ITU4YyRUmpoL8xA7UY0FSWeipNSKVJOKnMxSy86Z+omPsuXF5vkifEbaShra6WX4EcxajhycDdwHO3r6aCkNHfJfk1pKG3jBo+b9hSplHvx/KjjI0zLxFY2sVQMXdPxGl6KvEUSrrNAOc5Ab0wMp68PevshHgdHgdcCrxctnH+TUyTc5LHaUC3r+tfRn+yf0FoSj+GhyFPk/sEYKW0rMvs85Tuf6ZM6nFEMDjDpeozRhpE0TXN7YTQTv+HHsAzpCROjSi/Bj0ZWh9LTNg1PKEiqZOa5lVKYmjmurWzE6FQiAbG42zvT0wvROKRSYBrg9UBRBC1Hw01jJeEmj4U8IWr1WlZ3rcbSrQnthagMVA7pdh5MoagIVEzYc2ebqZuZOpxPOj/BY3jc7m/dyNQTDP483Q0++J3hpscH1xvk80V+8DBSOsxEU1Fidsw9plKk7FTm9kOGkbSAFPWKvDRSeNKV+3voN/3b3dIA2ZYpBI7FcHp6oS8KiQSgub0zQT+aNbXiwtRq7XaozFdGNBmlqb9pQqv6F81cxH0f3Tfi1xSKTzo/mfAepGxK1+GkN7JLkHB3rB3cFY4a0g3ufqoyISb9OBrasKCTrh0wNTPTyzG4EHPTIst0zcDgr216fKw2N4yUsBOZnpl0UE2vE5MOMaZlyrtbUVCUbUPKBtNAMyTobEmmEDgWQ/X1DxQCx8FxwDTB54FQYEr/nZBwk+c0TaM6VE3ccRf4K/WVTsjz1IZq+da+3+JXb/zKfUEPjHOnCwnfbHmT7zzzHS4/8HLqQnUT0oaJsLVr+DjKyXSFK6Uyu9w6yhlWOzD4a+m6gbTBhZdDAs8IxZaZgKQbQ3qXHNt9/Kb+JmzsjcW8A8NICoWOnhlG8hk+TMvM6x4mIbJFdffgtHdCLAqGCR4LzedF83ndC3X6n2Wi6dvv74RKpSAaQ0VjbiFwLAqJFBgaeL0QCRVUMJRwMwVYukVtsNZdvTXRO2ErCx8982h2L9t92Do3PYkefvyvH7OuZx3ffurbfHvet9m/ev8JaUO+0DU9q/UDg4NSuudocE+SrWySTnJIUMoUYqbcYw29DXgsD6ZuurtI6zKMJLZPynHcCzTgrF6LYVng97lrq8QGpiU7CncdAt2tFUkHH78PzePJBB5MAyxrSvdSjEQ5zsBQUxyntxf6+iGeBKXAY4HPhxYp3AkXEm6miPQCf6u6VhFLxTLTObOtNlQ74qyo6w+/nmv+dQ0r2lfww5d+yFm7nsUZu5whvQNjNLhmYLzslE099ZT6tr9tB4QYTCkFPb04be04nd3uwaLIoHqQ4Rdr5TjukJVtQzSK6ukZCD6aO33ZNMEwwOdB8/nQLMsNPZblBh9z6gzjqkQConFUf79bCBxLgJ1yvz+vB4rD203vlYSbKaTYW0xNsIb1veuxdGtS37WX+Er40SE/4tZ/38qSVUv44/t/5JOuT7h4v4unTB2OEGJqGhxq6Op1Q0kkDF1dW5y1o+k6eHRGDD62484Csm3o7UN1dQ8EH0A3wBro8dk0+KSHuczcXkJVykb19QNgr17n1s0k3Flk+DxTshA4W7bP73qK0jSNykAlsVSM9lg7pb7SSX1HYekWX9/n6+xUvBM3vXUTLzW8xLef/jaXH3g508LTJq0dQojtg1IKevtw2jqga6CnJhJEM020gb3ItoVm6DDKOj9ukXLK7fXp7kV1dLnldEq5gccyBopvvWherxsiMr09FtoE9LK6hcDxgaE3t3fGicfdL/b3g9875QuBs0XCzRRj6AY1oRpidozuRDdF3qJJb8OimYuYGZnJj1/+Met71/Ptp7/Nt+d+mwNqDpj0tgghCo9SCvr6cdo7oKPLPRgKTmovhGYYA8M5I7Qv3duTSkFnDJVyBuYRqEEFzAaaz4/m9Wzs7Un3+IyjcFclk5usORODZMrd1sDrgXAYOjvRIqHtZshpLCTcTEE+00dd2K2/ydX07J1Ldua6w6/jp6/8lHfb3uWHL7t1OGfucqbU4Qghtprq7RsINd2AA6FQ3g2taOmgsknwUUptrO9JJFH9MbcHCEDTNhY2W4NmdFkDNT/pIS9wC4GjMbcQuD/qTttWyt3eIDAwPJZuSxZ6sApRfr1ixJhFPBFqAjWs612HZVhZ3TdF9UdxmlvdWQXBAPh9I77TKPGV8MODf8ht/76NR1Y9wp/e/xOfdH7CJXMvkTocIcS4qL5+d0p3R5e73ko4MOQiPhVomjZQjGyyafJxg8/AMFd8oOjXHtiDSdfdnhjDdENQPAFqYNNJrxeKI9IrM04Sbqaw8kA5MTtGc18zpf7sLPCnuntwNjS6izt1gNLdXy6tOOIGnYB/SNCxdIsL9rkgU4fzcuPLfPvpb/ODA3/A9PD0bW7P9m5wwaBq60B5Bt7lGUZmlsdEjO0LMVlUfxTV3onq6HQv/OEgmmdqhZqxcIOP5f7bhHKcgWEue2Owy3Gx8lQnZ28K0zWdmmANcTs7C/ypjk6cDQ0AaGUl7jHbcYNOQxNK09y1EdJBx+/PXFiPnnk0MyIzhtXhHFhz4LZ9k9uhzHTO3l5U98aCQWdDvfvuTW3yTs/Q3fU7PB53/Q5DHxJ+JACJfKSiMTewd3S6PRrhUEGGmrHQdN39nZ5iPVX5TMLNFGcZFrWhWlZ2rtzqBf6UUqiWNlRDk3uRDG4cUtIMHYIBCAYGBZ1mN+h4PW7QCQXB7x9Wh3P1y1dLHc4YZGZA9Mdweno2Lral43ZJpwsGS4szXdPKdsCxwR54x9ebQNk97jvA9DLJ6cXLdGPjQmVej9vVbxobe4AMQ5atF5NGxQaFmqTtzu7xhnPdLFFgJNwUgKAVpC5cx+qu1STsBJ5RpjaORNk2qqkF1dQCwYBb4DaKYUEnHkc1tqC0lszQVXEwwA8PvJLfv387/1j5j0wdzsVzLyZoBbPx7RYE5TjurIdozF2MLL0UumWAz+v+LAamc45UMOhOYdVHWrpj43OkA1BqYFZHPI7qcjau44EaCD76xjU9rHQPkLXJ8JfbGyQBSGwtFYu506nbO9zwHg6gRUb/eyPEtpBwUyBKvCXEgjHqe+sp8ZVgaFu+CKlUCqe+CVrb3X1FxtElrBk6BPwQ8G8SdED3evlq2Uns6K3jpg9+n6nDufzAy7frOpzM3i59/ajuHjfc2LY7ndOf/aXQNwag0R9XpXt+bNudXhqNoxwblc5TGqDpwwNQel2PIcNfEoDEcCoWR3V2odo63J2mgwG08MRsISNEmoSbApFe4C+aitIZ76TMV7bZ26t4Aqe+ATq73SW5t6F4bUjQGdjPRLW0cwSzmD79P7mm/nY29G7g209/m0vmXsJBNQdt9XNNNSqecJd8H1hwi3jc3VjT58mLjeoyAWgzXUDKHjT8lUgOBKCuQT1AbBz60nU3AHk8bgAyh9b+SADafqh4YiDUtLtTm4MBtHBJrpslthMSbgqIqZvUhmqJp+J0xbtGXeBP9UfdYNPTD8VFW1y+fDw0fWjQ2Snu45fVF/Lz5j/ybnw1P3r5R3xu1ml8bo8vYFhjHz6bKpRS7h/y/uhA/UzUfbeq6+5w0xSc0plZzGyUAKSUcmd4DAtAnUMDULr4OV0LZJloA8NgG+uD9OFBSFZbnVJUIoHq7N4YagJ+tPJtm+wgxHhJuCkwftOfWeBvpA02VU8vzvoG94JbWjShFw5N18Hvo8Q/jStLL+H2tX/jHx3P8pfV9/Nxy/tcMuc/CJVUDluUaqpRtu0ON/VHUd3d0B93a12MgfqZAl8OXdO0jYFkSwEoPdU1XQPkKPf8aZo7C0zT3H/pGV+a7vb8eEycgb3UVGcXyrI23sZwh8xkRlhuqWTSDTWt7RCNuqGmTHpqRG5IuClARd4iaoI1rOtZh6mbmLr7Y1YdnTj1jeAotJLJ3bbBMiy+OvssdozswE1r/8irfe/xnXev5rKKLzI9PB0tHEYLB90/iFMg6KhkEvpj7nTtnj53uMlR4LW2683qRjM0AG1ephA63RuUiLtDe3YKAGfdBndzdU1zh8OM9P/dIKR5PAObGg4830i9QVOs9yyfDQk1sZgb6MtKCjrQi/wnf4ELVEWgglgqRku0hVJvKbR1oOob3ane4dytHnxk2UHM8NdwzSe3UJ9s5buNN3OR/gUOSsxBtbS5tSihEHokhPLkz7CVO13brZ9xenqht8/9XNPcP+aRcFaH97ZnG+uANjnuONDZgVZShKbrQ4fD0ougJZOovj6wHffrg6fFp9cG0gbqgkwLzRoIQ4OCz6ZhSC7SI1OpFHR14zS3ucXxfi+UFsv5EnlBwk2B0jWdmlAN0UQfXWs/JtIxMPbt9235zhNsp8BMfrnrpfx81a280/sRP1n/e86oPp7PVR+PHk9CewdOazvOQO+H6u5BhQLuRWgSZaZrx2I4XT3urruJlFsbssl0bTH5xtUbNDgEOY47MywWR9npqfFq49BYujcoPSxmme6bAstyC++NQeHHNLe7NYJUynZDTWsb9EYh4IUyCTUiv0i4KWCWo1HVpbG+uYNYOIw/D4JNWrEV4co5/8Xt6+/j4ZYn+WvjElb2r+XiWV8m5C9y33VH40AcZ/Vad/2dcAg9HHJD2gQFHZWy3SGQ/iiqq9ttg51yp2v7sj9dW0yOzAqwYzBkgcSB2X/0R1GOzYZEK4/3vkpzsoNKq5Sjivan1l8zdCNEc2PoyWyRUQAXfpWyobtnINT0u72s5RJqRH6ScFOgnHicxPr1eNp7KK+ZTUO0GdNOYhn5c3E2NYPzp5/BjoGZbh1O9zt894OfctkOFzDDX4Pm8wB9UFIMySS0d+K0trtBIxREj4SzEnRUPOGuvNzTN2i6tnJ7Z2SPl+3OaAskPtb2AjduuBsNDYVCQ+P+rqf5z5rPcVRo7sBGiDaZoTDDHBj+Guj58fk2rg49KPzke/2PstOhpt0djvV43MkIed5usX2Tv9oFyOnrI7FuPXZPN0ZpKaW6QRKHlmgLRXpR3m2FcETZgW4dzspbqI83890PfspFs87lgMjewMAEGp8XfN6NtS+d3ThtHe4f2vBA0PH70bxbDjpDp2v3utsdTPHp2mJi1ceauXHN3aiB/4DM/29s+At77L4rNeHKzO2VUhsXR0wNDIF1dG2sA9K1jev/eAa2xfB5Nx4zTTf45HAGmLJt6Ol1e2p6+sBjQYmEGjE1SLgpMHZ3N4l161CxGEZZWabLuCxQRsJJ0J3opthbnNtGjmDHwAx+ucul/GzVrbzT+yE/WXkLp1cdy95qwZDbaekC3nTQSQwEndaOgR6dwECPTmBI0Bk6XXtgdeBUyr2I+DwFP11bbJvH2l7I9NhsSkNjedsLnFN3ysZjmpYJKIyww0BmZehUyh0G7ekdWvtjGht7frzejVtimCbKnSs2EJSyTzmOG2pa2qGn121DltfDEmKiSbgpIKmODpLr1qFsG6N06KJZpmZS4a8gnopv9QabE63ICnPVnG9x+4YH+Hvz49zb9Chvmyv5n9RXiYzQXk3T3I0lvYOCTncPTlunG3SCAfRwyF1UrKvHHW6yHfdrAZmuLcZuXawBh+F7fIHbg9OcaBvX42WGvkbY8kQptXE/sETSDeUpB6UBSmXW+3E+Xo3t9wwa7jKHDHmNt8jZDTV97vBTd7f7OMWRvA819fFmnmx/ieZEG5WeMo4uW0Ctr3LLdxQFTf66FwClFKnmFpIb1oNpYhQXj3g7n+mjKljF+t71xFNxvGb+bVpnaAbnTTudHf3T+c3aP/Jh6kO+9+HP+MGOFzDDXzvq/QYHHRioo+npwenodGe8eK282O5ATB22cnij+12Wtj7Hv7reHvV2CkVTvI3eVB8hc9s3h9U0zZ2hNVr4Tqago8steu7tQ3V1b1wJevBO8Jspch5cR5YJNe3t0NXjhq7iyJT4XXkt/hoPrnhwaB1U0zK+OfNsjiqbn+vmiRyScDPFKdsm2dhIsrER3edDD2x+DZuwJ0yFv4LGvkYs3ULP0/Hzw8sOpNZbxY8+uoWGRAvf/eBn/NfMc1hQst+Y7q95PW4PjRDj1Jro4LG2F1je+jytyY4x3efD/lV87d3/x2erj+P4isPw6BNXuJ/uSdGC/mH1L0M2Qo3HhxY5awzU8wwEHa+7/5fq74euXrcOqCg8JUINuD02D0YfHLEO6tdr7mL34I7USA/OdkvCzRSmkkkS9fXYzc3o4TC6d2w9MaW+UuJ2nI5YB8Xe/J3KuWNgBl8Pf51/OPfx794P+emq/+P0/mM5q/ZEjDwrihZTW7qX5tHWZ3mt6x2cgYtk2AhyRNlBLC47mA/7V/PrNXehpWdDDfQWfLriCN7qWcHaWAN/2HAf/2h5krNqTuSw0gMm/XW6uY1QM8Ndg4uc7U63tycSnHKzAp9oe3HUr2nAsrbn+VLdqZPXIJFXptarWWQ48TjJDRtItbZiFBePa8sCXdOpCFS69TfJXsKe8AS2dNsE9SD/b/Z/clfDQ5k6nFXRdVwy68tZGQIQ2ze3l+Z5lre+MKSXZo/QHBaXH8KC4n0zvTDT/TXsHtyR5W0vZOo7FpUtoMZXia0cnmx7iT81PExLop0b1tzBQ82P8aXaU9k3sntevIHY4nDXFKKU4oP+VSMWeAM4KB5oWs5LnW9S462gyltOtaeCam851d5yqjzl+Iz8G5YX2TP1X+XbIae/n8S6ddjd7lTvrelG9uiWW3/Ts55YMobPyp8F/jaVqcMJzOA3a+7mte53+fYHP+UHO3yNmf66XDdPTDG2cni9+12WjtBLc2TZQSwuP4RpvuoR71vjqxwyKyrN0HSOLl/AwtJ5/KP5Se5rWsrq6Aau/ORG9g7vwpfqTmWnwMyJ/La2C7ayeb7jdR5oWs7K6LrN3lahqI83Ux9vHvHrJWbEDT3eCqo9A/8fCD/FZiQvAqnYehJuphi7p4fE2nWoWNQNNttQMxO0glQGK9nQs8HdYNPI75fD4aUHMMNXwzUrf0tjvIXvffBzvjXzHA4eYx2O2L61JNp5vO0FlrW+QNugXpo9B3pp5g/qpdlaXt3DZ6qPYVH5wdzb+CiPtDzN2z0f8O33f8LCknl8sfYkqr0V2/qtbHfiToLH2l7goabHaBqYmWZpFkmVHPH2GhpX73QRjubQGG/d+C/RQlO8lV67n45UNx2pbt7vWzns/l7dQ7WnfJPw435e5SnDmsCaKpEd+X01E0Nsbqr31irxlBD3xWmNtVKkF6Pn+buVHQLT+eWul/HzVbfyds8H/GzV/3F6/zGcVXuS1OGIYWxl81rXuyxrfY7XusfXS7MtImaIr0w7nRMqjuBPDX/n6fZXeLbjVV7sfINjyw/ljOrjKLLydzg4X3SnelnS8jSPtDxFd6oXcM/tCRWHc2zZQh765GUeiD4wrA7qmzPPZs/IzgDsPcJp7k310ZgYFHriLTQl3P+3JjqIOwnWxOpZE6sfdl8NjXJPCVUDgad6yJBXBSFj69bMqo8189igIU+Z0r5tJNxMAUopUi0tJNdvfqr3VtGgPFhOQiXoSXRT5C3K3mNPkIgZ4oqdvsmdGx7kwebHuLdpKSuj6/j2rK8UXB1OfayZ5a3P81FfA3Pqa1hUfrD8wRuDlkQ7j7W+wPK2TXtpduaY8kM4qPhTEzqjKa3KW8bFs77MyZVHc8eGB3izZwX/aHmSx9te5LSqxZxUeaTUfoygJdHOQ02PsazteeJOAoBKTxmnVB3N0WUL8OoebMdhP+9+HDVrL54YtM5Nug5qc0JmkJ3M4IhDhUknRUuifSD8uD09DZnw00rMidOSaKcl0c47vR8Ou3/Q8A/0+lQMCz/lnhIMbXgZwWNtL3DjmrtlSnsWaWqilrnMU93d3RQVFdHV1UUkEsl1c0aUTCZZsmQJxx9/PKZhuFO9GxrGNNV7a8VSMdb1rAMFAc/EPMd42Y7De6s72H1WCcYow29Pt/+LG9fcTUIlqfaUc9mOFzCrQOpwRvqDl35Xuj3+wdvS6yHdS7O09Vle7353SC/NUWXzWVR+8IT00ozHm90ruGPDA5l6kRKriM/XnMDRZQtGvOiNZCy/F1PV6ugGHmhaxjPtr2YWTZztn8ZpVYs5uGS/IecoF+dBKUVXqmdgiGtj+GmMt9CYaKU92bXZ+xvoVHjLMsNc1d4KPJrF/63/66irX9+8+xWbDWv5+HqIdXcCil0OOg4ji+UO47l+S89NHlOp1MBU7xb0cGjMU723RmaBv578XeBvJIeVHsB0n7svVWOile9/8HO+NfNsZvunT+ku3s3tZSRreAzVkmhneevzPNb2Am3JzszxdC/N/OJP5U2NxKciu7F3eBee63iNu+sfoinRxk1r/8Tfm57g7LqTObBon+2ukFUpxbu9H3F/0zJe6343c3zv8C6cVrWYT4V3y5tzomkaxVaEYivCruww7OtxJ0FTvC0zzNWQCT+tNCVaSaqUG4TiLdAzhucbYWsPMTYSbvJYcv166OzEKCoa11TvrRWxIu4Cf/35vcDfptw6nEsH1eHcCoCOPuldvCllE3cSxJ0EiYH/x51k5tjgf4nBX1ODb59gZf86SrscItHhz9Hjh/ualvK16Z/H0rfPX2Fb2bza9Q7LWp8b0ksTMUMcWXpQXvTSjEbXdA4t3Z/5xZ/i0dZnuadhCevjjVyz8hZ2C+7Il+pOZbfQjrlu5oRzlMPLnW9xf9MyPuxfDYCOxvzifTm1ajFzglNvdplX9zDDX8MMf82wrznKoT3Z5Q5zJTb2+LzRvYIeu2+URxz/1h7CtX3+ZcxzTtS9oqU6OvBu5VTvraJBmb+MuB2nK95Fkbcob94xbUm6DufmNX9iefsLAJlu7cE9HtO8VRRbkVHCRpK42vR4ctRAkhjhMexR9h8ar7IuxQ232Hjs4V9LGPBfX3ueM9teosZXyXRfDdN9Nczw1TDdX0OdtzJveiqyrdPp5M8Nz/N4+wtDhgD2Cu08MOMpf3pptsTSLU6sPJIjy+Zzf+My/t78OCv6PuHSD3/BgUX7cE7dKXkb0LZF0knyZPvLPNC0PDNN29JMjiqbzymVRxdsj6Su6ZR7Sij3lLAHczLH79zwIA80LR9x7zIHha1slFJT5m9xvpBwk2fsnh4Sa9YAuIvzTfJS6LqmUxmoJOkk6Yp3EfFEpkwPjqEZRKzwqLs3KxTf+/Dnk9IWDQ2v7sGrW3h1Dx7dM/D5wD9t48eegdts/GexrudfeOzhxYoAHhtKojptRQ7rY42sjzXyIm9kvq6jU+OtcEOPv5oZvlqm+2qo81VNShFttqV7aR5tfZY3ut9DdQ/tpVlcfgh1vqoct3LrBQ0/Z9edzPEVh/Hnhn/weNsLvNz1Fq90/ZtF5Qv4XM2nKbXyv9B/S/rsKI+2PMPDzU/QkeoG3O/9uPLDOLHyCIqt/KyBnGhHly3g/qZlo379hc43uOLjX3PetM+O2CMkRibhJo+kOjpIrl+PE48DbNMaNtvCY3ioC0+jua+JzngnISuEZUyNi+JYunCHh4xNA4g1PIwM+ufRNg0jQ4OJV/dgauY2vdNqqooAI4cbgO/t8FWMHWaxLtbAulgDa6MNmY/77Cgb4k1siDfx0qD6Rh2N6nTo8VW7vT3+Wup8VXj1/NuHqznexvK2F3is7flhvTTHlC/koOJ9pkwvzViUeYr5z5lf5KTKo7ir/kH+1fU2S1uf46n2f3Fy5VGcWrWIgOHPdTPHrS3RycPNT/Bo67NEnRgAZVYJJ1ceyaLyQwgY+buA6GSo9VXyzZlnj7i1x36R3Xmr5wPe7FnBf624muMqDuXzNZ8mXGCzQieChJs8oJTCbm0lsX49GAZmcTFs2DDp7Ug1N2N3d2c+L1U2RryfDrMTT1U1fiv//7BWespG7bnR0Tm16mjOmQL7zZQ7QVKb+XqFpxR9oIt738jumeNKKTpS3ayN1g+EnUbWRetZG2ug1+7PrNj6ctdbmftoaFR5ypjur9k4xOWvYZq3etKnKad7adwZT+9lfo7pXppZ0T05dMc5eTMrZCLM8Ndw+Y5f573ej7l9wwN80LeSvzb+k0dbn+XM6uM5uvTgXDdxTNbHGnmgaTlPtf+LlHJfzdN9NZxWtYiFJftvt/ViIzmqbP6oW3s0xFv4w/r7eLnrLR5peYpn2l/h87Wf5tjyhWOeYbc9kldXjinHGTbVO2WPUGgxwVLNzaw7/6uo5PAVP32WRfIXl9FTXkzICuX12O/mungVikVl+X1hUB1d2P98HPufT2z+dkphL38Gff5ctNDGd3GaplFqFVFqFfGpyG5Dbt+V6mFtrJ510Ua3tyfWwNpoPT32wIJmiVZe6fr3kOep9JS5tTwD9TwzfDVM81XjH+e77S0tUOb20rgzngb30uwd3oVjyhdyYNHe6Bi8t3psu3QXgt1DO/HTnb/DS11vceeGB6iPN/N/6//K35uf4DDzSHZVCzHIv5D3Qd9K7mtcxr+63s6E092DO3Ja9THMjeyBLottjmi0rT1qvBX8YMcLeKv7fW5b/zfWxOr53bp7eLTlGc6b9ln2Cu0y+Y2dAiTc5JBKpUg2NJBsbEQPhdB9ueuetbu7Rww2ACSTVDlB2nWPW4fjjeTtH6jNdfF+c+bZeV+saC99EvuBf275hh+vInXrn+COe9APnY9x/FHo00Yfjx88hXXv8K5DvtaV7GFtrGHYEFdXqofmRBvNiTZe7X5nyH0qPKUbQ89Abc90X82IwyajLVB24YwvEDGDAzOeNvbSFJkhjipbwKKyoQsW2k52irWnEk3TmF/8KfYv2ovlrc/zl4ZHaEq08tfEX3ntw5c4d9qpw36euaCU4rXud7ivaRnv9X6cOX5g0T6cWrVou5j9NdH2iezKdbv9gGWtz/HH+odZG2vgfz/+FftH9uIQdTRQkusm5pWch5ubbrqJn//85zQ0NLDHHntw/fXXs3DhwlFv/8c//pGf/exnfPTRRxQVFXHsscfyi1/8grKyskls9bZzEgmS69eTam3DKJ6cqd7bwmf4mBaeRnN/c97X4WyuizffOJ+sAQ30Hdxpr8ZxR+K8/zH6IQdg//7PkBxhcMoywe9Dm1GHWrsBZ/nTOMufRtt7d4zjj0Tfd69x1WsVWWH2ssLsFd55yPHuVC/rog1Dgs+6aAMdqe7MCq2D1yUBt5Ziuq+aGf5apvuq8eu+Udfr+c3au4fcd3AvTSHV0mSDqRkcV3Eoh5cewINNj3N/4zI+ia7lfz66gf0iu/Ol2lOZFZg26e1KKZtn2l/hwablma0KTM3gsNIDOLVyEdOlADarDM3guIrDWFgyj780PMIjLU/zSve/eZ33WFV/BGfWHD8l67ImQk5XKL7nnns4++yzuemmmzj44IO55ZZbuPXWW3nvvfeYMWPGsNs/99xzHHbYYVx33XWceOKJbNiwgQsuuIA5c+bwwAMPjOk582GFYicadXf17urCKCkZNiMqZds89u67HL3HHpiTNFuq56mnaPnpz0b9ulldTdEppxA48jDa9Tit0RZ8hm9CdxPPx5U3s0EphXr7PVIPPop65320PXbBc8V3ht+upQ3V04vjKFY2dLNDTQRd19DCIbSKMvdx3vsQ+5HHcF59C9K/ylUVeK78LlrZxLyT60n1DQk76fCzpdVZR+LVLE6oPILFZQdvMXwW6uthvGzH4V8r1/GW50WWtT6LjYOGxuGlB/CF2pOo8GRn37nNidoxlrc9z0NNj9M6sL2FX/dxTPkhnFR5FGWe4glvg7weYF20gVvX/403e1YAUGSGObv2ZI4sm5/TvfbyYYXinIabAw88kP3224+bb745c2y33XbjlFNO4Zprrhl2+1/84hfcfPPNfPLJJ5ljv/71r/nZz37GunXrxvScuQ43dm8vyXXrcPr60EtKRnyHPZnhRilFzyNLaL3lFkhtroTVpXm9BBcuRFt0CO11EZTGhNXhFNofL2XbOC+9hv3QUtSqte5Bw0A/eH/MC76EZo38R2As50E1tWAvfQr7iefQSoqwrr0y8zNRff1owYnfUqM31b8x9MQaWRut573ej0lsZufmBcX78r0dvjqmxy+018PWGnwemhOt3FX/d57vfA1w14s5oeJwTq8+dkJm1HQmu3mk5SmWtDxNr90PQLEZ4cTKIzm2fCEhc/K2bpHXgytl2zz48cs8nlqaWTdoR/90zpv+WfYIzdnCvSdGPoSbnA1LJRIJXnvtNS699NIhxxcvXswLL7ww4n0WLFjA5ZdfzpIlSzjuuONobm7m3nvv5YQTThj1eeLxOPGBqdXgnhxw929KjlZjMkFSnZ2k6utxkkmMoiKUUjBC8XC6oHiiC4udvj7af/1r+p97fou3DZ92GrHXXiO5Zg29jz0Gjz2Gb9YMkocfSMdhcwn7s7+juO2oQf+f2vUWzkuv4fzpfmhqdQ94PWhHHoL+6UVo5aXudzdKTcmYzkNFGdoXP4Nx+qehtQ1HKVAKFYtjf/MHaDvNRjv2SLS9d5uwJQb8uo+dA7PZOTA7c+zu+od4sPmxERcoc2dplY+5lqaQXg/bYvB5qPSU8+1ZX+Gk/qO4q/4B3un9iAebH2N52/OcVnkMx1cclpVp/o3xVh5qfown21/KhNUabyWnVB7NYSUHZNZPmsy6KHk9uBwFu1i7cNzsuSxvf5Z7GpfwSXQdP/jwWg4unss5tadMSm/eYO7PRJFMJnGc7PWfjOeanbOem/r6eurq6nj++edZsGBB5viPf/xj7rjjDj744IMR73fvvffy5S9/mVgsRiqV4qSTTuLee+/FGqVm5YorruDKK68cdvxPf/oTgQnahHKqMDs7mXnDr9BjMdoOP5zSZ55BH6H3xjFNVn/nO6SKi/CtWUvRyy8Tfvtt9FSKeHU1ay76L8jjGVT5IPzaa9T89W+kgkE6F8ync/58nODEr1URfP99am+/A23g1zxeUUHnwQvo3m8/1ATuVZbWardyQ88No24KeFH4IsqMqVUvl6+UUnyY+pBl0WU0OU0AFGlFHOU7ik95PrVVkwDqU/U8G3+Wd5LvZH6GdUYdh3oPZTdrt5xPLDA7OjH6h29dYAeCpEqKJ79BeaDP6eOx2GO8mngVhcLE5BDvIRzqOxSPln/rWY1Hf38/Z511Vn4PS6XDzQsvvMD8+Rv3+/nRj37EXXfdxfvvvz/sPu+99x5HH300F198MccccwwNDQ1897vfZf/99+e2224b8XlG6rmZPn06ra2tkzIspRyHZEsLqYZGdK8XPbDlYq+UbfPU++9z+K67TviwVPT119GDQby77EKquRln0Do3aXokglk5tB7C7umh74knMUpL8B2ygLZoG60dGwhedwfGwoPQDj4Azb9t9Ti2o/hgbSe7zCjG0KdOeFKt7TiPPIY2rRb9qEPcYykb9dTzaAsPQvOO7w/Mtp4H1diM8+iTqKdegKi7iBoBP9oRC9A/vRittHjcjzkeT7S9yG/W/XHY7LVvTP8CR45jr6+p+nrIti2dB1s5PNPxL/7c8I9MPcxMXy1frD2Z/cJ7bHEIWSnF270f8EDTct7u3fh3eN/w7pxauYg9QnPyYjmIVHMbzsX/b8Q3ZFgmxvU/RCuf3B6LXBjt9bAqup4/bLiXd3o/AqDUKubsmpM5tGT/Cf/5xbq7AMWc/RdlfViqvLw8v4elysvLMQyDxsbGIcebm5upqhp5KfVrrrmGgw8+mO9+97sA7L333gSDQRYuXMjVV19NTc3wynyv14t3hHeolmWN2tuTLSqVItncDI2NeLZiqrdpGFkNN3ZPDy3X30B40dEEDzoIgPD++298vpoaGOEcjti24mK8p21cDK82VIP+1Av0v/8JzvufwF33oi88EGPRYeizhxeHj43b1Wzo2pQYU3fWbcB+aCnOc/8C20ZVlGEesQDNNMGjw+LDt/aRgW04D7XV8JXPoz5/Ks5Tz2P/8wlUQzNqyRMYxxw54SthL6o4mD3Dc7Iwe21qvR4mzubPg4HO0eULWFg6j0danuLexkdZE6vnRytvZs/QzpxbdypzgrOGrT10ROmBrI5u4IGmZXwSdWsYdXQWlszjtKpFOZmNtTmqt2/0OsFkCr23D72yfHIblRMjvx52Cs7g6jkX82LnG/xhw/00J9q4Ye0dPNr2LF+d9lnmBGdNWIvSIcuyrKyGm/Fcs3MWbjweD3PnzmX58uWceurGi+Ty5cs5+eSTR7xPf38/pjm0ycbAxT+HddEjUokEifUbSLW2urt6e3I7tTW24n2af/ITUs3NxFeswL/ffuieLHZRalBx6NG0RZP0PvooNDTjLH8GZ/kzaDvOwlh0KPohB6BNwlDIZFJKod7/yA01r72dOa7tsQvmKcfCJO8Ntjma34dx3FHoxxyB89a7qI9WodVsDBipu+9Dq6pAP/TArP+cRlugbCpJz17bVHr2Wr7x6h5Oq1rMorKDubfxUR5peYp3ej/kOx/8lJ38M/kkunbIat73NS0dct9FZQdzUuVRVHnz73sbC+e1t9BmTc+Ed9Xe6da1+X3g86EZ+ROQJ+q1pWkaC0r2Y17RXjzU/Bj3Ni7lg76VfOeDn3Jk6UF8sfbkSZnZlgs5Xefmkksu4eyzz2bevHnMnz+f3/3ud6xdu5YLLrgAgMsuu4wNGzZw5513AnDiiSfy1a9+lZtvvjkzLHXRRRdxwAEHUFtbm8tvZQgnGiWxfj12ZydG6fCp3pNJOQ5d9z9A++23g21jVldT9YPLshtsBhhFRVSe8Tkip51C0yvPEV/6OOar76A+WU1q5Ro8e+8OFYUVbuw/P7Bx0T1NQz9gX4xTjkXfafbm75hDmq5j7LsX7LtX5phqacN+eJn7x/+P92EcvRDjmCPy8qKdC6qljcR//feo6w55brg6b89V2Azy5Wmf4YSKw/lTw8M82f4yH0fdzXlHqoX6dMXhnFlzAhEzNNlNzSr73kcwTj8x83nq1j/ivPLmxht4PO56UX4f+H1YP7osM2PRfvJ51NoNbhDy+9B8PvB7Mx9ru+6U+buuUikwjK0e6pmM15ZHt/hs9XEcWTqfu+of5Mn2l3mi/SVe6HyDz1Yfy0mVR2VlU91MSOvrARSxyHvouoFZUoI1ydfonIabM888k7a2Nq666ioaGhrYc889WbJkCTNnuguaNTQ0sHbt2sztzz33XHp6erjxxhv59re/TXFxMUceeSQ//elPc/UtDJOZ6t3bi1FamrPNL8Fddbjll7+k/1+vABA8dCEV3/oW+gQXsvpMH9MOOoKWvfaktWk1/uffwmjtHPILmvrj/Wh11ejz5427BiWXVDIFiURmarU+bx/sh5ejHzYf46TF6LXVOW7hVgoFMc75rLvtQ1ML9kNLsf++zA1rxx+Ftlt+1FnkiurpHfniA5BMoXp68zbcpFV6y7ho1rnoGDzePvKMVB0dr+6d8sEGQNt95+GvWcPYOEM1kYBEAtXVDboO5sY3oc6rb+H8641RH9tz142ZXtnUb+/EeealTYJQ+mMv5je+nPl74bz1Ls6GRjdQ+Xxofi+qo2uzry2nuwcjS6+tMk8xF806l+MrDufW9X/lg75V3FX/EMtan+PLdZ/hoOJPZSWkpR9hLb8CQPN42PHRf05qwMn5CsUXXnghF1544Yhfu/3224cd++Y3v8k3v/nNCW7V1lGJBIk1a3FiUYyyspxeDOyeHtZ/4z+xW1vRLIuyC75G+LjjJq1NhmZQHazGW+el6dPFJIH0+wLV2o790KPuonO334Nx2Hz0RYdtdvuAXFPRGPZjz2D/Yzn6AftinXcWAPrOO+K55WdokXCOW7htNL8P84SjMY49EueNf2MveRz17xU4L7+O8/LrmBeei3FEfu/LNRFUXz9qQwOqgIJdQiVG3VwWFM2Jtklv01ionl7sBx9F33t39H123+LtzbNPH/K59b1vuOULyZRbWB+LoaIx9+NEYsjfRv2g/dCqK92vx9zbZG4bj8PgN2SxuPu3rD8K/dEhZ1XBkKFp+7l/4Tw1crAcTerSH5HSNDeADfrn+eX/ZgJ16eOPk3rtVVIDX9OG3FbD+s7X0ardIWj7ieeY9dSLXK3rdDhVbEg0E6cZR7uZt60QJV8+lxmz93Zv+9rbOC++Ouy5tYHHNY49IvO4zrsfjhrSVCJBqqNj+wo3hUQ5DiqZwAiHc/4u1wiHCRxwALG33qLyB5fh3WGHyW+EBiW+EizdymzbEPFE0LxejM+djP3Ys9DShr3kcewlj6PtNsctQD5ov7zZjkJ1drvtW/YU9LmLlqk330XZdqZbeqoHm8E0Q8eYtw/GvH3cAul/PoHzrzfRD9g3cxtn5Rq0ojBaWeHMRFHdPajV61AbGnE2NKDWN6A2NEKnu+qyecl/bP7+6+thYAuNfFfpKdtMuNGo9ORXD5Tqj2I/shz74eUQjeH8ewXW3rtBJIRjmqPOltLCw3ufNE0Dj+X+Kwoz2l9pY+FBMPouQEOY//kVt2B/0yA08PHgIKTvNBviCTdY9Q8ErO5e6OjcwkkYWBNt8Npng64xRn8U2jZuKrvpT1bZduZ7VU0tqBUfAlA88G+jHi5772Z2MhbyhZoTCa5dj/P0i6M2Sz9g343hZu36zX8Pk0zCTQGxOztRSmGWuMvul33tPyCVQs/xej4hj7sPVSbgBCKYp52AccpxqLfew17+NM5rb6NWfERqxUeYsbMxFh2a0zarhmZSDy9132UNvBvRaqsxTj4GfeGBOa2jmiz69Dr0/zgb9eXPZ2oRlFKkbrkLtXod+oH7uUNWu+yY8zA/Fsq2UY0tqPpG1PoGjMPmZ6bB28ufxv7LQyPfsaQYeqObfezUr3+P/dSLmKceh77Xbpu9ba4dXbaA+5uWjfg1hWJR2YIRvzbZVDzhbiT74KMwUGyrzZqOcaY74UQrL2X1d77DnCIDfZMp8ZNZ5K35vODzjhqUBjOOORzjmMOHHHNWriH5/atHvY/5PxejT6916+EcBY6Dchwo3jgVumPhQsqPX+juEe84Q26L4wx5I6IfcgDarOmDbueA7dCd6OGl9tdpLlrHJ63P8lzHq/xHzYEsOOsUdMWQx9v4uBu3eNGrK/JqKUUJNwUi+vbbNP/0Z1jTp1Pzo6vRDMMtGp6AwuGt4TW81IRqsDSL1lgrfsePz/Kh7bsn+r57oto6sJ94Duf5V9AP3jg9PbjifZx6E/3AuaNuTzAR7MfdmV4A2pwd3CLhefvktIYqV4ac9/6oW0/gODgvvorz4qtoO8x0N+xcsH/e9LgBOGvW47zwCmpDozu01NA85J2vNq0Go/RT7sfT69BqqtDqqtHqatCm1bgf11ajBQM4K9ds/sk0DfXvFaQcB0+eh5taXyXfnHk2v15z17C1h7458+y82GDWfvFVUn/4C3S4PWdabTXG505GP3C/jb+DSpEqKUabVYJewL+XWiiItsmChJsGqVRx0ZjPgz69DqbXDTteAhzHcczo+Yhb1/+NldF1XOd5int2ruS8aZ9lXtGem29nnk2ikHAzxSnbpvMvf6HjT38Gx0EPhbC7ujBL82/IwNRMqoPVeAwPzdFmkokkYY87pKOVlWB+9kTU6Z/euCeSUpQtXYrT0EAicg/GEQswjj400w2aLe5GlisgFETfcWB37hOORm1oxDhx8XZfTDuYFgzgueI7OKvXuUNWz76MWrmG1I1/gLvuxTz7sxiHjX1hvq2llILuno3BZX0DzoZGt+dkj13c26yvx75/ydA7ej1uYKmrRotsHLYwDtgXY9DQ26a0cMjdjX2UGS3W/34H5/l/oc/bZ2Mbu3pwXn0T/dCD8ir0ARxVNp/dgztmYe2hiaK5waaiDPOzJ7rnsEB7S7f02hppeG0i7RGewy92vZTH217g7vq/Ux9v5oef/Ia5kT34yrTTmeabGpMmJNxMYan2dpp/9nNib70FQGjRIsov/Pq4FwucVBqU+kvxGB6a+poydTjpZdyHhAjboW/33fHFotDR6c7geWgp2l67YSw+zO1JMbf+JbzpRpbaPrvj+e+L3XaUFGN9/z+36VstZPqs6ehf/xLqC6dhP/4s9qNPQnsnDNqgM12XtC1reCjbAcfOhAPfmjWkbvs/qG+E3uHL7juf2iMTbrQdZqIvOhStrgZ9oEeGspE3q90SraIMzw1Xb/b70HfZcchx+5+PY9/3CNzzd4wTF7nBfBtX7c6mfFl7SCmF8/LrkExhLDwQAP3AfTG/eR76/Ll5FwyzbSyvrclmaDqLyw/h4JK5/LVhCf9oeZLXut/lzfdWcHzFYXyu5gRCm2zMurmQpnk8mXKJySLhZorqf+MNWn72c+zOTjSfj/L//Abho47KdbPGbFgdjieCqQ99OWqmQdviRVSe9xm0N97BXv4M6q133e7/f69AX3gQ1rfOG/dzq3gC56nnST28HJpa3INeD3pdDcp28mpxr3ynRcKYpx6PceJinNf/jT5o7Rz7vkewX3kT1tWPuEHs4DU8VCKJamhye2E2NKDWD/TI1DdhnvNZjGOPAEDpOnz4ycCTa1BRhl43MIQ0rQZt950zD6/XVKH/x9nZ+14rysZ1odHKSt16nY5O7Dv/hn3fIxjHHoFx3FFoRYVThL61lFKoN98l9ecHUKvWQiTsvmHx+9y1mA49KNdNnDTjfW1NlqDh58vTPsMx5Qv5/YZ7eaXr3zzc8iRPtf+LL9SexOLygzG0gYkVg0JaYmCdm5l7Hbx9rnMjto6ybdp+ewt2ZyeeWbOo/MFleKZPz3Wzxm1wHU5bvA2/4cdrDl/kTzOMzLCBamrBfvw57CeeQz94XuY2qq0d55M16HP3hvbOUd8FOW+/R+pPD0B3j3swHMI47kh3SuMkd/8WEs00hwzrKMfBfvJ5aG0f/U4D68Oo7h6Sl/3YnREyAmdDA+kBiURVFfq3zseYVoNWW5XXK14biw5FP3w+zrMvYz/4KKqhyQ18Dy/HOOZwzHM+m+sm5ozz3oduqHn/Y/eAz4ux6LCtfryknSTlpPCZPhlCngC1vkr+e8cLeaP7PW5bfy/rYg38dt2f+WfLM5w//XT2Du8KDApp3Z2Awrf77lndfmE8JNxMQZphUHnp9+lZsoTS889Hz+M/8FtiaiZVwapMHU4ikcjU4YxEq6rAPOtUjDNOhEE7EtvLnnbrK4oi7swKZ4S6fcvEOOMkN9hUlGGeuBj9yIPz+gI5VWm6jueay0n99e84y5/e/G0rK9xgE/APKuatQZtWjV5bA4P2B1IeD/rB+0+ZAlLNsjCOPAT9sAU4r7yB/eA/UZ+scacKb4ec9Q2kbr8H9da77gHLxDjmCIxTjtvq3qx4KkFCxfDpPjriHQTN4IhvksS22zeyOzfsdjmPtjzLnxoeZk1sA//z0Q0cVPQpvjztNKq9FdTHmnm09QlaUh3s+sZHnLbzZ5gZmfxlEiTcTBH9r75KqrmZyPHHA+CdPRvvN76R41Zlh6ZpI9ThFG3+PpvW2gT8EAlD1/BdzTOSKbTdd8a86D/ctXQKtEAxX2jFEYyjF2453ISDeP7vl+66IwX6rlszdIyD5qIfuB/qnffRBgU2Z9Va7HsewjjlOPRdd8phKydBKuUGG8NAP/IQzM+cMGQ68daIpvqpCVVT5CumK9ZJe6ydaDxKyAoNG+oW287QDE6oPJyFpfP4S8Mj/LPlGV7qepNXu99hn/CuvN79bmYdpZffe5fb37uDKxdcySk7nTKp7ZSffJ5TqRTtd95F19/+BoaBd+ed8e5UmH8AQx73j1FztJmueCeBcSwBb558LMbxR2H/4zHsP90/6u000xwy1VzkB23Qmh2FTNM0tE2mitsPPorz2ts4r72NtutObsjZb6+CCHqqqQVnxUcYh7tr5+izpmOe/wX0fXbf5lmP8VQCgKpAFRX+Cnfz3kAFYU+Y9lg7nfFOdE0naAUzExZE9kTMEP8x/UyOLV/Ibevv5c2eFbzW/Q6wcc8yW7m1dv/7wv+yX+V+zIjMmLT2yU88j6Wam6n//vfdYANEjj8Oa8bkvThywWf6qA3VUuYroy85vG5mczTLGtOy7ELkE+PMk9CPWgiGgXr/Y1I/+TXJ71yJ/exLqJEKsacA1dZB8nd3k/iv/yH12ztR6cJ93IXstjXYxJIx4rY7tFfmKxuy8IvP9FEbrGVGeAZ+009XvIv+RL+7fIDIuhn+Wq7Y6ZvML97MUgpo3P/R6G86J4L03OSp4Hvv0Xjf/Ti9vWiBABUXXURo4SG5btakSK+HY2CygQb6En1EfDK7ZCrKtzU88pFeW41+wTmoz56I/chj2MufRq3dQOpXt6EtfRrP1d/PdRPHTHX1YD/4T+ylT0EyCYC2zx5Dlv/fVrFkjLgTp8pfxXrqh69oB6C5PcEBK0BXoou2/jY6Y50ErIDU40wATdMwNWPUbT0Uivre+kltk4SbPNR5++3U3XsfDuCdM4fKyy7FqsnfTSUnQroOBxowNIOueBdhTwS9ALrqtyf5uIbHtrIdm75UHxoaISuUteEjrazEnfZ+2vHYS5/CXvI4+oGDZqDZtrtJYx6tlZOmojF3HapHlrttBLRdd8I861T03Xbewr3HLpqMklRJakI1hM0IsPkLpq7plHhLCFohOmMdtMfaicVjhKwQhi41d9m0uT3LNDRqQzIVfLunFxUDED75JMrPO6/gF7HaktpQLW3xVrrinYQ94c0WCUpPQf7J1zU8xkspRV+yj5SToshbRMJO0JXoIuIpymro1kJBzM+cgPHpoxncLeG89DqpW+5EO/pQjL3n4S6YnydSKewlj0EsjjZ7BubnT0X71B5ZrRvqT/STIkVNsIZibzGpcQzZeXSLykAlYU+Ytmgb3YnugXqckLxhypIt7Vl22pzTJrU9Em7yhBONovv9AIRPOZm3PR4OOeF4mdGDO4ZeZ9XR0t9CW6yNgDl613Ih9hSI3IslY/Tb/QTNoNtrYIVJOAma+pvoGliEMts9AZsuUeC88qa74/TDy5i95HHsw+ejnXwsek1VVp93LFQyifPq2+6sQ01DC4cwz/4shIPu/k9ZDgz9iX5sbGpDtRRtYSbl5vhNP9NC0+hJ9tAabaUz3kHACOCz8q83bKrZdM8yhULXdBSKKxdcOanFxCDhJudUIknbrbcSfeMN6n51A7rfj6ZpxGZN/roA+czUh+5LlUqkCHqCI962UHoKRO6lnBS9yV4szXJ7DHzFmJr7Z9NreKkN1mJoBu2xdsJWGMuYuF5W87/Ox1l4IKkH/4n+/seox58j+cTz6Afth3HycZl90SaSsm2cZ14i9beHoaUN638uRtvbLeI3Fh06Ic/Zl+hDoagN1RLxZGFWnQZhT9itx4l10RbbWI/jMfJjo+GpKr1n2T/rB9a5mTmXz+x8+qQHG5Bwk1PJ+nqarvkJiY/dVTr7X3mF0KET8weiEGiaRpm/LLMezvZSh6MGhthUXxTCIwc6kV2OUvQle3GUQ6m3lBJfCT5z+Lt7UzepCdZgahYt0WYCauIKVjVNw5i7N+y7JyuffIOZ/3oe9fq/cV58DdXeiefqSyfkecFdcdp56TXse/6Oqm90D5YUTfhihL0Jtwe2NlS72cU9t4ahGZT6Swl5QnTEOuiIdxBNRQlb4SmzSGQ+qvFVclb5sYBil32PkxWKtze9Tz9Nyw2/QkWj6JEIld/5NoH9Zf2VsQh7wli65Q4JxDqJeLM/JJAPbMfB6e4mmUgCOik7hdHRCUWRrdr8UYxNNBklZscIeUKU+8oJWaGRZ+QM0DWdqkAllm7SFG3abK9itsRmz8I4Yl+0dfXYDy0dsnaT6unDee8D9P0/tc2vE6UUzuv/xv7zA6g1692DoSDGqce5U7oncHXvnkQPOjq1oVpCnomrlfMYHqqCVW49TqyNrngXlm4RtIIFsdbQ9krCzSRz4nHabvkdPf/8JwC+Pfeg8vvfxywv38I9xWA+00ddqI4Wfct1OPlKKYWtbGxn4B82jnLc9ThiCfT+KHokDFWVsKKVaG0R8eY2/C2tWKUl232hebYl7SS9yd7McFORryizKeAWDex2bxomjb2NdMe7CXsmfsVlfeY09E02j7WXPol9z0NotdUYJx+DvvAgNGsr/9Q7DvYdf0U1NIHf5+5ufsIitIA/C60f3WQFm8ECVgC/6afIW0RrfysdUo8zpUm4mWTtt97qBhtNo/hzZ1LyhS9I0fBWStfhWIZFS7RlUt4xj8fg8OIoh5RKbQwvuMMMuqZjaAaGbhAwA1jKwOjtx/AU4ZlRja+yGnSTVSuWsUP1HnQWt9G1biXRlnp8gSK8keLcfpMFwFGOO/yhQbmvPLMVyNaIeCKYYZPGvsYJmUk1Jh4LggFUfSOpm++Aex7C+PQijKMPRRvDNHLn41VoM6ehWZa7ae1Zp6I+WoVxyrGTMtuwO96NpVvUhGoIWpP7+6xpGhFPZGM9TtStxwlawQmtpxLZJ+FmkhWfdRax91ZQet5XCOy3X66bM+Vpmka5vzwndTibCy8aGkpTbnAZ+Be2wnh0D6ZhYmomhmZg6iaG7n7d6evDiUUxqmZhVVVhhNwLSXJgMbSQJ0RxoJi+cDVt9SvpXPsR0ca1+Esr8Hom9p10IVJKEU1GiTtxirxFlPhKCWXhYhqwAtSF62jub56wmVSbY550DMaiw7Afewb74eXQ3ol959+w73sE48RFmJ/5NKqlbdiMQtXQjP3Ec6i338M87yyMY48AwDhoLhw0d1La3h3vxqN7qAnVELACk/KcIzE1kzJ/GSFPiPZoO52JTqKpKCFPSLZymCIk3EwwJxaj74UXCB95JABmSQl1v/6V1ExkWcQTwaN7sjo1VynlhhYnNSS8oAb2TtEYEl6CZgiv4cEyrEx4MXT3n4k5at2GSiRJdXeg+/x4Z8/GKCkZtTdP0zRCnhChWXtTVlxD26r36WrdQH/QS8AfmXJDc7kST8XpT/a7U4PD04h4Ilm9aHkNLzXBmsxMqpAVmtR3/prfh3niYoxjj8B55iXshx5FNTSjmlpRLW0k/uu/R14LaoBqaZu0toL7u9ad6MZn+KgJ1eA38yOsp3+OYW+Ejlg73YluPJoHv+WXepw8J+FmAiXWrKHpx9eQXLsWzTAIHXYYgASbCZKuw2nub6Yj1oHf9G/2Yj9SeEkfAzLhRUfH1M2tDi+jPr/j4PT0oGwbs7ISq6oK3Tf28f1QcQXBPYvp2bCGznUf09XTTb/fxG/4pU5gFLZj05vsRdd0KoOVlPhKsPSJCR3pYVNTN2npb8Hn+Cb956JZFsZRC9EPPxjnlTfQZtS5PTabCTbmty9we2smyeBgUxuqHXFWWk5pELKCBEw/4USY9mg7HfEOgmZQ3kzkMQk3WZCsryfV0YFKJIivXo3m9RJ99TU6770XEgmMkhKM4uJcN3PMlFKoeBzN45lyQWzwejjpOhxTN1FKZXpexhJe0r0x6WGjrQkvm+PEYji9vRjhMFZ1NXpR0Va9E9Qsi/DMHQmES4isXU1PXztdvhTtsXY35Jg+eYfJxtWFk06SYm8xZf6ySekd0DWdSn9lZnafnbBzUhemGXomsDgr12z+tpWTN7lBKUVXogu/4c/PYDOIrukUe4sJWe7U8fZYO9F4lJAV2uyq6SI35CeyjZL19Xxy7HGoRGLEr3v32IOqy3+AWZJHS6VvRvqiq/t82H19aKaJHgpNqaJnXdMzdTgtfS2kHDfgBMwgHt2Dx7AydS4TFV5Go2wbu6sLzTSx6uqwKiq2edaTpmmYZWVEfD58GzYQbm+hz6/TaffSEe/Ap/u26270eCpOf6qfgBnIrC48qedCgxJfCaZu0tDbMGkzqfJdOtgEzAC1oVq8xtToBTF1k4pABWFPmPZYO53xzoGtHIJSj5NHJNxso3SPzWjK/uOrUyLYZC66uo5VW4tZWooTi5Fqackc10MhNHPqvGQinggB0y1KNLXJCS+bY/f2omIxjNJSrKpqjFB238HrwSDe2bPR/QGs5iYiZjl9fpVZoMyre/FbgYJf9DAtvbpwepf5Ym9xTt9hhz1hzIgbcLriXUS82a3zmUocpeiOdxH0BKkJ1kyZYDOYz/RRG3RXTU6vj+P+jm2/byTyydS5Uk1RU2FYJ3PRLSlxZ+mE3ZVAdb8fIxLB7u4m1daG3dUNKIxweMqssZIP3cUqkcTu7kL3+/FsoWB4W2mWhTWtDj3gJ1lfT7g/QahoGr2pPjqiHXTHu9xeLCtQsBfW9OrCSil3CMpXljfDHekCZrfwvWuLG8EWIkepzCa4NcGaqb3lgebOYgxYAboSXbT1b9zKQepxcmv7+q0SQ2Quur7RL7qaYWCWlGAUFeH09Lghp6MTUGihELpnCv9hmmDKcXC6e1DO1hUMb630MJXu85HYsAG7vZPiomIiRRF6Ej20R91ZH+4Mr2BBLTWf3uAyZIWo8FdscXXhXPAY7lRnUzNpi7URtIKTeoHXwiGwzJGLii1zQteycZRDV7yLIm8RVcFqPBNUzD3ZdE2nxFsypB4nFo8RskIFuXr6VCDhZjukBpb1x1FY1dWYFRVbvOhquo5RVIQeieBU9JJqbcXu7MTu7kYLh9EncBn2qciJxXB6ejEi21YwvC3Sw1TJxiaSzU1oHg/FoWIingi9yV46Yh1uyNGnfshJry7s0T3UBevGt7pwDpiaSVWwClM3ae5vxnGcSZtJpVWU4bnh6mHr3IAbfCZq09nBwaY6WD1hs9RyydItKgOV7lYO0Ta6E90D9Tih7WY4OF9IuNnOOP39OH39GEUR96IbiYzroqtpGkY4jB4K4fT1Y3e0k2pvJ9XTgx4KTUrPRD5Tto3T1QWmiTVjOlZZWU6H8DYdpkq1t2MUuwEnZIXoS/bRGe+kJ9GDhkbACkypYZJsri482XRNp8JfgWmYNPW5e1JN1lYDWkXZhIWYkTiOG2yKfcWZ6fGFzG/6mRaaRk+yh9ZoK52ylcOkK+xX2CQwS0rQPJ4Ri4o1y8KIRHLQquFUMonT1YXm9WLNnOFedLehOFjTNIxQECMUxCwrI9Xejt3eTqq3Fz0QQA/kbnXRXLF7e1Hx+EDtUvYLhrfWsGGqtjaMomJ0j0XYE86EnI54Jz2JbgCCZhAzR7v5jsWIqwubwbwbgtoiDUq8JViaRUPfQKGxZ3xvOPKd4zh0Jjop8ZVsF8EmQ3OLyDNbOcQ21uNMlQA+lW0nr7KJY9XWsuOj/xyyzo3u86GZJkYkgllZmdP2KaXcheJSKczycrfuI8vBQw8E8AQCOOXlpDo6sFvbSLW0oAcCaIFAQf2hHsmQguFZszBKS/OykHykYSojFNq46rEVojfVR2e8g55EDyql3P2u8mxPnXgqQdyJ4jf81IXrKPIUTfni6JAnxDR9WsHNpLIdm+5EN6W+UncYTtv+LjmGZlDqLyXkCWVmLkZTUcJWeEoPBee77e+VNgGs2lqs2lqcWAw0zb2o58FsIrfuowcjHMacMQOjuHhCg4bu8+GpqcEpLSXV2Ynd2ord2obm86IHg3l5wd8WgwuGrepqzMrKvK89Gm2YStP1zEqsITNIv7efrngXXYku+lJ9BMzcv9t0HHfD0aSToDIwsasL54Lf9DMtMp2mvkY6B7YQmcq9HCknRXeimzJfGVXBqryugZoMHsNDVbDKrccZmDpu6RZBK1jwbwBzYer+5ohRuXUf3WDoWNOmYZWXo03irCbd68VTVYUqKcHu6iLZ0orT3g4ejxtyptCCgKNxolGc3j6MSASruionBcNba7RhKs0zEBQ0d/PHgBWgOFVMV8wNOem9mCZ7iqtSiv5kP7FUHIBpoelEfJNTmzJSW1Q0iopGwTCy/nP3DOyGnZ5JFTCn5pTilJOiJ9FDua+cymDldh9sBgtYAfymnyJvEa39rXRIPc6EkHBTQJRSOL29qIEtHwbvLJ0LmseDWVGBUVzsrpXT0oLd2YlmmOjhqbXqcVq+FQxvi9GGqQbzm378Ib8bcuJddMY7icaikxZyBq8uXBeuoL5xHQFr8jdVVLaN09eHiifQ/X7M6mqc3l43GGZ53aL0ooOmbtISbUEpNaUufCk7RU9yY7AphOG1bNM0zV1kNF2PE3XrcYJWMO+GgacqCTcFwkkkcLq73fqX9Jo1eTIMpFkWZlnZ0JAzBVc9tnt6UIkEZmkpZmVV3hQMb4tNh6ns9g704qJhrx2f6cNn+ij2FdMd76Yj1kF/dGNPTrZ7rUZaXRg1+T1jTiyG6u9HgTu8O20aejiM7vHgJBIk12/AbmvN+nIImqYNmUmVTCQJe8JZe/yJkp6SL8FmbEzNpMxfRsgToj3aTmeik5jtro8zVXqC89XUuKqIUSnbdteaAazqGszKiryt+xiyIGB3N8m2NuzOToC8XvU4ExwHrzCcJ8ExG4YMU9XXY7e1oRcVjbhAo9fwUhGooMhbRHeiO1Mgma1NOtOrCzvKGba6cMq2t+mxx0rZNk5/PyoWQ/f5Mr2Peig05Oeuezx4Zs4g6fOSbGhEJZPZ7SkdNJOqsa8xM5MqX6WDTYW/kspAhVycx8FreKkJ1hD2Rmjua6In0UPEm78/66lAws0U5vT1o6L9GEVFWNXVeTPtfEs0XXcvFulVjwcWBETl16rH6YJhHGfKFAxvCz0YxDtrFkmfn2RzE2qEYao0j+Gh3F9OkbeInngPHbEOOuOd27S3TiwZI2pHCVrBnKwu7CQSOL3uwnZGIIBRVY1RFNns2k2aYWDV1KD7fCTXryfV0ZH1wv3MTKq+BjrjnYSs/Ps9T9gJ+lP9VAYqqfBLsNkqAwX9erCaDb0b6En0TIneunwl4WYKctes6UbzebFmzMQsK50yQzuDaZqGEYmgh8M4fX0DWzt0uD1RoRDksCdnSMFwzfgXO5yqxjpMlWbpFqX+UiLeCD3JHjqibsjx6J4xb9KZrtHw6B5qg7WTurqwchxUNIoTjbrDp6WlmCUl6OHwmOtoNE3DLC1F83hIrl8/IXU4PtNHXXgazX1NtEc7sva42ZCui6oKVFHuL98ufk8mUsAKUBOqpb5nA32JPoKeqT/8nQtT74q4HVOO465ZYzuYlRVYlZXo/skvrsw2d0HAEEYohF1WvnHV4+7uSW9LIRUMb63xDFOlmbpJibeEsCdMT8INOV3xTizdGnWTzsGrC5f5yij1l07a7tAqmXQLhFMp9EAAa/p0zEhkm9aAMkIhtNmzSW7YQKq1DT2S3Tqc9EwqTenU00o8lSDgyW2hcTwVJ5qKUh2sptxXPvUWUcxTIStITaiGDb0biCaj+HNQRD/VSbiZIjb2JORur6LJMHjVY9XaCo2NpFpb0UNhtMDWDXeMxeCZZmZpqbvYYXD7fsc0nmGqNFNzQ056/6qRNulMry6ccBKEvWFKfWWTsrpwZhp3f39mGrdZWuqGkiwFWN3rxTNzJprXS7KxCVKprL6ODM2gMlAJtBK3Y2hJlbMLXzwVJ2bHqA5WU+Yrk2CTZWFPmOpgNQ19DegpfUouCZBLEm7ynEql3J4Ey9quehL0QABPTQ288QbmtGnQ0en2IPj9WV/1OJ9nmuXaeIep0gzNoMhTRNgKD9mkU9d0bGXjM3zUhmsnZXXhYdO4a2vd7SeCE7N6tmYYWLW1bs/XBNThpB+nOlhDW6wlJ7UZsWSMuBOnOlBNqa9Ugs0EKfYW4zgODX0NABJwxkHCTR6ze3shldruexI8VVUYlZXYHZ2kWluyturxsN3RC7xgeGttzTBVmq7pRDwRwlZ4YP+qDryGl2JfCZ4JXl14c9O4J1r6nGle74TV4RR7i/CZHpr6miZ1T6pYMkZCJagJ1lDiLZFgM8FKfaU4ODT1N6FruqyDM0YSbvKQE4sB7jtAb3rbhO28J0H3eNCrKjFLNq6V47R3gMfaqlWPM8N8W7k7+vZoa4ap0jL7V03wrtdjncY9WYbV4RRFshquQp4Qpm7S2O9u2VDkKZrQ/YqiyShJlaQ6WO0GGzHxBmrSbMehJdpMWAtP6W05JoucoTyibBu7qws18Llnhx0wt9PemtFoHg9mefnGBQGbW7A7u9AMY0yrHg8Z5svC7ujbm+HDVO3oeRC+t2Ya92TRvV48M2YM1OE0gteb1V5Yn+mjLlRHU18THfEOIlZkQnZ070/0Y2NTE6xxF1UU46IcB5Ry/zkKhYLBx5RCOQ6arqN5vUP+LmmaRkWgHEfZtMZaKfYUy6abWyB/1fOE09eHE41ilJRglJXB+vV5s95LPtJM0y0GLSoasuoxmuYuCLhJYJGC4ezZlmGqbFJKofr7cWKxzOthvNO4J4tmmm4djtdLYsOGrNfhWIP3pIq34VfZ3R4jE2xCNRR5irL2uPlGqYHAAeA4wz5HKfdY+rgCpTYGFE0plKaBpoGj0Bi0sLamuT9vTQNd3/ixpoGmo+maW0+ZmRVro1kWms+H7vWiazqVwUocHDpiHRR5J75ebSqTcJNjKpHE7u5C9/nxDhSzptK/TGKLNrvqcSiM5rGGFgzvsIMM82XJtgxTbQuVTGL39KJSSXca97Rp2zyNezJomoZZXp6pw3Ha2tFLirMWxAzNoCpYhWmYNPc3Yzs2Ac+2n5PehNsjVhuqzdsVkpVto5LJjb0iapNekk0CCJrm9pC7H2Z6y9E0NDTQ3QAC7qKj6RCi6TqaboChg2G4nxuG+7FhZG4zLMDouhtgNNyPB26jZb6mZf4mZdZe6u8n1dWF09fnbv2i6+h+P5X+Chzl0BXvokh60EYl4SZHhhSzVlW5xazpLnQJN+M2bNXjgQUBVVfKfdcsBcMTIjNMFQyQ3LBhwoaplFI40Sjg9nKaJSVZn8Y9WYxwGG2HHSakDkfTNMr95ViGRWNv4zbPpOpJ9KCjUxuqnfB6qa1l9/ZCMonu84OuuT0guuWGBtNE07RMAMEw0AZ6SdgktIwUODYNKJPxpkjTdbRgED0YxKyowInFcKJR7O5unJ4etK4o5baFY5t02+2EfFL7NBIJNzng9Pfj9PVLMesEGLLqcUUFdnc3RjAo53gCpVfo1b3erA9TDZ7GzUAw9ew0B2/R1P55ZupwPB6STU3g9aEHs9fzVOQpwgibNPW6hcYRT9GYVoseLJ+DjVIKu68PAN003YkX4XCmV2QqvzY2pft8bnF8SYm7+GQ0itXbS1V7ALt1FT1d64EgKpECn5QypEm4mUTutgldaF6vFLNOsMGrHovJkc1hqiHTuEMhzLo6bL8fVq/CmKD1aSabZppYdXVu7dKGDdidnVldnDNkBTHDdTT1N9E1zplUPYkeDM2gJlRLyMqv2jSnrx8n2o820NPt2WEHzDwfkswWzbIwLMvdFqa6GqO7ltUNH8CHbRCPo3r73CEznxe8nu16+F2urJNAKeUWiKVSmOXlbjHrdvLLKLYv2zJMlZnGHY+je73DpnGrZHISvoPJNdF1OD7TR22olqb+JjpjnYSt8BZnUnXHuzMFysE8CjZOLIbT24vu82PNmIEKhWDlyik3LJktmq4TKq5gmmXxyYdP0zetlGLNh9PTB7290NmNUri9OT5v3hXZTzQJNxPMicVwenrcRcTSa9YUwLtOIUYz3mGqzDRupTCCwbyaxj1ZjHAYbfZstwenrT2rdTiWblETrMHSLFpjraPOpFJK0ZNwNzCtCdUQsPLjDZgTj6N6esFjYdXWYpaXo3u9JAsw7G6N9MaamtdLr6kTLq5FpVLQH0X1R1HdPdDdh7JT4LHA50PzFH4glHAzQdJr1miGgTVtGlZ5OZpM7Rbbkc0NU02ladyTRff58M6cSdLjJdmc3TocQzOoClRh6ibN0WbsxNCZVEopuhPd+AwfNaEa/GbuN2pUiSROTzeYJmZ1lbv8gPR4j6ouXMeG/g30JfvcHrdIGC0SRlWWQzQGsRhOVw/096O6ewt++ErCzQRw+vpRdgqjpASrqkrqPsR2a6RhKnRjyk3jniyaabrny5+uw+lCz1bxtAZl/jJMw6Spt4meRA8hy/3blA42taFafGZue8xUKoXd3Y2GhlFejllegRHKn+GxfFXsLUYzNNb1rENP6ZmAquk6BAMQDKCXlkA8AdEoTm9/QQ9fSbjJsvSUQs+M6bIBoxAMH6ZC16fsNO7JkKnD8XhIrN+A09aGnsV9qYo8RZhh092TKtEFgN/w5zzYKNt2axMd5U71r6hw661kGH/Myv3lOI7Dup51aGjDfp6aprm9NT4vRknxCMNXvSjbLojhKwk3WaR5PO4qpOGwrKcixCb0YBDvTjsByAVrDIxIBO8OnkwdjlFUlLWLTdAKUjcwk8p2bGpDtXiN3PzNUukVeVMpjKIirIqKrM4a295UBCqwlU19Xz26puMxRi+H0Exz88NXPb3u+kBez5QbvpJwk0WarmOWl+e6GULkLblgjc+QOpymRnS/P7Pez7byGl5qQ7WgyMlGjOktUYjH0cMRzKpKjEikYIZFckXTNKqCVTjKoaGvgSJvEZa+5VA8+vBVH/T2TbnhKwk3QgiRx9J1OJrX425WGotn7bFNzYRJzpuZYvL+KHowiDW71p1FKmt+ZY2u6VQHq7GVTVN/E6XeUgx97GFk2PBVMgnRmDt81TVo+MrrAa83L4ev5NUkhBB5TtM0rIEtWuw1awC3RoU8f/e8Kae/H6e/H93vxzNzJmZJscwinSCGblAbqsVRDq3RVkp8JRja1r1eNMsCyxo6fBWN4XSPMHzly4+SjHGHm2g0ilKKwMDshjVr1vDAAw+w++67s3jx4qw3UAghhMuIRPDMmgUrV2J3dmIWl+Tlu+ZNObEYTl8futeLNX26W2AuoWbCmbpJXagOW9l0xDoo9ZVu807iQ4avykYYvmrvhES/e5scGne4OfnkkznttNO44IIL6Ozs5MADD8SyLFpbW7n22mv5+te/PhHtFEIIAZnFDc2qKuzWVnS/P2+n0juJBKq7Gzwed/PasjK3bkhMGsuwmB6ejqMcOuIdlHpLs1b7NtrwFV3tkEq5G47myLgj3Ouvv87ChQsBuPfee6mqqmLNmjXceeed/OpXv8p6A4UQQgxn1dbimTEDlUxid3XlujlDqGQSu70d1d+PUVmJb6ed8EybJsEmRzyGh+nh6QTNIB3xDpRSE/I82sDQFdUVMK0mpxMIxt1z09/fTzgcBmDZsmWcdtpp6LrOQQcdxJqBsWAhhBATK1OH4/WSWL/e7cXJ4no4W0PZNnZ3NyjlrjpdUSGLmOYJn+ljRmQGa7rX0BnvpMRXkusmTahx99zstNNOPPjgg6xbt46lS5dm6myam5uJRCLjbsBNN93E7Nmz8fl8zJ07l2effXazt4/H41x++eXMnDkTr9fLjjvuyO9///txP68QQhQCo6gI7w47oJeWur0licnfc0nZNnZnF3ZXF0ZREb45c/DMmiXBJs8ErADTw9OxDIuueH719mXbuHtu/t//+3+cddZZXHzxxRx55JHMnz8fcHtx9t1333E91j333MNFF13ETTfdxMEHH8wtt9zCcccdx3vvvceMGTNGvM8ZZ5xBU1MTt912GzvttBPNzc2kUqnxfhtCCFEwdL8f74wZJD0ekk3N6H7fpNThKMfB6e1FJZMYkYjbU1NUNKUWe9vehDwhpoens6Z7Db2JXkKewgyg4w43p59+OocccggNDQ3ss88+meNHHXUUp5566rge69prr+W8887j/PPPB+D6669n6dKl3HzzzVxzzTXDbv/oo4/y9NNPs3LlSkpLSwGYNWvWeL8FIYQoOO4+XtPQPF6SDfWZXpSJoJTC6euDWAw9HMacPt0NNVNsavr2qshblAk4mY02C8xWrXNTXV1Nb28vy5cv59BDD8Xv97P//vuPq3gokUjw2muvcemllw45vnjxYl544YUR7/P3v/+defPm8bOf/Yy77rqLYDDISSedxA9/+EP8oxSqxeNx4vGNi151d3cDkEwmSSYnv/t2LNLtytf2TRY5Dy45Dy45D64tnofSEnTTIFlfT6qlxd3KIIuhw+mP4kT70QMBzGnT0IuLUaZJynHAcbL2PFsirwfX1p6HkBGi2l/Nhp4NKFtldSd4O2Vn2rStU88HG8/3OO5w09bWxhlnnMGTTz6Jpml89NFH7LDDDpx//vkUFxfzy1/+ckyP09raim3bVFVVDTleVVVFY2PjiPdZuXIlzz33HD6fjwceeIDW1lYuvPBC2tvbR627ueaaa7jyyiuHHV+2bFlmrZ58tXz58lw3IS/IeXDJeXDJeXCN+Tw0NExcI1aunLjHHiN5Pbjy8TysJLuvj/7+/jHfdtzh5uKLL8ayLNauXctuu+2WOX7mmWdy8cUXjzncpG3a26OUGrUHyHEcNE3jj3/8I0UD3a3XXnstp59+Or/5zW9G7L257LLLuOSSSzKfd3d3M336dBYvXrxVBdCTIZlMsnz5chYtWoS1He+aLOfBJefBJefBNZ7zoJJJks3NpJqb3fVwtmIqthOPo3r70Lwe9LKyvFmAT14Prm09D0opmvubaehrIGSFNrvR5lj1J90QsnPpzlntuUmPvIzFuMPNsmXLWLp0KdOmTRtyfM6cOeOaCl5eXo5hGMN6aZqbm4f15qTV1NRQV1eXCTYAu+22G0op1q9fz5w5c4bdx+v14h1hoznLsvL+F2IqtHEyyHlwyXlwyXlwjek8WBbWjBmk/AGS9Rugt3fMdTgqkcTp6cYwTczaGszy8rxcp0ZeD65tOQ+1Vi2aodHQ14BpmWPaaHNzDGVk2pTNcDOe72/cz9rX1zficE5ra+uIIWI0Ho+HuXPnDutKW758OQsWLBjxPgcffDD19fX09vZmjn344Yfouj4sbAkhhHCXy7eqKvHOno1mmthtbajN1MaoVIpUeztOXy9GRQXenebgmT49L4ONyI70RpuVgUo6453Yjp3rJm2zcYebQw89lDvvvDPzuaZpOI7Dz3/+c4444ohxPdYll1zCrbfeyu9//3tWrFjBxRdfzNq1a7ngggsAd0jpnHPOydz+rLPOoqysjC9/+cu89957PPPMM3z3u9/lK1/5yqgFxUIIIcAoLnbXwykqctfD2aQ4012rphO7uwezpATvnDl4ZszACBXeTBoxXHqjzQp/BR3xDmw1tQPOuIelfv7zn3P44Yfz6quvkkgk+N73vse7775Le3s7zz///Lge68wzz6StrY2rrrqKhoYG9txzT5YsWcLMmTMBaGhoYO3atZnbh0Ihli9fzje/+U3mzZtHWVkZZ5xxBldfffV4vw0hhNju6IEA3lmzSKRnUgUCaF4vTk8PKpXCKC7GqqhAj0RyunS+yI2J2GgzV8YdbnbffXfefvttbr75ZgzDoK+vj9NOO41vfOMb1NTUjLsBF154IRdeeOGIX7v99tuHHdt1113zsipcCCGmAs2y8EyfjubzkdqwAaevDyMcwayqlAX4xIRutDmZxhVukskkixcv5pZbbhlxerUQQoj8p+k6nqoqDJ8PZdsYkQiauVXLnokClN5oc3XXajfg+Epz3aRxG1dEtyyLd955Z0qmOCGEEEMZRUWYpaUSbMQw6Y02/aafjlhHrpszbuPufzznnHO47bbbJqItQgghhMgTU3mjzXHH9UQiwa233sry5cuZN28eweDQSvprr702a40TQgghRO5M1Y02xx1u3nnnHfbbbz/AXWNmMBmuEkIIIQrLVNxoc9zh5sknn5yIdgghhBAiT5X4SrCVzdruteiantWNNifCNlWRrV+/Hk3TqKury1Z7hBBCCJGHyv3lOI7Dup51aGj4TF+umzSqcRcUO47DVVddRVFRETNnzmTGjBkUFxfzwx/+EGcSt7sXQgghxOSqCFRQG6qlL9VHwk7kujmjGnfPzeWXX85tt93GT37yEw4++GCUUjz//PNcccUVxGIxfvSjH01EO4UQQgiRY5qmURWswlY2jX2NFHmLtnmjzYkw7nBzxx13cOutt3LSSSdlju2zzz7U1dVx4YUXSrgRQgghCpiu6dQEa3CUQ1N/E6XeUgzdyHWzhhj3sFR7ezu77rrrsOO77ror7e3tWWmUEEIIIfJXvm+0Oe5ws88++3DjjTcOO37jjTeyzz77ZKVRQgghhMhv6Y02S3wldMQ6cFT+1N2Oe1jqZz/7GSeccAKPPfYY8+fPR9M0XnjhBdatW8eSJUsmoo1CCCGEyEMjbbSZD8bdc3PYYYfxwQcfcOqpp9LZ2Ul7ezunnXYaH3zwAQsXLpyINgohhBAiT6U32gyaQTri+bEP1Vatc1NXVyeFw0IIIYQANm60uaZ7DV3xLiKeSE7bM+6emz/84Q/87W9/G3b8b3/7G3fccUdWGiWEEEKIqSW90WY+7D817nDzk5/8hPLy8mHHKysr+fGPf5yVRgkhhBBi6klvtBnyhNDI3X6T4x6WWrNmDbNnzx52fObMmaxduzYrjRJCCCHE1FTkLaLIW5TTNoy756ayspK333572PG33nqLsrKyrDRKCCGEEGJrjTvcfO5zn+Nb3/oWTz75JLZtY9s2TzzxBP/1X//F5z73uYlooxBCCCHEmI17WOrqq69mzZo1HHXUUZime3fHcTjnnHOk5kYIIYQQOTfucOPxeLjnnnu4+uqrefPNN/H7/ey1117MnDlzItonhBBCCDEuW7XODcCcOXOYM2cOqVSKWCyWzTYJIYQQQmy1MdfcLFmyhLvuumvIsR/96EeEQiGKi4tZvHgxHR35sTKhEEIIIbZfYw43v/jFL+ju7s58/sILL/D//t//43/+53/461//yrp16/jhD384IY0UQgghhBirMYebd955hwULFmQ+v/fee1m0aBGXX345p512Gr/85S95+OGHJ6SRQgghhBBjNeZw09PTM2Qdm+eee44jjzwy8/kee+xBfX19dlsnhBBCCDFOYw43tbW1rFixAoDe3l7eeustDj744MzX29raCAQC2W+hEEIIIcQ4jDncnH766Vx00UXcddddfPWrX6W6upqDDjoo8/VXX32VXXbZZUIaKYQQQggxVmOeCv6///u/1NfX861vfYvq6mruvvtuDMPIfP3Pf/4zJ5544oQ0UgghhBBirMYcbgKBwLCp4IM9+eSTWWmQEEIIIcS2GPfeUkIIIYQQ+UzCjRBCCCEKioQbIYQQQhQUCTdCCCGEKCgSboQQQghRUMY0W+pXv/rVmB/wW9/61lY3RgghhBBiW40p3Fx33XVjejBN0yTcCCGEECKnxhRuVq1aNdHtEEIIIYTIiq2uuUkkEnzwwQekUqlstkcIIYQQYpuMO9z09/dz3nnnEQgE2GOPPVi7di3g1tr85Cc/yXoDhRBCCCHGY9zh5rLLLuOtt97iqaeewufzZY4fffTR3HPPPVltnBBCCCHEeI15b6m0Bx98kHvuuYeDDjoITdMyx3fffXc++eSTrDZOCCGEEGK8xt1z09LSQmVl5bDjfX19Q8KOEEIIIUQujDvc7L///jzyyCOZz9OB5v/+7/+YP39+9lomhBBCCLEVxj0sdc0113Dsscfy3nvvkUqluOGGG3j33Xd58cUXefrppyeijUIIIYQQYzbunpsFCxbw/PPP09/fz4477siyZcuoqqrixRdfZO7cuRPRRiGEEEKIMRt3zw3AXnvtxR133JHttgghhBBCbLMxhZvu7u4xP2AkEtnqxgghhBBCbKsxhZvi4uIxz4SybXubGiSEEEIIsS3GFG6efPLJzMerV6/m0ksv5dxzz83MjnrxxRe54447uOaaayamlUIIIYQQYzSmcHPYYYdlPr7qqqu49tpr+fznP585dtJJJ7HXXnvxu9/9ji996UvZb6UQQgghxBiNe7bUiy++yLx584YdnzdvHv/617+y0ighhBBCiK017nAzffp0fvvb3w47fssttzB9+vSsNEoIIYQQYmuNeyr4ddddx2c+8xmWLl3KQQcdBMBLL73EJ598wn333Zf1BgohhBBCjMe4e26OP/54PvroI0466STa29tpa2vj5JNP5sMPP+T444+fiDYKIYQQQozZVi3iN23aNH784x9nuy1CCCGEENtsq8JNZ2cnt912GytWrEDTNHbffXe+8pWvUFRUlO32CSGEEEKMy7iHpV599VV23HFHrrvuOtrb22ltbeXaa69lxx135PXXX5+INgohhBBCjNm4e24uvvhiTjrpJP7v//4P03TvnkqlOP/887nooot45plnst5IIYQQQoixGne4efXVV4cEGwDTNPne97434vo3QgghhBCTadzDUpFIhLVr1w47vm7dOsLhcFYaJYQQQgixtcYdbs4880zOO+887rnnHtatW8f69ev5y1/+wvnnnz9kSwYhhBBCiFwYd7j5xS9+wWmnncY555zDrFmzmDlzJueeey6nn346P/3pT8fdgJtuuonZs2fj8/mYO3cuzz777Jju9/zzz2OaJp/61KfG/ZxCCCGEKFzjDjcej4cbbriBjo4O3nzzTd544w3a29u57rrr8Hq943qse+65h4suuojLL7+cN954g4ULF3LccceNOOw1WFdXF+eccw5HHXXUeJsvhBBCiAI37nCTFggE2Guvvdh7770JBAJb9RjXXnst5513Hueffz677bYb119/PdOnT+fmm2/e7P2+9rWvcdZZZzF//vytel4hhBBCFK4xz5b6yle+Mqbb/f73vx/T7RKJBK+99hqXXnrpkOOLFy/mhRdeGPV+f/jDH/jkk0+4++67ufrqq7f4PPF4nHg8nvm8u7sbgGQySTKZHFNbJ1u6Xfnavski58El58El58El58El58G1PZ2H8XyPYw43t99+OzNnzmTfffdFKbVVDRustbUV27apqqoacryqqorGxsYR7/PRRx9x6aWX8uyzzw6Zir4511xzDVdeeeWw48uWLdvqHqfJsnz58lw3IS/IeXDJeXDJeXDJeXDJeXBtD+ehv79/zLcdc7i54IIL+Mtf/sLKlSv5yle+whe/+EVKS0u3qoGDaZo25HOl1LBjALZtc9ZZZ3HllVey8847j/nxL7vsMi655JLM593d3UyfPp3FixcTiUS2vuETKJlMsnz5chYtWoRlWbluTs7IeXDJeXDJeXDJeXDJeXBtT+chPfIyFmMONzfddBPXXXcd999/P7///e+57LLLOOGEEzjvvPNYvHjxiIFkc8rLyzEMY1gvTXNz87DeHICenh5effVV3njjDf7zP/8TAMdxUEphmibLli3jyCOPHHY/r9c7YqGzZVl5/0KYCm2cDHIeXHIeXHIeXHIeXHIeXNvDeRjP9zeugmKv18vnP/95li9fznvvvccee+zBhRdeyMyZM+nt7R1XIz0eD3Pnzh3WlbZ8+XIWLFgw7PaRSIR///vfvPnmm5l/F1xwAbvssgtvvvkmBx544LieXwghhBCFaat2BQd3OEnTNJRSOI6zVY9xySWXcPbZZzNv3jzmz5/P7373O9auXcsFF1wAuENKGzZs4M4770TXdfbcc88h96+srMTn8w07LoQQQojt17jCTTwezwxLPffcc3z605/mxhtv5Nhjj0XXxz+r/Mwzz6StrY2rrrqKhoYG9txzT5YsWcLMmTMBaGho2OKaN0IIIYQQg4053Fx44YX85S9/YcaMGXz5y1/mL3/5C2VlZdvcgAsvvJALL7xwxK/dfvvtm73vFVdcwRVXXLHNbRBCCCFE4RhzuPntb3/LjBkzmD17Nk8//TRPP/30iLe7//77s9Y4IYQQQojxGnO4Oeecc8Y9I0oIIYQQYrKNaxE/IYQQQoh8t9V7SwkhhBBC5CMJN0IIIYQoKBJuhBBCCFFQJNwIIYQQoqBIuBFCCCFEQZFwI4QQQoiCIuFGCCGEEAVFwo0QQgghCoqEGyGEEEIUFAk3QgghhCgoEm6EEEIIUVAk3AghhBCioEi4EUIIIURBkXAjhBBCiIIi4UYIIYQQBUXCjRBCCCEKioQbIYQQQhQUCTdCCCGEKCgSboQQQghRUCTcCCGEEKKgSLgRQgghREGRcCOEEEKIgiLhRgghhBAFRcKNEEIIIQqKhBshhBBCFBQJN0IIIYQoKBJuhBBCCFFQJNwIIYQQoqBIuBFCCCFEQZFwI4QQQoiCIuFGCCGEEAVFwo0QQgghCoqEGyGEEEIUFAk3QgghhCgoEm6EEEIIUVAk3AghhBCioEi4EUIIIURBkXAjhBBCiIIi4UYIIYQQBUXCjRBCCCEKioQbIYQQQhQUCTdCCCGEKCgSboQQQghRUCTcCCGEEKKgSLgRQgghREGRcCOEEEKIgiLhRgghhBAFRcKNEEIIIQqKhBshhBBCFBQJN0IIIYQoKBJuhBBCCFFQJNwIIYQQoqBIuBFCCCFEQZFwI4QQQoiCIuFGCCGEEAVFwo0QQgghCoqEGyGEEEIUFAk3QgghhCgoEm6EEEIIUVAk3AghhBCioOQ83Nx0003Mnj0bn8/H3LlzefbZZ0e97f3338+iRYuoqKggEokwf/58li5dOomtFUIIIUS+y2m4ueeee7jooou4/PLLeeONN1i4cCHHHXcca9euHfH2zzzzDIsWLWLJkiW89tprHHHEEZx44om88cYbk9xyIYQQQuSrnIaba6+9lvPOO4/zzz+f3Xbbjeuvv57p06dz8803j3j766+/nu9973vsv//+zJkzhx//+MfMmTOHhx9+eJJbLoQQQoh8ZebqiROJBK+99hqXXnrpkOOLFy/mhRdeGNNjOI5DT08PpaWlo94mHo8Tj8czn3d3dwOQTCZJJpNb0fKJl25XvrZvssh5cMl5cMl5cMl5cMl5cG1P52E832POwk1rayu2bVNVVTXkeFVVFY2NjWN6jF/+8pf09fVxxhlnjHqba665hiuvvHLY8WXLlhEIBMbX6Em2fPnyXDchL8h5cMl5cMl5cMl5cMl5cG0P56G/v3/Mt81ZuEnTNG3I50qpYcdG8uc//5krrriChx56iMrKylFvd9lll3HJJZdkPu/u7mb69OksXryYSCSy9Q2fQMlkkuXLl7No0SIsy8p1c3JGzoNLzoNLzoNLzoNLzoNrezoP6ZGXschZuCkvL8cwjGG9NM3NzcN6czZ1zz33cN555/G3v/2No48+erO39Xq9eL3eYccty8r7F8JUaONkkPPgkvPgkvPgkvPgkvPg2h7Ow3i+v5wVFHs8HubOnTusK2358uUsWLBg1Pv9+c9/5txzz+VPf/oTJ5xwwkQ3UwghhBBTTE6HpS655BLOPvts5s2bx/z58/nd737H2rVrueCCCwB3SGnDhg3ceeedgBtszjnnHG644QYOOuigTK+P3++nqKgoZ9+HEEIIIfJHTsPNmWeeSVtbG1dddRUNDQ3sueeeLFmyhJkzZwLQ0NAwZM2bW265hVQqxTe+8Q2+8Y1vZI5/6Utf4vbbb5/s5gshhBAiD+W8oPjCCy/kwgsvHPFrmwaWp556auIbJIQQQogpLefbLwghhBBCZJOEGyGEEEIUFAk3QgghhCgoEm6EEEIIUVAk3AghhBCioEi4EUIIIURBkXAjhBBCiIIi4UYIIYQQBUXCjRBCCCEKioQbIYQQQhQUCTdCCCGEKCgSboQQQghRUCTcCCGEEKKg5HxXcCGEEKKQ2LZNMpmclOdKJpOYpkksFsO27Ul5zonk8XjQ9W3vd5FwI4QQQmSBUorGxkY6Ozsn9Tmrq6tZt24dmqZN2vNOFF3XmT17Nh6PZ5seR8KNEEIIkQXpYFNZWUkgEJiUsOE4Dr29vYRCoaz0eOSS4zjU19fT0NDAjBkztun8SbgRQgghtpFt25lgU1ZWNmnP6zgOiUQCn8835cMNQEVFBfX19aRSKSzL2urHmfpnQgghhMixdI1NIBDIcUumtvRw1LbWD0m4EUIIIbKkEOpecilb50/CjRBCCCEKioQbIYQQQmTFrFmzuP7663PdDCkoFkIIIfLFmu41PPDRA9T31lMbquXUOacyMzJzQp/z8MMP51Of+lRWQskrr7xCMBjc9kZtIwk3QgghRB544KMHuOLFK9DQUCg0NP7w7h+4csGVnLLTKTlrl1IK27YxzS1HhoqKiklo0ZbJsJQQQggxAZRS9Cf7x/Tv/bb3ueKFK3CUg63sIf//3+f/lw/aPxj1vtFUdMjnSqkxt/Hcc8/l6aef5oYbbkDTNDRN4/bbb0fTNJYuXcq8efPwer08++yzfPLJJ5x88slUVVURCoXYf//9eeyxx4Y83qbDUpqmceutt3LqqacSCASYM2cOf//737N1ikclPTdCCCHEBIimohz4pwO3+XEcHE5/+PQx3/7ls14mYI1tSvoNN9zAhx9+yJ577slVV10FwLvvvgvA9773PX7xi1+www47UFxczPr16zn++OO5+uqr8fl83HHHHZx44ol88MEHzJgxY9TnuPLKK/nZz37Gz3/+c37961/zhS98gTVr1lBaWjrm72m8pOdGCCGE2E4VFRXh8XgIBAJUV1dTXV2NYRgAXHXVVSxatIgdd9yRsrIy9tlnH772ta+x1157MWfOHK6++mp22GGHLfbEnHvuuXz+859np5124sc//jF9fX3861//mtDvS3puhBBCiAngN/28fNbLY7rtb978DX9c8UdsNXzxOkMz+MJuX+Abn/rGsK85jkNPTw/hcDizQrHf9G9bwwfMmzdvyOd9fX1ceeWV/OMf/8isIhyNRlm7du1mH2fvvffOfBwMBgmHwzQ3N2eljaORcCOEEEJMAE3Txjw8dMYuZ3D3irtH/JpCceYuZ474WI7jkDJTBKxA1rdf2HTW03e/+12WLl3KL37xC3baaSf8fj+nn346iURis4+z6TYKmqbhOE5W27opGZYSQgghcmxmZCZXLrgSXdMxNGPI/69ccCUzIqPXtGwrj8czpu0Onn32Wc4991xOPfVU9tprL6qrq1m9evWEtWtbSM+NEEIIkQdO2ekU9qvcj/s/uj+zzs1pc06b0GAD7gynl19+mdWrVxMKhUbtVdlpp524//77OfHEE9E0jf/5n/+Z8B6YrSXhRgghhMgTMyIzuGjuRZP6nN/5znf40pe+xO677040GuUPf/jDiLe77rrr+MpXvsKCBQsoLy/n+9//Pt3d3ZPa1rGScCOEEEJsx3beeWdefPHFIcfOPffcYbebNWsWTzzxxJBj3/jG0CLnTYepRlpzp7Ozc6vaOR5ScyOEEEKIgiLhRgghhBAFRcKNEEIIIQqKhBshhBBCFBQJN0IIIYQoKBJuhBBCCFFQJNwIIYQQoqBIuBFCCCFEQZFwI4QQQoiCIuFGCCGEEAVFtl8QQggh8kCyvp5UR8ew42ZJCVZt7YQ97+GHH86nPvUprr/++qw83rnnnktnZycPPvhgVh5va0i4EUIIIXIsWV/PJ8ceh0okhn1N83jY8dF/TmjAKTQyLCWEEEJMIKe/f/R/8TgAqY6OEYMNgEokSDY04MRiIz9uNJr5eLzOPfdcnn76aW644QY0TUPTNFavXs17773H8ccfTygUoqqqirPPPpvW1tbM/e6991722msv/H4/ZWVlHH300fT19XHFFVdwxx138NBDD2Ue76mnnhp3u7aV9NwIIYQQE+iD/eaO+rXgYYcy45ZbtvgYa77wRQL778/Mu+7MHPv4qKOxB4axmgaO7fb+inG17YYbbuDDDz9kzz335KqrrgLAtm0OO+wwvvrVr3LttdcSjUb5/ve/zxlnnMETTzzB/2/vzqOaOtM/gH8vmBAgEGQRSJGlgIqAqMCM4ogeW0HqbheXHsVR6VBR3Es71qJW69IZl3GpPVa0Ha12zoiOM1IFR0EUF4ZFLEVxCdhOQdQq4AaBPL8/+HGnMWGxLJHwfM7JObnvfe/N8755Lz7eJW9JSQkmT56M9evXY/z48aisrER6ejqICIsXL0ZBQQEqKiqwe/duAICtre1zxdQaOLlhjDHGOimFQgGpVAoLCws4OTkBAD766CP0798fn3zyiVgvISEB3bt3R2FhIR4+fIiamhpMmDABbm5uAAB/f3+xrrm5OaqqqsT9GQInN4wxxlgb6pmd1fBKU9Nm7cNt317IfH21yrz+fQIajQYVlZWwtrKCiUnr3GmSlZWFU6dOQS6X66y7ceMGwsLC8Morr8Df3x/h4eEICwvDG2+8ga5du7bK57cGTm4YY4yxNmRiYdHifQgyGUxkMt39ajQwqamBiYVFqyU3Go0Go0ePxrp163TWOTs7w9TUFCkpKcjIyEBycjK2bNmCpUuX4sKFC/Dw8GiVGFqKbyhmjDHGDKxL164QpFK96wSpFF3a8KyIVCpFbW2tuNy/f3/k5+fD3d0dXl5eWi9LS8u6mAQBgwYNwooVK5CTkwOpVIpDhw7p3Z8h8JkbxhhjzMAkSiU8j31rkN+5cXd3x4ULF1BUVAS5XI6YmBjs3LkTkydPxpIlS2Bvb4/r16/jwIED2LlzJ/7zn//g3//+N8LCwtCtWzdcuHABd+7cgY+Pj7i/48eP4+rVq7Czs4NCoYBEImmz+PXhMzeMMcbYC0CiVMLc11fn1da/b7N48WKYmpqid+/ecHBwQHV1Nc6ePYva2lqEh4fDz88P8+bNg0KhgImJCaytrXH69Gm89tpr6NGjBz788EP8+c9/RkREBAAgKioKPXv2RFBQEBwcHHD27Nk2jV8fPnPDGGOMdWI9evTAuXPndMoTExP11vfx8cGxY8ca3J+DgwOSk5NbLb5fg8/cMMYYY8yocHLDGGOMMaPCyQ1jjDHGjAonN4wxxhgzKpzcMMYYY62EiAwdQofWWv3HyQ1jjDHWQvW/4/L4V8zMzf6n+v9nRjdt5rQUDeFHwRljjLEWMjU1hY2NDcrKygAAFhYWEAShzT9Xo9GguroaT58+bbXpFwxFo9Hgzp07sLCwQJcuLUtPOLlhjDHGWkH9LNj1CU57ICI8efIE5ubm7ZJMtTUTExO4urq2uC2c3DDGGGOtQBAEODs7o1u3blCr1e3ymWq1GqdPn0ZoaGi7T3HQFqRSaaucgeLkhjHGGGtFpqamLb5n5Hk+q6amBjKZzCiSm9Zi8At027dvh4eHB2QyGQIDA5Gent5o/bS0NAQGBkImk+Hll1/Gjh072ilSxhhjjHUEBk1uvvnmG8yfPx9Lly5FTk4OBg8ejIiICNy6dUtvfZVKhddeew2DBw9GTk4O/vjHPyI2NhYHDx5s58gZY4wx9qIyaHKzYcMGzJw5E7NmzYKPjw82bdqE7t2747PPPtNbf8eOHXB1dcWmTZvg4+ODWbNmYcaMGfjTn/7UzpEzxhhj7EVlsHtuqqurkZWVhffff1+rPCwsDBkZGXq3OXfuHMLCwrTKwsPDsWvXLqjVar3XG6uqqlBVVSUul5eXAwB+/vnndrvh63mp1Wo8fvwY9+7d69TXULkf6nA/1OF+qMP9UIf7oU5n6ofKykoAzfuhP4MlN3fv3kVtbS0cHR21yh0dHVFaWqp3m9LSUr31a2pqcPfuXTg7O+tss2bNGqxYsUKn3MPDowXRM8YYY8wQKisroVAoGq1j8Kelnn2WnYgafb5dX3195fU++OADLFy4UFzWaDT4+eefYWdn98L+JkBFRQW6d++OH374AdbW1oYOx2C4H+pwP9ThfqjD/VCH+6FOZ+oHIkJlZSWUSmWTdQ2W3Njb28PU1FTnLE1ZWZnO2Zl6Tk5Oeut36dIFdnZ2ercxMzODmZmZVpmNjc2vD7wdWVtbG/1gbQ7uhzrcD3W4H+pwP9ThfqjTWfqhqTM29Qx2Q7FUKkVgYCBSUlK0ylNSUhASEqJ3m4EDB+rUT05ORlBQkNFfa2SMMcZY8xj0aamFCxfiiy++QEJCAgoKCrBgwQLcunUL0dHRAOouKU2bNk2sHx0djeLiYixcuBAFBQVISEjArl27sHjxYkM1gTHGGGMvGIPeczNx4kTcu3cPK1euRElJCfz8/JCUlAQ3NzcAQElJidZv3nh4eCApKQkLFizAtm3boFQq8Ze//AWvv/66oZrQJszMzBAfH69zOa2z4X6ow/1Qh/uhDvdDHe6HOtwP+gnUnGeqGGOMMcY6CINPv8AYY4wx1po4uWGMMcaYUeHkhjHGGGNGhZMbxhhjjBkVTm4MaM2aNQgODoaVlRW6deuGcePG4erVq1p1pk+fDkEQtF4DBgwwUMRtY/ny5TptdHJyEtcTEZYvXw6lUglzc3MMHToU+fn5Boy4bbi7u+v0gyAIiImJAWCcY+H06dMYPXo0lEolBEHA4cOHtdY357uvqqrC3LlzYW9vD0tLS4wZMwY//vhjO7ai5RrrB7Vajbi4OPj7+8PS0hJKpRLTpk3DTz/9pLWPoUOH6oyPSZMmtXNLWqap8dCcY8DYxwMAvX8nBEHAp59+KtYxhvHQEpzcGFBaWhpiYmJw/vx5pKSkoKamBmFhYXj06JFWvREjRqCkpER8JSUlGSjituPr66vVxsuXL4vr1q9fjw0bNmDr1q3IzMyEk5MThg8fLk6iZiwyMzO1+qD+ByvffPNNsY6xjYVHjx4hICAAW7du1bu+Od/9/PnzcejQIRw4cABnzpzBw4cPMWrUKNTW1rZXM1qssX54/PgxsrOzsWzZMmRnZyMxMRGFhYUYM2aMTt2oqCit8fH555+3R/itpqnxADR9DBj7eACg1f6SkhIkJCRAEASdn0Xp6OOhRYi9MMrKyggApaWliWWRkZE0duxYwwXVDuLj4ykgIEDvOo1GQ05OTrR27Vqx7OnTp6RQKGjHjh3tFKFhzJs3jzw9PUmj0RCR8Y8FAHTo0CFxuTnf/YMHD0gikdCBAwfEOv/973/JxMSEjh071m6xt6Zn+0GfixcvEgAqLi4Wy4YMGULz5s1r2+Dakb5+aOoY6KzjYezYsTRs2DCtMmMbD8+Lz9y8QMrLywEAtra2WuWpqano1q0bevTogaioKJSVlRkivDZ17do1KJVKeHh4YNKkSbh58yYAQKVSobS0FGFhYWJdMzMzDBkyBBkZGYYKt81VV1dj7969mDFjhtYEr51hLNRrzneflZUFtVqtVUepVMLPz8+ox0d5eTkEQdCZJ2/fvn2wt7eHr68vFi9ebHRnN4HGj4HOOB5u376No0ePYubMmTrrOsN4aIjBZwVndYgICxcuxO9+9zv4+fmJ5REREXjzzTfh5uYGlUqFZcuWYdiwYcjKyjKaX6T87W9/i6+++go9evTA7du3sWrVKoSEhCA/P1+cKPXZyVQdHR1RXFxsiHDbxeHDh/HgwQNMnz5dLOsMY+GXmvPdl5aWQiqVomvXrjp1np1k11g8ffoU77//PqZMmaI1UeLbb78NDw8PODk54bvvvsMHH3yAS5cu6czH15E1dQx0xvHw5ZdfwsrKChMmTNAq7wzjoTGc3Lwg5syZg7y8PJw5c0arfOLEieJ7Pz8/BAUFwc3NDUePHtUZzB1VRESE+N7f3x8DBw6Ep6cnvvzyS/FmwV+evQDqksFny4zJrl27EBERAaVSKZZ1hrGgz6/57o11fKjVakyaNAkajQbbt2/XWhcVFSW+9/Pzg7e3N4KCgpCdnY3+/fu3d6ht4tceA8Y6HgAgISEBb7/9NmQymVZ5ZxgPjeHLUi+AuXPn4siRIzh16hRcXFwarevs7Aw3Nzdcu3atnaJrf5aWlvD398e1a9fEp6ae/V9XWVmZzv/ojUVxcTFOnDiBWbNmNVrP2MdCc757JycnVFdX4/79+w3WMRZqtRpvvfUWVCoVUlJStM7a6NO/f39IJBKjHR+A7jHQmcYDAKSnp+Pq1atN/q0AOsd4+CVObgyIiDBnzhwkJibi5MmT8PDwaHKbe/fu4YcffoCzs3M7RGgYVVVVKCgogLOzs3ha9ZenUqurq5GWloaQkBADRtl2du/ejW7dumHkyJGN1jP2sdCc7z4wMBASiUSrTklJCb777jujGh/1ic21a9dw4sQJ2NnZNblNfn4+1Gq10Y4PQPcY6Czjod6uXbsQGBiIgICAJut2hvGgxZB3M3d27777LikUCkpNTaWSkhLx9fjxYyIiqqyspEWLFlFGRgapVCo6deoUDRw4kF566SWqqKgwcPStZ9GiRZSamko3b96k8+fP06hRo8jKyoqKioqIiGjt2rWkUCgoMTGRLl++TJMnTyZnZ2ej6oN6tbW15OrqSnFxcVrlxjoWKisrKScnh3JycggAbdiwgXJycsSngJrz3UdHR5OLiwudOHGCsrOzadiwYRQQEEA1NTWGatZza6wf1Go1jRkzhlxcXCg3N1frb0VVVRUREV2/fp1WrFhBmZmZpFKp6OjRo9SrVy/q16+f0fRDc48BYx8P9crLy8nCwoI+++wzne2NZTy0BCc3BgRA72v37t1ERPT48WMKCwsjBwcHkkgk5OrqSpGRkXTr1i3DBt7KJk6cSM7OziSRSEipVNKECRMoPz9fXK/RaCg+Pp6cnJzIzMyMQkND6fLlywaMuO0cP36cANDVq1e1yo11LJw6dUrvMRAZGUlEzfvunzx5QnPmzCFbW1syNzenUaNGdbh+aawfVCpVg38rTp06RUREt27dotDQULK1tSWpVEqenp4UGxtL9+7dM2zDnlNj/dDcY8DYx0O9zz//nMzNzenBgwc62xvLeGgJgYioTU8NMcYYY4y1I77nhjHGGGNGhZMbxhhjjBkVTm4YY4wxZlQ4uWGMMcaYUeHkhjHGGGNGhZMbxhhjjBkVTm4YY4wxZlQ4uWGMia5cuYIBAwZAJpOhb9++7fKZ7u7u2LRpU7Prp6amQhAEPHjwoM1iepF19vYz1hw8KzhjHdCdO3egVCpRXl4OqVQKhUKBgoICuLq6tmi/8fHxsLS0xNWrVyGXy/XWGTp0KPr27ftcCUljMjMzYWlp2ez6ISEhKCkpgUKhaJXPZ4wZH05uGOuAzp07h759+8LCwgIXLlyAra1tixMbALhx4wZGjhwJNze3Fu2HiFBbW4suXZr+E+Pg4PBc+5ZKpeKM4Ywxpg9flmKsA8rIyMCgQYMAAGfOnBHfN0aj0WDlypVwcXGBmZkZ+vbti2PHjonrBUFAVlYWVq5cCUEQsHz5cp19TJ8+HWlpadi8eTMEQYAgCCgqKhIvlRw/fhxBQUEwMzNDeno6bty4gbFjx8LR0RFyuRzBwcE4ceKE1j6fvSwlCAK++OILjB8/HhYWFvD29saRI0fE9c9eltmzZw9sbGxw/Phx+Pj4QC6XY8SIESgpKRG3qampQWxsLGxsbGBnZ4e4uDhERkZi3LhxDfZXcXExRo8eja5du8LS0hK+vr5ISkoCANTW1mLmzJnw8PCAubk5evbsic2bN+v01bhx4/DJJ5/A0dERNjY2WLFiBWpqarBkyRLY2trCxcUFCQkJ4jZFRUUQBAEHDhxASEgIZDIZfH19kZqa2mCcQN14CA0Nhbm5Obp3747Y2Fg8evRIXL99+3Z4e3tDJpPB0dERb7zxRqP7Y6zDM/DcVoyxZiouLiaFQkEKhYIkEgnJZDJSKBQklUrJzMyMFAoFvfvuuw1uv2HDBrK2tqb9+/fTlStX6L333iOJREKFhYVERFRSUkK+vr60aNEiKikpocrKSp19PHjwgAYOHEhRUVHizNQ1NTXiRH99+vSh5ORkun79Ot29e5dyc3Npx44dlJeXR4WFhbR06VKSyWRasxu7ubnRxo0bxWUA5OLiQl9//TVdu3aNYmNjSS6Xi5P+1X/W/fv3iYho9+7dJJFI6NVXX6XMzEzKysoiHx8fmjJlirjPVatWka2tLSUmJlJBQQFFR0eTtbU1jR07tsH+GjlyJA0fPpzy8vLoxo0b9M9//pPS0tKIiKi6upo++ugjunjxIt28eZP27t1LFhYW9M0334jbR0ZGkpWVFcXExNCVK1do165dBIDCw8Np9erVVFhYSB9//DFJJBJxYsf6STJdXFzo73//O33//fc0a9YssrKyort37+ptf15eHsnlctq4cSMVFhbS2bNnqV+/fjR9+nQiIsrMzCRTU1P6+uuvqaioiLKzs2nz5s0NtpsxY8DJDWMdhFqtJpVKRZcuXSKJREK5ubl0/fp1ksvllJaWRiqViu7cudPg9kqlklavXq1VFhwcTLNnzxaXAwICKD4+vtE4hgwZQvPmzdMqq/8H9/Dhw022o3fv3rRlyxZxWV9y8+GHH4rLDx8+JEEQ6Ntvv9X6rF8mNwDo+vXr4jbbtm0jR0dHcdnR0ZE+/fRTcbmmpoZcXV0bTW78/f1p+fLlTban3uzZs+n1118XlyMjI8nNzY1qa2vFsp49e9LgwYO14rC0tKT9+/cT0f+Sm7Vr14p11Go1ubi40Lp16/S2f+rUqfTOO+9oxZKenk4mJib05MkTOnjwIFlbW1NFRUWz28JYR8eXpRjrILp06QJ3d3dcuXIFwcHBCAgIQGlpKRwdHREaGgp3d3fY29vr3baiogI//fSTzuWrQYMGoaCgoNViDAoK0lp+9OgR3nvvPfTu3Rs2NjaQy+W4cuUKbt261eh++vTpI763tLSElZUVysrKGqxvYWEBT09PcdnZ2VmsX15ejtu3b+M3v/mNuN7U1BSBgYGNxhAbG4tVq1Zh0KBBiI+PR15entb6HTt2ICgoCA4ODpDL5di5c6dOu3x9fWFi8r8/s46OjvD399eKw87OTqdtAwcOFN936dIFQUFBDX5PWVlZ2LNnD+RyufgKDw+HRqOBSqXC8OHD4ebmhpdffhlTp07Fvn378Pjx40bbzlhHx8kNYx2Er68v5HI5pk6diosXL0Iul+OVV15BUVER5HI5fH19m9yHIAhay0SkU9YSzz71tGTJEhw8eBCrV69Geno6cnNz4e/vj+rq6kb3I5FItJYFQYBGo3mu+kSkU/ZLz65/1qxZs3Dz5k1MnToVly9fRlBQELZs2QIA+Nvf/oYFCxZgxowZSE5ORm5uLn7/+9/rtEtfXM/btobir6fRaPCHP/wBubm54uvSpUu4du0aPD09YWVlhezsbOzfvx/Ozs746KOPEBAQwI+SM6PGyQ1jHURSUhJyc3Ph5OSEvXv3Ijc3F35+fti0aRNyc3PFm131sba2hlKpxJkzZ7TKMzIy4OPj81xxSKVS1NbWNqtueno6pk+fjvHjx8Pf3x9OTk4oKip6rs9rKYVCAUdHR1y8eFEsq62tRU5OTpPbdu/eHdHR0UhMTMSiRYuwc+dOAHXtCgkJwezZs9GvXz94eXnhxo0brRbz+fPnxfc1NTXIyspCr1699Nbt378/8vPz4eXlpfOSSqUA6s7+vPrqq1i/fj3y8vJQVFSEkydPtlq8jL1o+FFwxjoINzc3lJaW4vbt2xg7dixMTEzw/fffY8KECVAqlU1uv2TJEsTHx8PT0xN9+/bF7t27kZubi3379j1XHO7u7rhw4YJ4xsjW1rbBul5eXkhMTMTo0aMhCAKWLVvWrLMUrW3u3LlYs2YNvLy80KtXL2zZsgX3799v9KzV/PnzERERgR49euD+/fs4efKkmAh6eXnhq6++wvHjx+Hh4YG//vWvyMzMhIeHR6vEu23bNnh7e8PHxwcbN27E/fv3MWPGDL114+LiMGDAAMTExCAqKgqWlpYoKChASkoKtmzZgn/961+4efMmQkND0bVrVyQlJUGj0aBnz56tEitjLyJObhjrQFJTUxEcHAyZTIb09HS89NJLzUpsgLp7SCoqKrBo0SKUlZWhd+/eOHLkCLy9vZ8rhsWLFyMyMhK9e/fGkydPoFKpGqy7ceNGzJgxAyEhIbC3t0dcXBwqKiqe6/NaQ1xcHEpLSzFt2jSYmprinXfeQXh4OExNTRvcpra2FjExMfjxxx9hbW2NESNGYOPGjQCA6Oho5ObmYuLEiRAEAZMnT8bs2bPx7bfftkq8a9euxbp165CTkwNPT0/84x//aPB+qj59+iAtLQ1Lly7F4MGDQUTw9PTExIkTAQA2NjZITEzE8uXL8fTpU3h7e2P//v3NuozJWEclUFMXnhljzMhoNBr4+Pjgrbfewscff2zocERFRUXw8PBATk5Ou01/wZgx4jM3jDGjV1xcjOTkZAwZMgRVVVXYunUrVCoVpkyZYujQGGNtgG8oZowZPRMTE+zZswfBwcEYNGgQLl++jBMnTjz3zdSMsY6BL0sxxhhjzKjwmRvGGGOMGRVObhhjjDFmVDi5YYwxxphR4eSGMcYYY0aFkxvGGGOMGRVObhhjjDFmVDi5YYwxxphR4eSGMcYYY0aFkxvGGGOMGZX/AwnliYi3PqyqAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_sizes, train_mean,\n",
    "             color='C2', marker='o',\n",
    "             markersize=5, label='train')\n",
    "\n",
    "plt.fill_between(train_sizes,\n",
    "                     train_mean + train_std,\n",
    "                     train_mean - train_std,\n",
    "                     alpha=0.15, color='C2')\n",
    "\n",
    "plt.plot(train_sizes, test_mean,\n",
    "             color='C3', linestyle='--',\n",
    "             marker='s', markersize=5,\n",
    "             label='test')\n",
    "\n",
    "plt.fill_between(train_sizes,\n",
    "                     test_mean + test_std,\n",
    "                     test_mean - test_std,\n",
    "                     alpha=0.15, color='C3')\n",
    "plt.grid()\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('# of training samples')\n",
    "plt.ylabel('Model Scores')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "13d9383a-9a2b-4139-a3df-7f271f61d075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "# plt.title(\"Modeling Time: \"+ title)\n",
    "plt.xlabel(\"# 0f training Examples\")\n",
    "plt.ylabel(\"Time (s)\")\n",
    "plt.plot(train_sizes, fit_time_mean, 'o-', color=\"b\", label=\"fit Time (s)\")\n",
    "plt.plot(train_sizes, score_time_mean, 'o-', color=\"r\", label=\"score Time (s)\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944a2c77-188b-4861-9848-633abd961676",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
