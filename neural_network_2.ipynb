{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2130e5f8-9d57-42ab-9599-9955534dab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14508a86-4a9f-4263-9f3d-6d69b8b57264",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_52476\\2215475066.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79857730-659d-42c0-891a-cef0b8ab0092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'alpha': 0.0001,\n",
       " 'batch_size': 'auto',\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'early_stopping': False,\n",
       " 'epsilon': 1e-08,\n",
       " 'hidden_layer_sizes': (100,),\n",
       " 'learning_rate': 'constant',\n",
       " 'learning_rate_init': 0.001,\n",
       " 'max_fun': 15000,\n",
       " 'max_iter': 200,\n",
       " 'momentum': 0.9,\n",
       " 'n_iter_no_change': 10,\n",
       " 'nesterovs_momentum': True,\n",
       " 'power_t': 0.5,\n",
       " 'random_state': None,\n",
       " 'shuffle': True,\n",
       " 'solver': 'adam',\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': False,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import decision tree model\n",
    "NN = MLPClassifier()\n",
    "NN.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb741258-a261-46fe-968f-0886d3615a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evalutions\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eda199ec-8d20-4d5d-8d50-e776a4b51519",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(\"apple_quality.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c35d8548-6fbd-4eb2-9bfb-653a2459c35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_id</th>\n",
       "      <th>Size</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Sweetness</th>\n",
       "      <th>Crunchiness</th>\n",
       "      <th>Juiciness</th>\n",
       "      <th>Ripeness</th>\n",
       "      <th>Acidity</th>\n",
       "      <th>Quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.970049</td>\n",
       "      <td>-2.512336</td>\n",
       "      <td>5.346330</td>\n",
       "      <td>-1.012009</td>\n",
       "      <td>1.844900</td>\n",
       "      <td>0.329840</td>\n",
       "      <td>-0.491590483</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.195217</td>\n",
       "      <td>-2.839257</td>\n",
       "      <td>3.664059</td>\n",
       "      <td>1.588232</td>\n",
       "      <td>0.853286</td>\n",
       "      <td>0.867530</td>\n",
       "      <td>-0.722809367</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.292024</td>\n",
       "      <td>-1.351282</td>\n",
       "      <td>-1.738429</td>\n",
       "      <td>-0.342616</td>\n",
       "      <td>2.838636</td>\n",
       "      <td>-0.038033</td>\n",
       "      <td>2.621636473</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.657196</td>\n",
       "      <td>-2.271627</td>\n",
       "      <td>1.324874</td>\n",
       "      <td>-0.097875</td>\n",
       "      <td>3.637970</td>\n",
       "      <td>-3.413761</td>\n",
       "      <td>0.790723217</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.364217</td>\n",
       "      <td>-1.296612</td>\n",
       "      <td>-0.384658</td>\n",
       "      <td>-0.553006</td>\n",
       "      <td>3.030874</td>\n",
       "      <td>-1.303849</td>\n",
       "      <td>0.501984036</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>3996.0</td>\n",
       "      <td>-0.293118</td>\n",
       "      <td>1.949253</td>\n",
       "      <td>-0.204020</td>\n",
       "      <td>-0.640196</td>\n",
       "      <td>0.024523</td>\n",
       "      <td>-1.087900</td>\n",
       "      <td>1.854235285</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>3997.0</td>\n",
       "      <td>-2.634515</td>\n",
       "      <td>-2.138247</td>\n",
       "      <td>-2.440461</td>\n",
       "      <td>0.657223</td>\n",
       "      <td>2.199709</td>\n",
       "      <td>4.763859</td>\n",
       "      <td>-1.334611391</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>3998.0</td>\n",
       "      <td>-4.008004</td>\n",
       "      <td>-1.779337</td>\n",
       "      <td>2.366397</td>\n",
       "      <td>-0.200329</td>\n",
       "      <td>2.161435</td>\n",
       "      <td>0.214488</td>\n",
       "      <td>-2.229719806</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>3999.0</td>\n",
       "      <td>0.278540</td>\n",
       "      <td>-1.715505</td>\n",
       "      <td>0.121217</td>\n",
       "      <td>-1.154075</td>\n",
       "      <td>1.266677</td>\n",
       "      <td>-0.776571</td>\n",
       "      <td>1.599796456</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Created_by_Nidula_Elgiriyewithana</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4001 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        A_id      Size    Weight  Sweetness  Crunchiness  Juiciness  Ripeness  \\\n",
       "0        0.0 -3.970049 -2.512336   5.346330    -1.012009   1.844900  0.329840   \n",
       "1        1.0 -1.195217 -2.839257   3.664059     1.588232   0.853286  0.867530   \n",
       "2        2.0 -0.292024 -1.351282  -1.738429    -0.342616   2.838636 -0.038033   \n",
       "3        3.0 -0.657196 -2.271627   1.324874    -0.097875   3.637970 -3.413761   \n",
       "4        4.0  1.364217 -1.296612  -0.384658    -0.553006   3.030874 -1.303849   \n",
       "...      ...       ...       ...        ...          ...        ...       ...   \n",
       "3996  3996.0 -0.293118  1.949253  -0.204020    -0.640196   0.024523 -1.087900   \n",
       "3997  3997.0 -2.634515 -2.138247  -2.440461     0.657223   2.199709  4.763859   \n",
       "3998  3998.0 -4.008004 -1.779337   2.366397    -0.200329   2.161435  0.214488   \n",
       "3999  3999.0  0.278540 -1.715505   0.121217    -1.154075   1.266677 -0.776571   \n",
       "4000     NaN       NaN       NaN        NaN          NaN        NaN       NaN   \n",
       "\n",
       "                                Acidity Quality  \n",
       "0                          -0.491590483    good  \n",
       "1                          -0.722809367    good  \n",
       "2                           2.621636473     bad  \n",
       "3                           0.790723217    good  \n",
       "4                           0.501984036    good  \n",
       "...                                 ...     ...  \n",
       "3996                        1.854235285    good  \n",
       "3997                       -1.334611391     bad  \n",
       "3998                       -2.229719806    good  \n",
       "3999                        1.599796456    good  \n",
       "4000  Created_by_Nidula_Elgiriyewithana     NaN  \n",
       "\n",
       "[4001 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dc4409d-1228-4b74-a81a-628d09d540fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1= df_1.replace(to_replace=\"good\", value = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09301529-fd0d-4a1e-b3db-9fcbfe0f6f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_52476\\3158947988.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_1=df_1.replace(to_replace=\"bad\", value = 0)\n"
     ]
    }
   ],
   "source": [
    "df_1=df_1.replace(to_replace=\"bad\", value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "431861f2-4b1d-4619-b412-636ff09c06da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_id</th>\n",
       "      <th>Size</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Sweetness</th>\n",
       "      <th>Crunchiness</th>\n",
       "      <th>Juiciness</th>\n",
       "      <th>Ripeness</th>\n",
       "      <th>Acidity</th>\n",
       "      <th>Quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.970049</td>\n",
       "      <td>-2.512336</td>\n",
       "      <td>5.346330</td>\n",
       "      <td>-1.012009</td>\n",
       "      <td>1.844900</td>\n",
       "      <td>0.329840</td>\n",
       "      <td>-0.491590483</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.195217</td>\n",
       "      <td>-2.839257</td>\n",
       "      <td>3.664059</td>\n",
       "      <td>1.588232</td>\n",
       "      <td>0.853286</td>\n",
       "      <td>0.867530</td>\n",
       "      <td>-0.722809367</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.292024</td>\n",
       "      <td>-1.351282</td>\n",
       "      <td>-1.738429</td>\n",
       "      <td>-0.342616</td>\n",
       "      <td>2.838636</td>\n",
       "      <td>-0.038033</td>\n",
       "      <td>2.621636473</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.657196</td>\n",
       "      <td>-2.271627</td>\n",
       "      <td>1.324874</td>\n",
       "      <td>-0.097875</td>\n",
       "      <td>3.637970</td>\n",
       "      <td>-3.413761</td>\n",
       "      <td>0.790723217</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.364217</td>\n",
       "      <td>-1.296612</td>\n",
       "      <td>-0.384658</td>\n",
       "      <td>-0.553006</td>\n",
       "      <td>3.030874</td>\n",
       "      <td>-1.303849</td>\n",
       "      <td>0.501984036</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>3995.0</td>\n",
       "      <td>0.059386</td>\n",
       "      <td>-1.067408</td>\n",
       "      <td>-3.714549</td>\n",
       "      <td>0.473052</td>\n",
       "      <td>1.697986</td>\n",
       "      <td>2.244055</td>\n",
       "      <td>0.137784369</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>3996.0</td>\n",
       "      <td>-0.293118</td>\n",
       "      <td>1.949253</td>\n",
       "      <td>-0.204020</td>\n",
       "      <td>-0.640196</td>\n",
       "      <td>0.024523</td>\n",
       "      <td>-1.087900</td>\n",
       "      <td>1.854235285</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>3997.0</td>\n",
       "      <td>-2.634515</td>\n",
       "      <td>-2.138247</td>\n",
       "      <td>-2.440461</td>\n",
       "      <td>0.657223</td>\n",
       "      <td>2.199709</td>\n",
       "      <td>4.763859</td>\n",
       "      <td>-1.334611391</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>3998.0</td>\n",
       "      <td>-4.008004</td>\n",
       "      <td>-1.779337</td>\n",
       "      <td>2.366397</td>\n",
       "      <td>-0.200329</td>\n",
       "      <td>2.161435</td>\n",
       "      <td>0.214488</td>\n",
       "      <td>-2.229719806</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>3999.0</td>\n",
       "      <td>0.278540</td>\n",
       "      <td>-1.715505</td>\n",
       "      <td>0.121217</td>\n",
       "      <td>-1.154075</td>\n",
       "      <td>1.266677</td>\n",
       "      <td>-0.776571</td>\n",
       "      <td>1.599796456</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        A_id      Size    Weight  Sweetness  Crunchiness  Juiciness  Ripeness  \\\n",
       "0        0.0 -3.970049 -2.512336   5.346330    -1.012009   1.844900  0.329840   \n",
       "1        1.0 -1.195217 -2.839257   3.664059     1.588232   0.853286  0.867530   \n",
       "2        2.0 -0.292024 -1.351282  -1.738429    -0.342616   2.838636 -0.038033   \n",
       "3        3.0 -0.657196 -2.271627   1.324874    -0.097875   3.637970 -3.413761   \n",
       "4        4.0  1.364217 -1.296612  -0.384658    -0.553006   3.030874 -1.303849   \n",
       "...      ...       ...       ...        ...          ...        ...       ...   \n",
       "3995  3995.0  0.059386 -1.067408  -3.714549     0.473052   1.697986  2.244055   \n",
       "3996  3996.0 -0.293118  1.949253  -0.204020    -0.640196   0.024523 -1.087900   \n",
       "3997  3997.0 -2.634515 -2.138247  -2.440461     0.657223   2.199709  4.763859   \n",
       "3998  3998.0 -4.008004 -1.779337   2.366397    -0.200329   2.161435  0.214488   \n",
       "3999  3999.0  0.278540 -1.715505   0.121217    -1.154075   1.266677 -0.776571   \n",
       "\n",
       "           Acidity  Quality  \n",
       "0     -0.491590483      1.0  \n",
       "1     -0.722809367      1.0  \n",
       "2      2.621636473      0.0  \n",
       "3      0.790723217      1.0  \n",
       "4      0.501984036      1.0  \n",
       "...            ...      ...  \n",
       "3995   0.137784369      0.0  \n",
       "3996   1.854235285      1.0  \n",
       "3997  -1.334611391      0.0  \n",
       "3998  -2.229719806      1.0  \n",
       "3999   1.599796456      1.0  \n",
       "\n",
       "[4000 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1=df_1.drop(4000)\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bc689ee-a8b3-4be9-a423-d5465f086e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into X and y\n",
    "X_1 = df_1.drop(\"Quality\",axis=1)\n",
    "y_1= df_1[\"Quality\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5b7cdf-300b-44d4-ad5f-b5a54b586d80",
   "metadata": {},
   "source": [
    "* split into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d90a08f-c7cb-4729-b2ac-055a4e4a6611",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "#split into train and test\n",
    "X1_train,X1_test,y1_train,y1_test=train_test_split(X_1,y_1,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94b3d4e6-cbfb-42fb-8774-7633d3f5767f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'alpha': 0.0001,\n",
       " 'batch_size': 'auto',\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'early_stopping': False,\n",
       " 'epsilon': 1e-08,\n",
       " 'hidden_layer_sizes': (100,),\n",
       " 'learning_rate': 'constant',\n",
       " 'learning_rate_init': 0.001,\n",
       " 'max_fun': 15000,\n",
       " 'max_iter': 200,\n",
       " 'momentum': 0.9,\n",
       " 'n_iter_no_change': 10,\n",
       " 'nesterovs_momentum': True,\n",
       " 'power_t': 0.5,\n",
       " 'random_state': None,\n",
       " 'shuffle': True,\n",
       " 'solver': 'adam',\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': False,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3213181d-4b8b-447e-9898-091011c8acc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_size = range(1,100,10)\n",
    "train_scores=[]\n",
    "test_scores=[]\n",
    "# loop through layers\n",
    "for i in layer_size:\n",
    "    NN.set_params(hidden_layer_sizes=i, max_iter=1000)\n",
    "    NN.fit(X1_train,y1_train)\n",
    "    # update the training scores list\n",
    "    train_scores.append(NN.score(X1_train,y1_train))\n",
    "    #update the test scores list\n",
    "    test_scores.append(NN.score(X1_test,y1_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f457d6d-8eec-49d2-9c67-10de290032d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4984375,\n",
       " 0.7309375,\n",
       " 0.7184375,\n",
       " 0.736875,\n",
       " 0.7496875,\n",
       " 0.7496875,\n",
       " 0.65375,\n",
       " 0.715,\n",
       " 0.705,\n",
       " 0.735625]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73055279-7ffe-474d-9303-475fb2cb2149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.50125,\n",
       " 0.74125,\n",
       " 0.725,\n",
       " 0.745,\n",
       " 0.7575,\n",
       " 0.7575,\n",
       " 0.645,\n",
       " 0.72375,\n",
       " 0.71625,\n",
       " 0.74375]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7f93ba7-5060-4f75-8895-cc8790932de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max neural network score on the test data: 75.75%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAG2CAYAAACDLKdOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABV3ElEQVR4nO3deVhU1f8H8PcwMDPsCLILCOKGCwm4oLmUW2qavxaXckvTTMstS81SM79iq2WlprmkVlJqZmUqlqKpaSqaC26AggoiIPsyMHN+f4xMjCwyCg5zfb+eZx7hzF0+B7J5e86958qEEAJEREREEmFh6gKIiIiIahLDDREREUkKww0RERFJCsMNERERSQrDDREREUkKww0RERFJCsMNERERSQrDDREREUkKww0RERFJCsMNERERSYpJw82+ffvQv39/eHl5QSaTYevWrXfdJzo6GqGhoVCpVAgICMDy5ctrv1AiIiIyGyYNN3l5eQgODsYXX3xRre0TEhLQt29fdO7cGTExMXjrrbcwadIkbN68uZYrJSIiInMhqysPzpTJZPjpp58wcODASreZMWMGtm3bhtjYWH3b+PHjcfLkSRw6dOgBVElERER1naWpCzDGoUOH0KtXL4O23r17Y9WqVSguLoaVlVW5fYqKilBUVKT/XqvVIiMjAy4uLpDJZLVeMxEREd0/IQRycnLg5eUFC4uqJ57MKtykpKTA3d3doM3d3R0lJSVIS0uDp6dnuX0iIiLw7rvvPqgSiYiIqBYlJSWhQYMGVW5jVuEGQLnRltJZtcpGYWbNmoVp06bpv8/KyoKvry+SkpLg4OBQe4USERFRjcnOzoaPjw/s7e3vuq1ZhRsPDw+kpKQYtKWmpsLS0hIuLi4V7qNUKqFUKsu1Ozg4MNwQERGZmepcUmJW69yEh4cjKirKoG3Xrl0ICwur8HobIiIieviYNNzk5ubixIkTOHHiBADdrd4nTpxAYmIiAN2U0ogRI/Tbjx8/HleuXMG0adMQGxuL1atXY9WqVZg+fbopyiciIqI6yKTTUkePHsVjjz2m/7702piRI0di7dq1SE5O1gcdAPD398f27dsxdepUfPnll/Dy8sKSJUvwzDPPPPDaiYiIqG6qM+vcPCjZ2dlwdHREVlYWr7khIjITGo0GxcXFpi6DaplCoaj0Nm9jPr/N6oJiIiJ6uAghkJKSgszMTFOXQg+AhYUF/P39oVAo7us4DDdERFRnlQYbNzc32NjYcPFVCdNqtbh+/TqSk5Ph6+t7X79rhhsiIqqTNBqNPthUttwHSYurqyuuX7+OkpKS+7oL2qxuBScioodH6TU2NjY2Jq6EHpTS6SiNRnNfx2G4ISKiOo1TUQ+PmvpdM9wQERGRpDDcEBERmYFu3bphypQppi7DLPCCYiIiohp0t6mV0oVqjbVlyxY+aqiaGG6IiIhqUHJysv7ryMhIzJkzB+fPn9e3WVtbG2xfXFxcrdDi7Oxcc0U+ANXtV23gtBQREVEN8vDw0L8cHR0hk8n03xcWFsLJyQk//PADunXrBpVKhQ0bNiA9PR1Dhw5FgwYNYGNjg1atWuH77783OO6d01INGzbEwoULMXr0aNjb28PX1xcrVqyosrZNmzahVatWsLa2houLC3r06IG8vDz9+6tXr0aLFi2gVCrh6emJV199Vf9eYmIinnrqKdjZ2cHBwQGDBg3CjRs39O/PmzcPjzzyCFavXo2AgAAolUoIIZCVlYVx48bBzc0NDg4OePzxx3Hy5Mn7/ClXjeGGiIjMhhAC+eoSk7xq8mlFM2bMwKRJkxAbG4vevXujsLAQoaGh+PXXX3H69GmMGzcOw4cPx+HDh6s8zscff4ywsDDExMRgwoQJeOWVV3Du3LkKt01OTsbQoUMxevRoxMbGYu/evXj66af1/Vq2bBkmTpyIcePG4dSpU9i2bRsCAwP1P/eBAwciIyMD0dHRiIqKQlxcHAYPHmxwjkuXLuGHH37A5s2b9Q/F7tevH1JSUrB9+3YcO3YMISEh6N69OzIyMu7zp1g5TksREZHZKCjWIGjOTpOc++z83rBR1MzH5pQpU/D0008btE2fPl3/9WuvvYYdO3bgxx9/RPv27Ss9Tt++fTFhwgQAusC0ePFi7N27F82aNSu3bXJyMkpKSvD000/Dz88PANCqVSv9+wsWLMDrr7+OyZMn69vatm0LANi9ezf+/fdfJCQkwMfHBwCwfv16tGjRAv/8849+O7VajfXr18PV1RUA8Oeff+LUqVNITU2FUqkEAHz00UfYunUrNm3ahHHjxlXzJ2YchhsiIqIHLCwszOB7jUaDRYsWITIyEteuXUNRURGKiopga2tb5XFat26t/7p0+is1NbXCbYODg9G9e3e0atUKvXv3Rq9evfDss8+iXr16SE1NxfXr19G9e/cK942NjYWPj48+2ABAUFAQnJycEBsbqw83fn5++mADAMeOHUNubm65FaYLCgoQFxdXZd/uB8MNERGZDWsrOc7O722yc9eUO0PLxx9/jMWLF+PTTz9Fq1atYGtriylTpkCtVld5nDsv2JXJZNBqtRVuK5fLERUVhYMHD2LXrl34/PPPMXv2bBw+fBj169ev8jxCiArvAruz/c5+abVaeHp6Yu/eveX2dXJyqvKc94PhhoiIzIZMJquxqaG6ZP/+/XjqqacwbNgwALpQcPHiRTRv3rxGzyOTydCpUyd06tQJc+bMgZ+fH3766SdMmzYNDRs2xB9//IHHHnus3H5BQUFITExEUlKSfvTm7NmzyMrKqrLGkJAQpKSkwNLSEg0bNqzRvlSFFxQTERGZWGBgoH5UJTY2Fi+//DJSUlJq9ByHDx/GwoULcfToUSQmJmLLli24efOmPpzMmzcPH3/8MZYsWYKLFy/i+PHj+PzzzwEAPXr0QOvWrfHCCy/g+PHjOHLkCEaMGIGuXbuWm2Irq0ePHggPD8fAgQOxc+dOXL58GQcPHsTbb7+No0eP1mj/ymK4ISIiMrF33nkHISEh6N27N7p16wYPDw8MHDiwRs/h4OCAffv2oW/fvmjSpAnefvttfPzxx+jTpw8A3eKCn376KZYuXYoWLVrgySefxMWLFwHoRny2bt2KevXqoUuXLujRowcCAgIQGRlZ5TllMhm2b9+OLl26YPTo0WjSpAmGDBmCy5cvw93dvUb7Z3BeUZP3tpmB7OxsODo6IisrCw4ODqYuh4iIKlFYWIiEhAT4+/tDpVKZuhx6AKr6nRvz+c2RGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIqIaJJPJqnyNGjXqno/dsGFDfPrppzVWq1RJ77nxREREJpScnKz/OjIyEnPmzMH58+f1bdbW1qYoq9ao1WooFApTl2GAIzdEREQ1yMPDQ/9ydHSETCYzaNu3bx9CQ0OhUqkQEBCAd999FyUlJfr9582bB19fXyiVSnh5eWHSpEkAgG7duuHKlSuYOnWqfhSoMpUdAwCKiorw5ptvwsfHB0qlEo0bN8aqVav070dHR6Ndu3ZQKpXw9PTEzJkzDerr1q0bXn31VUybNg3169dHz549AQBnz55F3759YWdnB3d3dwwfPhxpaWk19nM1BkduiIjIfAgBFOeb5txWNkAVgaI6du7ciWHDhmHJkiXo3Lkz4uLiMG7cOADA3LlzsWnTJixevBgbN25EixYtkJKSgpMnTwIAtmzZguDgYIwbNw5jx46t9BxVHQMARowYgUOHDmHJkiUIDg5GQkKCPoRcu3YNffv2xahRo7Bu3TqcO3cOY8eOhUqlwrx58/TH+Oabb/DKK6/gwIEDEEIgOTkZXbt2xdixY/HJJ5+goKAAM2bMwKBBg/Dnn3/e18/sXjDcEBGR+SjOBxZ6mebcb10HFLb3dYj//e9/mDlzJkaOHAkACAgIwHvvvYc333wTc+fORWJiIjw8PNCjRw9YWVnB19cX7dq1AwA4OztDLpfD3t4eHh4elZ6jqmNcuHABP/zwA6KiotCjRw99DaWWLl0KHx8ffPHFF5DJZGjWrBmuX7+OGTNmYM6cObCw0E34BAYG4oMPPtDvN2fOHISEhGDhwoX6ttWrV8PHxwcXLlxAkyZN7uvnZixOSxERET0gx44dw/z582FnZ6d/jR07FsnJycjPz8dzzz2HgoICBAQEYOzYsfjpp58MpoSqo6pjnDhxAnK5HF27dq1w39jYWISHhxtMeXXq1Am5ubm4evWqvi0sLKxcv/bs2WPQr2bNmgEA4uLijKq/JnDkhoiIzIeVjW4ExVTnvk9arRbvvvsunn766XLvqVQq+Pj44Pz584iKisLu3bsxYcIEfPjhh4iOjoaVlVW1zlHVMe52MbMQoty1PEIIADBot7U1HMHSarXo378/3n///XLH9PT0rFbdNYnhhoiIzIdMdt9TQ6YUEhKC8+fPIzAwsNJtrK2tMWDAAAwYMAATJ05Es2bNcOrUKYSEhEChUECj0dz1PJUdo1WrVtBqtYiOjtZPS5UVFBSEzZs3G4ScgwcPwt7eHt7e3lX2a/PmzWjYsCEsLU0fLTgtRURE9IDMmTMH69atw7x583DmzBnExsYiMjISb7/9NgBg7dq1WLVqFU6fPo34+HisX78e1tbW8PPzA6Bb52bfvn24du1apXciVXWMhg0bYuTIkRg9ejS2bt2KhIQE7N27Fz/88AMAYMKECUhKSsJrr72Gc+fO4eeff8bcuXMxbdo0/fU2FZk4cSIyMjIwdOhQHDlyBPHx8di1axdGjx5drTBW0xhuiIiIHpDevXvj119/RVRUFNq2bYsOHTrgk08+0YcXJycnrFy5Ep06dULr1q3xxx9/4JdffoGLiwsAYP78+bh8+TIaNWoEV1fXCs9xt2MsW7YMzz77LCZMmIBmzZph7NixyMvLAwB4e3tj+/btOHLkCIKDgzF+/HiMGTNGH74q4+XlhQMHDkCj0aB3795o2bIlJk+eDEdHxypDUW2RidLJtIdEdnY2HB0dkZWVBQcHB1OXQ0RElSgsLERCQgL8/f2hUqlMXQ49AFX9zo35/ObIDREREUkKww0RERFJCsMNERERSQrDDREREUkKww0REdVpD9l9Lw+1mvpdM9wQEVGdVLoib36+iR6USQ+cWq0GAMjl8vs6jumXESQiIqqAXC6Hk5MTUlNTAQA2NjblHg1A0qHVanHz5k3Y2Njc9yrHDDdERFRnlT79ujTgkLRZWFjA19f3vkMsww0REdVZMpkMnp6ecHNzQ3FxsanLoVqmUChqZEVjhhsiIqrz5HL5fV+HQQ8PXlBMREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJJi8nCzdOlS+Pv7Q6VSITQ0FPv3769y+2+//RbBwcGwsbGBp6cnXnzxRaSnpz+gaomIiKiuM2m4iYyMxJQpUzB79mzExMSgc+fO6NOnDxITEyvc/q+//sKIESMwZswYnDlzBj/++CP++ecfvPTSSw+4ciIiIqqrTBpuPvnkE4wZMwYvvfQSmjdvjk8//RQ+Pj5YtmxZhdv//fffaNiwISZNmgR/f388+uijePnll3H06NEHXDkRERHVVSYLN2q1GseOHUOvXr0M2nv16oWDBw9WuE/Hjh1x9epVbN++HUII3LhxA5s2bUK/fv0qPU9RURGys7MNXkRERCRdJgs3aWlp0Gg0cHd3N2h3d3dHSkpKhft07NgR3377LQYPHgyFQgEPDw84OTnh888/r/Q8ERERcHR01L98fHxqtB9ERERUt5j8gmKZTGbwvRCiXFups2fPYtKkSZgzZw6OHTuGHTt2ICEhAePHj6/0+LNmzUJWVpb+lZSUVKP1ExERUd1iaaoT169fH3K5vNwoTWpqarnRnFIRERHo1KkT3njjDQBA69atYWtri86dO2PBggXw9PQst49SqYRSqaz5DhAREVGdZLKRG4VCgdDQUERFRRm0R0VFoWPHjhXuk5+fDwsLw5LlcjkA3YgPERERkUmnpaZNm4avv/4aq1evRmxsLKZOnYrExET9NNOsWbMwYsQI/fb9+/fHli1bsGzZMsTHx+PAgQOYNGkS2rVrBy8vL1N1g4iIiOoQk01LAcDgwYORnp6O+fPnIzk5GS1btsT27dvh5+cHAEhOTjZY82bUqFHIycnBF198gddffx1OTk54/PHH8f7775uqC0RERFTHyMRDNp+TnZ0NR0dHZGVlwcHBwdTlEBERUTUY8/lt8ruliIiIiGoSww0RERFJCsMNERERSQrDDREREUkKww0RERFJCsMNERERSQrDDREREUmKSRfxIyIJ02qBggwg9waQm6p7FdwCIIGltRR2QIuBgNLe1JUQUQUYboio+oQACjNvh5UyoSUvtYK2m4DQmLri2vP3UmDo90C9hqauhIjuwHBD9LATAijK0YWR3Bu3X7e/NggtN3Xfa9TGHd/GBbBzB2xdARtnQCaB2fDLfwGpZ4GVjwOD1gMNO5m6IiIqg+GGSKrU+bcDSkWh5Y62kgLjjq1yvB1Y3AA7N93Xdq63/3SHxqY+blnUww2NHW7maXEzpwg3c4uQlV8shUkpuDYfjZFXZkGR+i+w7ingyU+AkBF335GIHgiGGyJzUlJ0x1RQmWkgg9CSCqhzjTu2wu6/oGL7X1ApDS3C1hX5ivpI1dghtUCGm7lFutCSU4TUnCLcTC7Sh5j03OvQiuu18zOoI75WvYmfvL+F17XfgW2vAanngJ7zATn/t0pkavxbSFSXaDVA1lUg/RKQEa/7M/0SkJmoCy2FWcYdz1JVZmSlbGj5L7wUW9dHBhxxo1CuDyulISU1sahMiElDQfGNap9aJgNcbJVwtde93OyVqGdjBQuZzMgfSt1zMC4dp65loWPcMHzl44neN1cDf38JpJ0Hnl2tG9kiehjlpADXYwB1HtDqWZOVwaeCU3nXjuuuJ3BsADj66P60VJq6KukQQjfCUhpc0i8B6XG6V0Y8oCmqen8LqzsCitvt6aGyoyxuyJY746baEqk5aoNRFv1Iy+0Ak5Fn3DU0dkpLXWCx+y+4GLzslHBzUMLZRgFLuQSur6lAsUaLz3ZfxNK9l6AVwHCHE3hXswQWmkKgfhNg6EbApZGpyySqXbk3geQTujBT+spJ1r3n6ANMPV2jpzPm85vhhgxlJgJftAVKCg3b7dz/CzpOPoCjb5mvfQBrJ5OUW6cVZAIZcf8Fl7JBRp1T+X4WVoBzAOASqPuAdGkE1PMH7D1QqKyPtBIVbuaq/wsoOf+NrqTmFCHtdptao612qZYWMtS3Kx9QKgoxNgoO+JY6kpCBqZEncC2zAK3ll/Gt7aewV6cC1vWAQesA/y6mLpGoZuRn6MKLPsycALKSym8nswBcmwFebYD+nwFyqxorgeGmCgw3d7FpNHB6M+DgDShsgcyk6l1sqnT4b6THyafM17dDkJ0HYCHBf8UXF9yePoorMwJzSRdq8m5WsaNM97PRBxjdnwUO/rhS4ozEW0VIzMjHlfR8XMnIx7Vb+biZU4TswhKjynNQWcLNQVUuoLjdMdJSz0YBCwvzny4yhezCYszZehpbT1yHK25hg90SNC05D1hYAn0+ANqOMXWJRMYpyASSTxqOyGReqWBDGVC/sS7I3H7dsm+K4ylq5Kk1GBDsVaNlMdxUgeGmCklHgFU9AciAl6MBz2DdFEp+BpCVqAs6WUm6a0IyE//7Oj/97se2sAIcvW+P/lQQgBy8AStVrXfxnmhKdH+xywaX0iCTdRVVLkpn524QYIRzADKt/ZCgccWVbA2upOcjMSMfibdDzM2cu0xJAVDILSqcCroztNS3U0JlJa+5nwNV6ecT1/D21tNQF+bjI+XX6C/7S/dGu3FA7wheaEx1U1EOkPyvYZDJiKt4W+dGBkFG694KcdkyHLtyS/dKvIX4m3kAAG8naxyY+XiNlmrM5zf/tpGOEMCOWQCAyz4DseaIHC52F/UfnPXt/eHq1Qz1myigtLzjA1Odp/uQz0q6IwDd/jr7OqAtBm5d1r0qY+tW8ahPaRhSOemuUq0NWq1urlgfXspMI926DGirGDFROgL1A3UhxrkRNPUCkKrwQYJwR3y2xe0RmDwkJhQgMT0PeeokABUM597maG0FX2cb+LrYwM/ZBn4uNmhQzwbuDkq42qngYG0JmQQuypWapx7xRqhfPUz74SReS3gFsXJvvGkVCRxZAaRdAJ5bq5uuIjIVdR6Qcko3pVQaZNIuoMJ/oDn5GQQZeAYj18IOJ5MydUHmz1uISTxU4WhyI1dbhPrVQ1GJpvznxQPCkRvSObUJ2DwGGksbdMj9EDdR+f+EHVSW+pGBsn+WHUGob6eEi50CVnIL3chHTnLFoz6lAag4/+41KuwNr/NxbHA7AN3+2t4DsLjLX6T8jDsu5L0EpMfrAk1VNVha60Zfbl8LU+Toj+vyBogX7ojLVeJKRoF+GulaZgE02sr/WslkgKeD6nZ4sYWviw18b4cYP2dbONrU3Bw1PXgarcBX++Lwya4LeBxH8KliGWxQqPtX7/ORumF8otpWXAjcOG04InPzHCAquBbPoQHg9YhBmBHW9ZCUUYDjibf0IzPnUrJx5//arK3kCPZxRKhfPYT61UMbn3qoZ6uolS5xWqoKDDcVKC7QXUSclYRvbYZjdkYftGvojABXW6SVucsmLVdt1EWqAOBsq0B9O8V/I0AVBKL6tgo4W+RBnn3nqE/if1/np939ZBaWuukt/bSXj+5itrKjMIWZle8vk+uW0ncJhHBphFxbP1yXeyNO64Fz+fZIulWoG4HJyEdabtV3GCksLXSBxWAExhY+zjZoUM+a00UPgVNXszB5YwyU6WexUvExGsjSIJQOkD23FgjsburySEpK1EDqGcMgkxpb8YizvecdIzKPAHauKCzW4Mz1rP+mmK5kIi23/DS5t5O1PsiE+tVDMw/7B3ZXJMNNFRhuKrDvI+DP95Cv8kBIZgTkChvsmd4Nbg6G18AIIZBdUPLfbcW5t+/MyS0NP//9mZarrnL04k4WMsDZtuz1IgqDkSB3lRbuSEP9klTYFSZDVhqCSqfCsq9V/zlGDg0Al0bQOAcgy9oP1+TeiNO442x+PSRkqpF4+zqYguKqj1fPxgq+Lra6AHNHiHGzV/ICXUK+ugQLfovFzsOnsFyxGG0tLkDI5JA9EaG7FofTi/enRA0cXg78vUz3WBCl/e2Xw39fqxwqbq/o67p63V9ZmmJdcCl759KNMxU/FsWmPuAdYhhkHDwBAKnZhQbXypy5ll3uH69Wchlaejsi1FcXZEL86sHdwXQ/I4abKjDc3CHnBvB5CKDOxTvyyVif1x4z+zTD+K73t0aHVitwK1+NtFz17SBUiLTb663cGYjS89Qw5r/Csrct60OQrSX8FNnwlqXBTXsTziU3YFeYDAtNMdJVDZBs4YWLWg+cLqiPuEzdhbzXMwvKDbGWZSEDPB2tddNFLjbwdba9/acuyDioOH1E1RN19gbe3nQMbxQvw7PyfQAAETIKsn4f1eitsg+VCzt11wlWdvHrvZArygSesgHIoeL2yoKTpapmgqumRHdNTNkRmZRTFa+FZV3PcETGq41uJFsmQ4lGi3MpOQZTTFdvlb8Ltr6dQhdiboeZlt6OdWqUmeGmCgw3d9j2GnB8Ha7bBqFT+lvwc7HDzqldHuhFYCUaLTLy1GUCj7rMVFiZUaLcImTmF9fouVVWFvBz1k0X/RdidKMv3k7WUFhK8PZ1MonUnEK88cNJNIlfi1mW38NCJqD26QjF0G91DxSl6km7qAs1l6J039u6Ad3nAN6hujt/inKAouzbr5w72nKAwjvbc6ped+peWFhVYxSpgvBkZaNbWkIfZP6t+FpApWO5a2Tg5KsPVJn5asQkZuqDzMmrmchXG45EW8iAph4OCPVz0k0x+TrDx9m6Tt+swHBTBYabMlJOAcs7AxAYXDIPh0uaYPWoMDzezN3UlVVKXaJFel5R+fBTJhSVtuUU6eabXWwV+ikjXxfbMhfv2sDVXlmn/zKTtAghsO7QFRz4/Vt8bPE57GUFyLf1gc3ITYBbM1OXV7cVZgHRH+imobQlgIUVRPtX8Kf7SGw+o3ssiZONAk7WVqhno4CTje7PerZWcLJRoJ6NAo7WVpBXNF2s1eoCTkVhqFwgquzr26+afjSswk43nVQ2zNTz168bptUKxKfllrlW5hbibt+OXZa9ylI/IhPqVw/BPk6wU5rXDdMMN1VguLlNCGDdACBhH47YdMWgjJfRrakr1r7YztSV1ZjCYg00WgFbM/sLTNJ34UYOPt6wFbOz3oWvxU0UWtgAz66GKqiPqUure7Ra4MQG4I/5+oUxNYG98avnRHwWIxCfVv6DvDIyGeCgskI9Gys42ihQz+aOIGTzXxBysrFCPVtdWLJRyKv3jyCtFijOq2YYuiMYFWbrHnbr4G04IuMSaLAAal5RCU4mZeqnmI4nZiKroPyIdoCrrUGYCXS1M/vrABluqsBwc9v534Hvh0BrYYUuBR8iReaOnVO7oJGrnakrI3ooFJVo8OWvh9Hp+FS0tzgHLWS40W42PPtM54XGpRL/Bn6fobtwFkCJcyC2ebyGBee99c9Ec1BZYmg7X3g5WeNWvhqZ+cW4la/GrfxiZOardW15xfqR3HuhkFvoA1D5ESErOFn/F4ZKA5KTtdV930UkhMDVW4a3Y8cml78dW2VlgeAGTv/dju1bD861dDu2KXERP6qaphjY9TYAIFLeH1eFG8Y+2pDBhugBUlrKMW1gRxxs/hN+jnwNT2l3w/PIAsQm/osmo1dCrjCDO3dqS9Y1YPdc4NSPAACNwh47XEZiRlIH5F63AKBGg3rWGPOoPwaF+VRrdLZYo0VWQWngKcatPMMglFWgxq28YoOAlJlfDLVGC7VGi9Tbz24zhr3K0mBE6M6A9N+Ike5rB5UVLt3MxfEydzFVtGq5t5M1QvzqIdTXCSF+9dDc00G3phjpceTmYfT3cmDHDBRY1UPbnA+hsquHPdO7wp53/xCZRGZeEXatmY9nbn4JuUwg1qoFnF7cCE8vX1OX9mAVFwKHPgf2fwIU50NAhv12fTA1rT/S4QgACG7giLFdAvBEC49aX19FCIF8tUYfdP4LPbcD0h0jRVn6oFRzNz5YyWVo4eWon2IK8XOCp6N1jR3fnHDkhiqXnwHsjQAAfKB+FrmwwZwnmjLYEJmQk60Sz01cgH2/t0Kbw1PRvPgMrq14HHseW4HHutbs83nqJCGA2F+AXbN1K5gDOGsZhDfznsfpwgAAQI/m7hjXJQBtG9Z7YDcByGQy2CotYau0RAMjnpyh0QpkFZQJQmVGhDILykyZ3TFSVFSihYutQjcqc/vVqo7djm0uGG4eNvs+BAozkaz0x7qsLghu4IhnQxqYuiqih55MJkPXvkNwrXEz5G4cCm/NdTj9OQSrLs7Bc8Nelu66SjfOADtmAgm69X9S4YIF6qHYVhgOpaUcz4c2wJhH/c1q2lxuIYOzrcLo614KizVQWlrwDs4awGmph0naJWBpe0BbguHqmdivbY0tEzoixJcP8yOqS0py03F95WD4Zv0DrZDhK6sXEPbCfLT1dzF1aTUnPwPYsxDi6CrIhBZFsMLykiexvKQ/rG0dMLyDH4aH+6G+ndLUlVIdwWkpqljUHEBbgqOKtthf2BpPh3gz2BDVQZZ2LvCd9DtSf5wKt3Pr8UrJBvy0+jL+6hiBV3u1NO+LRzUlwLE10PyxAPKiTMgAbNe0w8KSF2Dl0hBvd/bHMyENOBVD94Xh5mGRsA84/xu0Mjlm5AyCrUKOmU9w0TCiOktuBbchX6DwYCtY7ZqF/5P/hZhDL+Kli3Mx7/nu8K9va+oKjSbio5G/7Q3YZp6HHMA5rQ/eLRkBjW9nzO0SgO7N3Mx+LRaqGxhuHgZaDbDjLQDAJllPxAlvzHi8cbkHYxJR3aPq+DLg0RTq70egTfElRKRPxmtL3sRzT/bD4LY+ZnF9hjrtMm5ueh3eKbthC+CWsMPikudwK+gFzOjSGI/4OJm6RJIYXnPzMDi+Htj2KgrldgjP+wiOLh4P/PlRRHSf0uNQsmEQLG9dQr5QYlrxK9A2649Fz7Suswu2ZWVl4uKW99DqyjdQohgaIcNG9MLV4Kl4vlswfJxtTF0imRFec0P/KcoB/nwPAPCpeiBuwQEfPRnEYENkblwawXLcHxCbRsMm7g8sV3yKT85fxROLh+CjQY+gSxNXU1eol5Seh39+XYGO8UsQJssAAPwja4W4sNl48vEecLSR6J1fVGcw3Ejdgc+A3Bu4YemF1YU90bWJKx5v5mbqqojoXlg7Qfb8D7oVxg8vwzSrTWhcdBXjVr+M5zs1w5tPNDXphbj/Xs3E77t+R/fLi/G0xXlABqTI3BAf+hZCew9HWyt+5NCDwf/SpCwzCTj4OQBgTv4gaC0UeOfJILOYoyeiSsgtgT6LALdmEL+9jv74G76yVIw7MA0H49Lw6ZBH0MzjwU25a7UCf55LReTe4+h+fTnekEfDwkKgUKZEcquJaNj/TXhYPZwr6pLpMNxI2R/vAiWFOClvgZ3atnjp0YYIdDOfhbCIqAqhoyBzCQQihyO4IB6/qt7BmBvTMOCLPMx4ohle7NiwVu88KizW4KeYa1iz7zw63/oJH1tugYNlAQAgK3AgHPsvhL+jd62dn6gqvKBYqq4eBb7uDgEZ+he9hxTbZvhzejfprnJK9LDKSAC+HwrcjIVapsDrRePwi7YjOjeuj4+eC4Z7Dd8VmZGnxvpDV7Du0GW0KjiCdyzXo5FFMgBA7dYaiic/BHw71Og5iQBeUExCADt1t35vE11wWgTgg97NGGyIpMjZHxizC9j8EhQXd+JzxRdorr2GDy8+gyc+3YdFz7RG7xYe932a+Ju5WPVXAjYfvwqPkmv4wHIDuitiAABaG1dY9JgDxSPDAAszXmCQJIMjN1J0eguw6UWoZSp0LvgI7g38sXVCJy6ORSRlWg2wex5wcAkA4ICiI17KfgkFUGFIWx+882QQbJXG/XtWCIFjV25hxb54RMXegK3Ix6uWWzHGcgesUAJhYQlZ+/FA1zcBlWMtdIroPxy5eZgVFwK75wIAvizuhxtwxtL+LRhsiKTOQg70eg9wbQb8OgWd1Aex1zkNT996FRv/Af6OT8enQ9pUa8E8jVZg55kUrNgXjxNJmZBBi2fl+/C28kc4am/pNgrsCdkTEUD9xrXbL6J7wHAjNYeXAZmJSLdwwYqSfvi/Nt4I9ePzo4geGm1eAFwaAZHD4J53AXsc52Oi5nVEpfvhmWUHMbVHY7zSLRDyCv7Bk1dUgh+PJmHVgQQkZeguDm5neQkf238Hn4JzgBaAcyPgiUVAk14PuGNE1cdpKSnJTQWWhADqHExTj8cOy8ewZ3q3Gr+gkIjMQGai7kLjG6ch5Aqsc30dcy+3AgC0bVgPnwx6RL9CcGp2Ib45dBkb/k5EVkExAKCxdQ4+q78VQTd/1x1PYa+bfmo/HrCsmysik7QZ8/nNcCMlv0wGjq3FWVkj9Ct4F2880RwTugWauioiMpWiXOCnl4FzvwIAzgeOwXMXeyK7SAt7pSWm926K09ey8POJ61BrtACAJs6WeN97Px65vBqy4jwAMt1o0ONzAHt3E3aGHnYMN1WQbLi5cQZY/iggtHiuaA5SnUOwi8+PIiKtFtizANj/MQCgwL8Xxua+jL+Sigw2C/N1wluNEtDm3IeQ3bqsa2zQDujzPuAd8oCLJiqPFxQ/bIQAds4GhBY7tO3wj2iGlf34/Cgigu7W7O5zANfmwM8TYZ2wC+tdk/BN5/ex+GgROjZywastS9Di5P+AQ9G6few9gR7vAq0HAVzRnMwQw40UXIwC4vegGFZYWDwUXZq4okdzPj+KiMpo/ZxuTZyNz0N2Mxaj8l7EqKHLgEuRwM9fA0IDyJVAx1eBR6cBSq5mTuaL4cbcaYqBXbMBAKtLeuG6zAOr+fwoIqpIgzBg7B5g41Ag+STw3aD/3mv2JNBrgS4AEZk5LiVp7o6uAdIuIFPmgC9K/g8jO/L5UURUBUdv4MXfgaCndN+7NgeGbwWGfMtgQ5LBkRtzVnAL2BsBAPhI/QwUtk6Y1J0LahHRXShsgee+AdIvAfX8dU8aJ5IQ/hdtzvZ9BBRk4JJogO81j2PhE03haM3nRxFRNchkXF2YJIvTUuYqPQ44/BUA4L3iFxDk7YznQn1MXBQREZHpceTGXEXNAbTFiNa2RrQ2GJsHBPH5UURERODIjXlK2A+c+xUaWGBB8TAMfMQLoX7Opq6KiIioTuDIjbnRaoGdbwEAvi95DNes/LC+T3MTF0VERFR3cOTG3Jz8Hkj5F7mwwSclz2HiY4HwcOSDMYmIiEox3JgTdR7wx3wAwJLip2Dn7IExj3JdCiIiorI4LWVODnwG5KYgSbhhreYJfNGvOVRWfH4UERFRWRy5MRdZ14ADSwAAC4uHon1jT/QMcjdxUURERHUPR27MxR/zgZICHNE2RRTaY0d/Pj+KiIioIhy5MQfXjgH/bgQALCgehhHh/gh0szdxUURERHWTycPN0qVL4e/vD5VKhdDQUOzfv7/K7YuKijB79mz4+flBqVSiUaNGWL169QOq1gSEAHbqnvq9WfMortk0x+QeXDKdiIioMvc0LRUXF4c1a9YgLi4On332Gdzc3LBjxw74+PigRYsW1T5OZGQkpkyZgqVLl6JTp0746quv0KdPH5w9exa+vr4V7jNo0CDcuHEDq1atQmBgIFJTU1FSUnIv3TAPZ38GEg+hQCjwYfFgvNGfz48iIiKqikwIIYzZITo6Gn369EGnTp2wb98+xMbGIiAgAB988AGOHDmCTZs2VftY7du3R0hICJYtW6Zva968OQYOHIiIiIhy2+/YsQNDhgxBfHw8nJ3vbUXe7OxsODo6IisrCw4ODvd0jAempAj4oi2QeQWflTyNKPfR+Hnio5DzMQtERPSQMebz2+hpqZkzZ2LBggWIioqCQqHQtz/22GM4dOhQtY+jVqtx7Ngx9OrVy6C9V69eOHjwYIX7bNu2DWFhYfjggw/g7e2NJk2aYPr06SgoKKj0PEVFRcjOzjZ4mY3Dy4HMK7ghnPBVyZOY178Fgw0REdFdGD0tderUKXz33Xfl2l1dXZGenl7t46SlpUGj0cDd3fB2Znd3d6SkpFS4T3x8PP766y+oVCr89NNPSEtLw4QJE5CRkVHpdTcRERF49913q11XnZF7E2LfR5AB+LBkMHo+EoCwhnx+FBER0d0YPXLj5OSE5OTkcu0xMTHw9vY2uoA7b2cWQlR6i7NWq4VMJsO3336Ldu3aoW/fvvjkk0+wdu3aSkdvZs2ahaysLP0rKSnJ6BpNYm8EZEXZOKVtiN/l3TCLz48iIiKqFqPDzfPPP48ZM2YgJSUFMpkMWq0WBw4cwPTp0zFixIhqH6d+/fqQy+XlRmlSU1PLjeaU8vT0hLe3NxwdHfVtzZs3hxACV69erXAfpVIJBwcHg1edlxoLcWwNAGBB8XBMeKwJnx9FRERUTUaHm//973/w9fWFt7c3cnNzERQUhC5duqBjx454++23q30chUKB0NBQREVFGbRHRUWhY8eOFe7TqVMnXL9+Hbm5ufq2CxcuwMLCAg0aNDC2K3XXrrchE1rs0LRFcr1QPj+KiIjICEbdLSWEQGJiIlxdXZGSkoLjx49Dq9WiTZs2aNzY+LVXIiMjMXz4cCxfvhzh4eFYsWIFVq5ciTNnzsDPzw+zZs3CtWvXsG7dOgBAbm4umjdvjg4dOuDdd99FWloaXnrpJXTt2hUrV66s1jnr/N1SF3cD3z4DtZCjp/pDvDWsH3q38DB1VURERCZlzOe3URcUCyHQuHFjnDlzBo0bN0ZAQMB9FTp48GCkp6dj/vz5SE5ORsuWLbF9+3b4+fkBAJKTk5GYmKjf3s7ODlFRUXjttdcQFhYGFxcXDBo0CAsWLLivOuoMTQmwS7dg3zea3vANbIlefH4UERGRUYxe56ZFixZYtWoVOnToUFs11ao6PXLzz9fAb68jQ9ihe/Fi/DC5Dxq78zELREREtbrOzQcffIA33ngDp0+fvucCqQIFmRB7FgIAPi15BgPDWzDYEBER3QOj17kZNmwY8vPzERwcDIVCAWtra4P3MzIyaqy4h8r+jyHLT8clrRd2KPsgqkcTU1dERERklowON59++mktlPGQy0iAOLwcMgD/K3kBU59swedHERER3SOjw83IkSNro46H2+65kGnU2KdphVT3LhgU5mPqioiIiMzWPT0VXKPRYOvWrYiNjYVMJkNQUBAGDBgAuVxe0/VJ35WDwNmfoREy/K/kBSx4qiWfH0VERHQfjA43ly5dQt++fXHt2jU0bdoUQghcuHABPj4++O2339CoUaPaqFOatFqIHbMgAxCpeQxNW3dAWz4/ioiI6L4YfbfUpEmT0KhRIyQlJeH48eOIiYlBYmIi/P39MWnSpNqoUbpO/QBZ8gnkCGsslQ3GrL7NTF0RERGR2TN65CY6Ohp///03nJ3/G2FwcXHBokWL0KlTpxotTtLUedDungcLAEtLnsKQ7qHwdLS+625ERERUNaPDjVKpRE5OTrn23NxcKBSKGinqoXDwC1jkJOOqqI9dDv+H3zrf32rPREREpGP0tNSTTz6JcePG4fDhwxBCQAiBv//+G+PHj8eAAQNqo0bpyb4O7V+LAQCLiofijX6PQGXFi7GJiIhqgtHhZsmSJWjUqBHCw8OhUqmgUqnQqVMnBAYG4rPPPquNGqXnj/dgUVKAo9omuOXfD71b8PlRRERENcXoaSknJyf8/PPPuHTpEmJjYyGEQFBQEAIDA2ujPum5HgOc/A4AsFAzHIsGtIRMxlu/iYiIaso9rXMDAIGBgQw0xhIC2h1vwQLAVk1HtG7fHU34/CgiIqIaZfS01LPPPotFixaVa//www/x3HPP1UhRknXuV1gkHkShsMJXlsMwlc+PIiIiqnFGh5vo6Gj069evXPsTTzyBffv21UhRklRSBM3OtwEAKzX9MOyJR+Fow+dHERER1TSjp6Uqu+XbysoK2dnZNVKUJB1ZCXnmZaQKJ+yp/wJ+bOtr6oqIiIgkyeiRm5YtWyIyMrJc+8aNGxEUFFQjRUlOXjo0e98HAHxYMggznwrj86OIiIhqidEjN++88w6eeeYZxMXF4fHHHwcA/PHHH/j+++/x448/1niBUiD2RkCuzsYZrR+KWgxGO38+P4qIiKi2GB1uBgwYgK1bt2LhwoXYtGkTrK2t0bp1a+zevRtdu3atjRrN283zEEdXQwbgAzEcEX1bmLoiIiIiSbunW8H79etX4UXFVJ5mx2zIhQZRmlCEdRsILyc+P4qIiKg2GX3NTVJSEq5evar//siRI5gyZQpWrFhRo4VJwqU/II+LQrGQY7XNixjbhc+PIiIiqm1Gh5vnn38ee/bsAQCkpKSgR48eOHLkCN566y3Mnz+/xgs0W5oSqH9/CwCwXtMTI/v34POjiIiIHgCjw83p06fRrl07AMAPP/yAVq1a4eDBg/juu++wdu3amq7PfMWsgyL9HDKFLQ75jEHvFh6mroiIiOihYHS4KS4uhlKpBADs3r1b/yTwZs2aITk5uWarM1eF2VBHvQcAWKJ5FtOfCufzo4iIiB4Qo8NNixYtsHz5cuzfvx9RUVF44oknAADXr1+Hi4tLjRdojjT7PoKiKANxWk+g7Rg09eDzo4iIiB4Uo8PN+++/j6+++grdunXD0KFDERwcDADYtm2bfrrqoXbrMnBoKQBgiXwEJvfkwoZEREQPktG3gnfr1g1paWnIzs5GvXr19O3jxo2DjY1NjRZnjop2zIFSFOOApgXa9n2ez48iIiJ6wO5pnRu5XG4QbACgYcOGNVGPeUv8G8rzP0MrZPjW6WV83t7P1BURERE9dIyelqJKaLXI/2UGACBS0w2jnu7P50cRERGZAMNNDRGX98Hm5gnkChX+bfIqnx9FRERkIvc0LUXlHdS2xFL1LPha3sJrAzqZuhwiIqKHFsNNDenYyAX5w17EjexCPj+KiIjIhKoVbpYsWVLtA06aNOmeizFnMpkMPYPcTV0GERHRQ08mhBB328jf3796B5PJEB8ff99F1abs7Gw4OjoiKysLDg4Opi6HiIiIqsGYz+9qjdwkJCTUSGFEREREte2e75ZSq9U4f/48SkpKarIeIiIiovtidLjJz8/HmDFjYGNjgxYtWiAxMRGA7lqbRYsW1XiBRERERMYwOtzMmjULJ0+exN69e6FSqfTtPXr0QGRkZI0WR0RERGQso28F37p1KyIjI9GhQwfIZP+twBsUFIS4uLgaLY6IiIjIWEaP3Ny8eRNubm7l2vPy8gzCDhEREZEpGB1u2rZti99++03/fWmgWblyJcLDw2uuMiIiIqJ7YPS0VEREBJ544gmcPXsWJSUl+Oyzz3DmzBkcOnQI0dHRtVEjERERUbUZPXLTsWNHHDhwAPn5+WjUqBF27doFd3d3HDp0CKGhobVRIxEREVG1VWuFYinhCsVERETmp8ZXKM7Ozq72yRkYiIiIyJSqFW6cnJyqfSeURqO5r4KIiIiI7ke1ws2ePXv0X1++fBkzZ87EqFGj9HdHHTp0CN988w0iIiJqp0oiIiKiajL6mpvu3bvjpZdewtChQw3av/vuO6xYsQJ79+6tyfpqHK+5ISIiMj/GfH4bfbfUoUOHEBYWVq49LCwMR44cMfZwRERERDXK6HDj4+OD5cuXl2v/6quv4OPjUyNFEREREd0roxfxW7x4MZ555hns3LkTHTp0AAD8/fffiIuLw+bNm2u8QCIiIiJjGD1y07dvX1y8eBEDBgxARkYG0tPT8dRTT+HChQvo27dvbdRIREREVG1cxI+IiIjqvBpfxO9OmZmZWLVqFWJjYyGTyRAUFITRo0fD0dHxngomIiIiqilGT0sdPXoUjRo1wuLFi5GRkYG0tDR88sknaNSoEY4fP14bNRIRERFVm9HTUp07d0ZgYCBWrlwJS0vdwE9JSQleeuklxMfHY9++fbVSaE3htBQREZH5Mebz2+hwY21tjZiYGDRr1syg/ezZswgLC0N+fr7xFT9ADDdERETmp1YX8XNwcEBiYmK59qSkJNjb2xt7OCIiIqIaZXS4GTx4MMaMGYPIyEgkJSXh6tWr2LhxY4WPZCAiIiJ60Iy+W+qjjz6CTCbDiBEjUFJSAgCwsrLCK6+8gkWLFtV4gURERETGuOd1bvLz8xEXFwchBAIDA2FjY1PTtdUKXnNDRERkfmp9nRsAsLGxQatWre51dyIiIqJaUe1wM3r06Gptt3r16nsuhoiIiOh+VfuC4rVr12LPnj3IzMzErVu3Kn0Za+nSpfD394dKpUJoaCj2799frf0OHDgAS0tLPPLII0afk4iIiKSr2iM348ePx8aNGxEfH4/Ro0dj2LBhcHZ2vq+TR0ZGYsqUKVi6dCk6deqEr776Cn369MHZs2fh6+tb6X5ZWVkYMWIEunfvjhs3btxXDURERCQtRl1QXFRUhC1btmD16tU4ePAg+vXrhzFjxqBXr16QyWRGn7x9+/YICQnBsmXL9G3NmzfHwIEDERERUel+Q4YMQePGjSGXy7F161acOHGi2ufkBcVERETmp9YW8VMqlRg6dCiioqJw9uxZtGjRAhMmTICfnx9yc3ONKlKtVuPYsWPo1auXQXuvXr1w8ODBSvdbs2YN4uLiMHfu3Gqdp6ioCNnZ2QYvIiIiki6jF/ErJZPJIJPJIISAVqs1ev+0tDRoNBq4u7sbtLu7uyMlJaXCfS5evIiZM2fi22+/1T/X6m4iIiLg6Oiof/n4+BhdKxEREZkPo8JNUVERvv/+e/Ts2RNNmzbFqVOn8MUXXyAxMRF2dnb3VMCd01lCiAqnuDQaDZ5//nm8++67aNKkSbWPP2vWLGRlZelfSUlJ91QnERERmYdqX1A8YcIEbNy4Eb6+vnjxxRexceNGuLi43POJ69evD7lcXm6UJjU1tdxoDgDk5OTg6NGjiImJwauvvgoA0Gq1EELA0tISu3btwuOPP15uP6VSCaVSec91EhERkXmpdrhZvnw5fH194e/vj+joaERHR1e43ZYtW6p1PIVCgdDQUERFReH//u//9O1RUVF46qmnym3v4OCAU6dOGbQtXboUf/75JzZt2gR/f//qdoWIiIgkrNrhZsSIEfd0R1RVpk2bhuHDhyMsLAzh4eFYsWIFEhMTMX78eAC6KaVr165h3bp1sLCwQMuWLQ32d3Nzg0qlKtdORERED69qh5u1a9fW+MkHDx6M9PR0zJ8/H8nJyWjZsiW2b98OPz8/AEBycjISExNr/LxEREQkXff84ExzxXVuiIiIzE+trXNDREREVNcx3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpJg83CxduhT+/v5QqVQIDQ3F/v37K912y5Yt6NmzJ1xdXeHg4IDw8HDs3LnzAVZLREREdZ1Jw01kZCSmTJmC2bNnIyYmBp07d0afPn2QmJhY4fb79u1Dz549sX37dhw7dgyPPfYY+vfvj5iYmAdcOREREdVVMiGEMNXJ27dvj5CQECxbtkzf1rx5cwwcOBARERHVOkaLFi0wePBgzJkzp1rbZ2dnw9HREVlZWXBwcLinuomIiOjBMubz22QjN2q1GseOHUOvXr0M2nv16oWDBw9W6xharRY5OTlwdnaudJuioiJkZ2cbvIiIiEi6TBZu0tLSoNFo4O7ubtDu7u6OlJSUah3j448/Rl5eHgYNGlTpNhEREXB0dNS/fHx87qtuIiIiqttMfkGxTCYz+F4IUa6tIt9//z3mzZuHyMhIuLm5VbrdrFmzkJWVpX8lJSXdd81ERERUd1ma6sT169eHXC4vN0qTmppabjTnTpGRkRgzZgx+/PFH9OjRo8ptlUollErlfddLRERE5sFkIzcKhQKhoaGIiooyaI+KikLHjh0r3e/777/HqFGj8N1336Ffv361XSYRERGZGZON3ADAtGnTMHz4cISFhSE8PBwrVqxAYmIixo8fD0A3pXTt2jWsW7cOgC7YjBgxAp999hk6dOigH/WxtraGo6OjyfpBREREdYdJw83gwYORnp6O+fPnIzk5GS1btsT27dvh5+cHAEhOTjZY8+arr75CSUkJJk6ciIkTJ+rbR44cibVr1z7o8omIiKgOMuk6N6bAdW6IiIjMj1msc0NERERUGxhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSTB5uli5dCn9/f6hUKoSGhmL//v1Vbh8dHY3Q0FCoVCoEBARg+fLlD6hSIiIiMgcmDTeRkZGYMmUKZs+ejZiYGHTu3Bl9+vRBYmJihdsnJCSgb9++6Ny5M2JiYvDWW29h0qRJ2Lx58wOunIiIiOoqmRBCmOrk7du3R0hICJYtW6Zva968OQYOHIiIiIhy28+YMQPbtm1DbGysvm38+PE4efIkDh06VK1zZmdnw9HREVlZWXBwcLj/ThAREVGtM+bz2/IB1VSOWq3GsWPHMHPmTIP2Xr164eDBgxXuc+jQIfTq1cugrXfv3li1ahWKi4thZWVVbp+ioiIUFRXpv8/KygKg+yERERGReSj93K7OmIzJwk1aWho0Gg3c3d0N2t3d3ZGSklLhPikpKRVuX1JSgrS0NHh6epbbJyIiAu+++265dh8fn/uonoiIiEwhJycHjo6OVW5jsnBTSiaTGXwvhCjXdrftK2ovNWvWLEybNk3/vVarRUZGBlxcXKo8z91kZ2fDx8cHSUlJZj29xX7ULexH3SKVfgDS6Qv7Ubc8yH4IIZCTkwMvL6+7bmuycFO/fn3I5fJyozSpqanlRmdKeXh4VLi9paUlXFxcKtxHqVRCqVQatDk5Od174XdwcHAw6/8wS7EfdQv7UbdIpR+AdPrCftQtD6ofdxuxKWWyu6UUCgVCQ0MRFRVl0B4VFYWOHTtWuE94eHi57Xft2oWwsLAKr7chIiKih49JbwWfNm0avv76a6xevRqxsbGYOnUqEhMTMX78eAC6KaURI0botx8/fjyuXLmCadOmITY2FqtXr8aqVaswffp0U3WBiIiI6hiTXnMzePBgpKenY/78+UhOTkbLli2xfft2+Pn5AQCSk5MN1rzx9/fH9u3bMXXqVHz55Zfw8vLCkiVL8Mwzzzzw2pVKJebOnVtuysvcsB91C/tRt0ilH4B0+sJ+1C11tR8mXeeGiIiIqKaZ/PELRERERDWJ4YaIiIgkheGGiIiIJIXhhoiIiCSF4eYeLF26FP7+/lCpVAgNDcX+/ftNXdJd7du3D/3794eXlxdkMhm2bt1q8L4QAvPmzYOXlxesra3RrVs3nDlzxjTFViIiIgJt27aFvb093NzcMHDgQJw/f95gG3Pox7Jly9C6dWv9olfh4eH4/fff9e+bQx8qEhERAZlMhilTpujbzKUv8+bNg0wmM3h5eHjo3zeXfgDAtWvXMGzYMLi4uMDGxgaPPPIIjh07pn/fHPrSsGHDcr8PmUyGiRMnAjCPPgBASUkJ3n77bfj7+8Pa2hoBAQGYP38+tFqtfhtz6UtOTg6mTJkCPz8/WFtbo2PHjvjnn3/079e5fggyysaNG4WVlZVYuXKlOHv2rJg8ebKwtbUVV65cMXVpVdq+fbuYPXu22Lx5swAgfvrpJ4P3Fy1aJOzt7cXmzZvFqVOnxODBg4Wnp6fIzs42TcEV6N27t1izZo04ffq0OHHihOjXr5/w9fUVubm5+m3MoR/btm0Tv/32mzh//rw4f/68eOutt4SVlZU4ffq0EMI8+nCnI0eOiIYNG4rWrVuLyZMn69vNpS9z584VLVq0EMnJyfpXamqq/n1z6UdGRobw8/MTo0aNEocPHxYJCQli9+7d4tKlS/ptzKEvqampBr+LqKgoAUDs2bNHCGEefRBCiAULFggXFxfx66+/ioSEBPHjjz8KOzs78emnn+q3MZe+DBo0SAQFBYno6Ghx8eJFMXfuXOHg4CCuXr0qhKh7/WC4MVK7du3E+PHjDdqaNWsmZs6caaKKjHdnuNFqtcLDw0MsWrRI31ZYWCgcHR3F8uXLTVBh9aSmpgoAIjo6Wghhvv0QQoh69eqJr7/+2iz7kJOTIxo3biyioqJE165d9eHGnPoyd+5cERwcXOF75tSPGTNmiEcffbTS982pL2VNnjxZNGrUSGi1WrPqQ79+/cTo0aMN2p5++mkxbNgwIYT5/D7y8/OFXC4Xv/76q0F7cHCwmD17dp3sB6eljKBWq3Hs2DH06tXLoL1Xr144ePCgiaq6fwkJCUhJSTHol1KpRNeuXet0v7KysgAAzs7OAMyzHxqNBhs3bkReXh7Cw8PNsg8TJ05Ev3790KNHD4N2c+vLxYsX4eXlBX9/fwwZMgTx8fEAzKsf27ZtQ1hYGJ577jm4ubmhTZs2WLlypf59c+pLKbVajQ0bNmD06NGQyWRm1YdHH30Uf/zxBy5cuAAAOHnyJP766y/07dsXgPn8PkpKSqDRaKBSqQzara2t8ddff9XJfjDcGCEtLQ0ajabcgz3d3d3LPdDTnJTWbk79EkJg2rRpePTRR9GyZUsA5tWPU6dOwc7ODkqlEuPHj8dPP/2EoKAgs+oDAGzcuBHHjx9HREREuffMqS/t27fHunXrsHPnTqxcuRIpKSno2LEj0tPTzaof8fHxWLZsGRo3boydO3di/PjxmDRpEtatWwfAvH4npbZu3YrMzEyMGjUKgHn1YcaMGRg6dCiaNWsGKysrtGnTBlOmTMHQoUMBmE9f7O3tER4ejvfeew/Xr1+HRqPBhg0bcPjwYSQnJ9fJfpj08QvmSiaTGXwvhCjXZo7MqV+vvvoq/v33X/z111/l3jOHfjRt2hQnTpxAZmYmNm/ejJEjRyI6Olr/vjn0ISkpCZMnT8auXbvK/YuuLHPoS58+ffRft2rVCuHh4WjUqBG++eYbdOjQAYB59EOr1SIsLAwLFy4EALRp0wZnzpzBsmXLDJ7TZw59KbVq1Sr06dMHXl5eBu3m0IfIyEhs2LAB3333HVq0aIETJ05gypQp8PLywsiRI/XbmUNf1q9fj9GjR8Pb2xtyuRwhISF4/vnncfz4cf02dakfHLkxQv369SGXy8sl0dTU1HKJ1ZyU3hViLv167bXXsG3bNuzZswcNGjTQt5tTPxQKBQIDAxEWFoaIiAgEBwfjs88+M6s+HDt2DKmpqQgNDYWlpSUsLS0RHR2NJUuWwNLSUl+vOfTlTra2tmjVqhUuXrxoVr8TT09PBAUFGbQ1b95c/4w+c+oLAFy5cgW7d+/GSy+9pG8zpz688cYbmDlzJoYMGYJWrVph+PDhmDp1qn6k05z60qhRI0RHRyM3NxdJSUk4cuQIiouL4e/vXyf7wXBjBIVCgdDQUERFRRm0R0VFoWPHjiaq6v6V/sdZtl9qtRrR0dF1ql9CCLz66qvYsmUL/vzzT/j7+xu8by79qIgQAkVFRWbVh+7du+PUqVM4ceKE/hUWFoYXXngBJ06cQEBAgNn05U5FRUWIjY2Fp6enWf1OOnXqVG55hAsXLugfRmxOfQGANWvWwM3NDf369dO3mVMf8vPzYWFh+DErl8v1t4KbU19K2drawtPTE7du3cLOnTvx1FNP1c1+mOQyZjNWeiv4qlWrxNmzZ8WUKVOEra2tuHz5sqlLq1JOTo6IiYkRMTExAoD45JNPRExMjP4W9kWLFglHR0exZcsWcerUKTF06NA6dzviK6+8IhwdHcXevXsNbhPNz8/Xb2MO/Zg1a5bYt2+fSEhIEP/++6946623hIWFhdi1a5cQwjz6UJmyd0sJYT59ef3118XevXtFfHy8+Pvvv8WTTz4p7O3t9X+vzaUfR44cEZaWluJ///ufuHjxovj222+FjY2N2LBhg34bc+mLRqMRvr6+YsaMGeXeM5c+jBw5Unh7e+tvBd+yZYuoX7++ePPNN/XbmEtfduzYIX7//XcRHx8vdu3aJYKDg0W7du2EWq0WQtS9fjDc3IMvv/xS+Pn5CYVCIUJCQvS3Itdle/bsEQDKvUaOHCmE0N2SOHfuXOHh4SGUSqXo0qWLOHXqlGmLvkNF9QMQa9as0W9jDv0YPXq0/r8fV1dX0b17d32wEcI8+lCZO8ONufSldE0OKysr4eXlJZ5++mlx5swZ/fvm0g8hhPjll19Ey5YthVKpFM2aNRMrVqwweN9c+rJz504BQJw/f77ce+bSh+zsbDF58mTh6+srVCqVCAgIELNnzxZFRUX6bcylL5GRkSIgIEAoFArh4eEhJk6cKDIzM/Xv17V+yIQQwiRDRkRERES1gNfcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQSUy3bt0wZcqUSt+XyWTYunVrpe9fvnwZMpkMJ06cqHSbvXv3QiaTITMz857rNEZ1ajIHd/vZE1HNsDR1AUT0YCUnJ6NevXqmLuOhxJ890YPBcEP0kPHw8DB1CWZLrVZDoVDc8/782RM9GJyWIpIgrVaLN998E87OzvDw8MC8efP07905NXLkyBG0adMGKpUKYWFhiImJKXe87du3o0mTJrC2tsZjjz2Gy5cvl9vm4MGD6NKlC6ytreHj44NJkyYhLy9P/37Dhg2xcOFCjB49Gvb29vD19cWKFSvuqX8ajQZjxoyBv78/rK2t0bRpU3z22Wf69/ft2wcrKyukpKQY7Pf666+jS5cuRtW8YMECjBo1Co6Ojhg7dmyVdanVarz66qvw9PSESqVCw4YNERERoX+/7M9+3rx5kMlk5V5r164FAAgh8MEHHyAgIADW1tYIDg7Gpk2b9Me6desWXnjhBbi6usLa2hqNGzfGmjVrjP5ZEkmSyR7ZSUS1omvXrsLBwUHMmzdPXLhwQXzzzTdCJpPpnzwOQPz0009CCCFyc3OFq6urGDx4sDh9+rT45ZdfREBAgAAgYmJihBBCJCYmCqVSKSZPnizOnTsnNmzYINzd3QUAcevWLSGEEP/++6+ws7MTixcvFhcuXBAHDhwQbdq0EaNGjdLX5efnJ5ydncWXX34pLl68KCIiIoSFhYWIjY29a58SEhIMalKr1WLOnDniyJEjIj4+XmzYsEHY2NiIyMhI/T5NmjQRH3zwgf774uJi4ebmJlavXm1UzQ4ODuLDDz8UFy9eFBcvXqyyzg8//FD4+PiIffv2icuXL4v9+/eL7777Tv9+2Z99Tk6OSE5O1r8++ugjYWNjo3+S8ltvvSWaNWsmduzYIeLi4sSaNWuEUqkUe/fuFUIIMXHiRPHII4+If/75RyQkJIioqCixbdu2u/4siR4GDDdEEtO1a1fx6KOPGrS1bdtWzJgxQwhh+AH71VdfCWdnZ5GXl6ffdtmyZQZBYtasWaJ58+ZCq9Xqt5kxY4ZBuBk+fLgYN26cwTn3798vLCwsREFBgRBCFxSGDRumf1+r1Qo3NzexbNmyu/bpznBTkQkTJohnnnlG//37778vmjdvrv9+69atws7OTuTm5hpV88CBA+9aX6nXXntNPP744wY/q7LK/uzLOnTokFCpVPpwlpubK1QqlTh48KDBdmPGjBFDhw4VQgjRv39/8eKLL1a7NqKHCaeliCSodevWBt97enoiNTW13HaxsbEIDg6GjY2Nvi08PLzcNh06dIBMJqt0m2PHjmHt2rWws7PTv3r37g2tVouEhIQK65LJZPDw8KiwrupYvnw5wsLC4OrqCjs7O6xcuRKJiYn690eNGoVLly7h77//BgCsXr0agwYNgq2trVE1h4WFVbumUaNG4cSJE2jatCkmTZqEXbt23XWfxMREDBw4ENOnT8egQYMAAGfPnkVhYSF69uxpUN+6desQFxcHAHjllVewceNGPPLII3jzzTdx8ODBatdJJHW8oJhIgqysrAy+l8lk0Gq15bYTQtz1WNXZRqvV4uWXX8akSZPKvefr62t0XXfzww8/YOrUqfj4448RHh4Oe3t7fPjhhzh8+LB+Gzc3N/Tv3x9r1qxBQEAAtm/fjr179xpdc2kYqo6QkBAkJCTg999/x+7duzFo0CD06NHD4FqZsvLy8jBgwACEh4dj/vz5BrUBwG+//QZvb2+DfZRKJQCgT58+uHLlCn777Tfs3r0b3bt3x8SJE/HRRx9Vu14iqWK4IXqIBQUFYf369SgoKIC1tTUA6Ec6ym5z59osd24TEhKCM2fOIDAwsFbrLbV//3507NgREyZM0LeVjmiU9dJLL2HIkCFo0KABGjVqhE6dOtV6zQ4ODhg8eDAGDx6MZ599Fk888QQyMjLg7OxssJ0QAsOGDYNWq8X69esNRsaCgoKgVCqRmJiIrl27VnouV1dXjBo1CqNGjULnzp3xxhtvMNwQgXdLET3Unn/+eVhYWGDMmDE4e/Ystm/fXu7Dcfz48YiLi8O0adNw/vx5fPfdd/o7ekrNmDEDhw4dwsSJE3HixAlcvHgR27Ztw2uvvVYrdQcGBuLo0aPYuXMnLly4gHfeeQf//PNPue169+4NR0dHLFiwAC+++GKt17x48WJs3LgR586dw4ULF/Djjz/Cw8MDTk5O5badN28edu/eja+++gq5ublISUlBSkoKCgoKYG9vj+nTp2Pq1Kn45ptvEBcXh5iYGHz55Zf45ptvAABz5szBzz//jEuXLuHMmTP49ddf0bx583uunUhKGG6IHmJ2dnb45ZdfcPbsWbRp0wazZ8/G+++/b7CNr68vNm/ejF9++QXBwcFYvnw5Fi5caLBN69atER0djYsXL6Jz585o06YN3nnnHXh6etZK3ePHj8fTTz+NwYMHo3379khPTzcYxSllYWGBUaNGQaPRYMSIEbVes52dHd5//32EhYWhbdu2uHz5MrZv3w4Li/L/q42OjkZubi46duwIT09P/SsyMhIA8N5772HOnDmIiIhA8+bN0bt3b/zyyy/w9/cHACgUCsyaNQutW7dGly5dIJfLsXHjxnuunUhKZKI6E+pERGZq7NixuHHjBrZt22bqUojoAeE1N0QkSVlZWfjnn3/w7bff4ueffzZ1OUT0AHFaiohMbuHChQa3PJd99enT556O+dRTT2HAgAF4+eWX0bNnzzpbJxHVPE5LEZHJZWRkICMjo8L3rK2ty90ObSrmUifRw47hhoiIiCSF01JEREQkKQw3REREJCkMN0RERCQpDDdEREQkKQw3REREJCkMN0RERCQpDDdEREQkKf8PY4ozA9W6J/kAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(layer_size, train_scores, label=\"Train score\")\n",
    "plt.plot(layer_size, test_scores, label=\"Test score\")\n",
    "plt.ylim(0,1)\n",
    "plt.xticks(np.arange(0,100,10))\n",
    "plt.xlabel(\"hidden_layer_sizes\")\n",
    "plt.ylabel(\"Model score\")\n",
    "plt.legend()\n",
    "\n",
    "print(f\"Max neural network score on the test data: {max(test_scores)*100:.2f}%\")\n",
    "# default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3616e9cc-8b45-4e40-8a6b-f52a7199211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f1_train_scores_relu=[]\n",
    "f1_test_scores_relu=[]\n",
    "\n",
    "for i in layer_size:\n",
    "    NN.set_params(hidden_layer_sizes=i, max_iter=1000,activation='relu')\n",
    "    NN.fit(X1_train,y1_train)\n",
    "    y1_train_pred = NN.predict(X1_train)\n",
    "    y1_test_pred = NN.predict(X1_test)\n",
    "    # update the training scores list\n",
    "    f1_train_scores_relu.append(f1_score(y1_train,y1_train_pred))\n",
    "    f1_test_scores_relu.append(f1_score(y1_test,y1_test_pred))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c283b60-4f6a-40e2-8add-84a6e2748c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f1_train_scores_logistic=[]\n",
    "f1_test_scores_logistic=[]\n",
    "\n",
    "for i in layer_size:\n",
    "    NN.set_params(hidden_layer_sizes=i, max_iter=2000,activation='logistic')\n",
    "    NN.fit(X1_train,y1_train)\n",
    "    y1_train_pred = NN.predict(X1_train)\n",
    "    y1_test_pred = NN.predict(X1_test)\n",
    "    # update the training scores list\n",
    "    f1_train_scores_logistic.append(f1_score(y1_train,y1_train_pred))\n",
    "    f1_test_scores_logistic.append(f1_score(y1_test,y1_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2118ae4b-df53-4934-90cc-d7fcfc0d6e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x18ea82ad910>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAG2CAYAAACDLKdOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAACfWUlEQVR4nOzdd3hT1RvA8e/NaJvuPSltgTKVWVFARAUEVBBFRVGRLQoiIqK4QEX5iQsUAUUEREXEiYoMZQ/ZBZSyuyiF0kH3TO7vj5RIhWKBtjdt38/z9Glye8ebtE3enPOecxRVVVWEEEIIIWoJndYBCCGEEEJUJkluhBBCCFGrSHIjhBBCiFpFkhshhBBC1CqS3AghhBCiVpHkRgghhBC1iiQ3QgghhKhVJLkRQgghRK0iyY0QQgghahVJboQQQghRq2ia3GzYsIHevXsTHByMoij8+OOP/3nM+vXradeuHU5OTjRo0IA5c+ZUfaBCCCGEqDE0TW5yc3Np1aoVM2fOrND+sbGx3H777XTu3Jk9e/bwwgsvMGbMGL777rsqjlQIIYQQNYViLwtnKorCDz/8QN++fcvd57nnnmPZsmXExMTYto0cOZK9e/eydevWaohSCCGEEPbOoHUAl2Pr1q3cdtttZbb16NGDefPmUVxcjNFovOCYwsJCCgsLbfctFgvp6en4+PigKEqVxyyEEEKIq6eqKtnZ2QQHB6PTXbrjqUYlN6dOnSIgIKDMtoCAAEpKSkhNTSUoKOiCY6ZOncqrr75aXSEKIYQQogolJiZSr169S+5To5Ib4ILWlnO9auW1wkycOJFx48bZ7mdmZlK/fn0SExNxd3evukCFEEIIUWmysrIIDQ3Fzc3tP/etUclNYGAgp06dKrMtJSUFg8GAj4/PRY9xdHTE0dHxgu3u7u6S3AghhBA1TEVKSmrUPDcdOnRg9erVZbatWrWKqKioi9bbCCGEEKLu0TS5ycnJITo6mujoaMA61Ds6OpqEhATA2qU0cOBA2/4jR44kPj6ecePGERMTw2effca8efMYP368FuELIYQQwg5p2i21c+dObrnlFtv9c7Uxjz76KAsWLCA5OdmW6ABERESwfPlynn76aT766COCg4P54IMP6NevX7XHLoQQQgj7ZDfz3FSXrKwsPDw8yMzMlJobIYQQooa4nPfvGlVzI4QQQgjxXyS5EUIIIUStIsmNEEIIIWoVSW6EEEIIUatIciOEEEKIWkWSGyGEEELUKpLcCCGEEKJWkeRGCCGEELWKJDdCCCGEqFUkuRFCCCFErSLJjRBCCCFqFUluhBBCCFGrSHIjhBBCiFpFkhshhBBC1CqS3AghhBCiVpHkRgghhBC1iiQ3QgghhKhVJLkRQgghRK0iyY0QQgghahVJboQQQghRq0hyI4QQQohaRZIbIYQQQtQqktwIIYQQolaR5EYIIYQQtYokN0IIIYSoVSS5EUIIIUStIsmNEEIIIWoVSW6EEEIIUatIciOEEEKIWkWSGyGEEELUKpLcCCGEEKJWkeRGCCGEELWKJDdCCCGEqFUkuRFCCCFErSLJjRBCCCFqFUluhBBCCFGrSHIjhBBCiFpFkhshhBBC1CqS3AghhBCiVpHkRgghhBC1iiQ3QgghhKhVJLkRQgghRK0iyY0QQgghahVJboQQQghRq0hyI4QQQohaRZIbIYQQQtQqktwIIYQQolaR5EYIIYQQtYokN0IIIYSoVSS5EUIIIUStYtA6ACEqQlVVzBYVg96ajxcUm9l8NJWsgmIy84rJKighK7+YzPxisgqKaR/hw9AbIzSOWgghhBYkuRHVxmxRySpNPrLyS8jML8bPzZEmgW4AnM0r4p1Vh8jML5uoZOVb978vqh5v3H0tYE1uhi7cWe61HAx62+2cwhKe/Go3Q26M4MZGviiKUrUPVFzS2bwiPJ0dtA5DCFGLSXIjLltRiYXY1NzzWk1KE5HShCUq3Ivbrw0C4OTZfO6bs5XM/GJyCksuONdD19e3JSyqCl/8mVDudbMK/jnezcnItSEeeJiMuJsM1u9ORtxN1q9If1fbvp9vjWPtoTOsPXSG9uHePN29MR0a+lTW0yEuQVVViswWHEuTzT+PpzFkwQ5G3NSAETc1wNlBXoKEEJVPXlnEBX7Yc4I/YlJKExZrl8+97eox6pZGACRn5tNj+oZyjy8sMduSG5NRT9LZ/DI/d3bQ25IRX1dH23Z3k5GnukbibjKW/rw0aSm9bTToOHk239by81TXSLIKisku7ZLKKigmIS2PrIJiVv51ijeXx+BhMtK3dQiDO4bz5fYEtsel8+DcP+nY0Idx3RsTFe5dBc+gsFhUVh04zcy1R7gp0o8JPZsC8FP0SfKKzEz//QiLtycw/rYm9GtbD51OWtOEqA2W7kzk4KlsXr6zuaZxSHIjyigoNvPs0n2UWNQy20+el6C4OxnxdnGwJSDnWkvOJSztwrxs+3qYjPw0qhOujgb0egXVopJXbCYrv4TsAmvi9NmmWFvCklVQzMFTWbbb57ZnFxTzr5AqbOORVJoGuvHyHc04fDqHr3cksOVYGluObeXmJn7MHRiFUS+19ZXBbFH5Zd9JPlp7lMOncwA4nVXI2G6NScku4Lbm/kSFezH998Mkpufz7Lf7WLAljhfvaEbHhr4aRy+EuBKqqtq6+71dHPh8axz9r6tH4wB3zWJSVFW9wreMmikrKwsPDw8yMzNxd9fuibdXf5/M5I4PNuHmaGBynxa2lpMAN0fcTcYyycb5Ccm5Fp5/bzvXqpJTVEJl/KUZ9co/3U+liZWbk+GCbe5O1u3b49L5Yms8uUVmACJ8Xeh/XT1iz+Tx3e4T9Lo2iA8fbHP1gdVxxWYLP+xJYva6Y8Sm5gLg5mhgYMcwro/w4Zudifz21ynMFhVPZyMD2tfHqNfx2aZYsku7Kx++oT5T+l6r5cMQQlyGnXHpfLzhONcEe/BUt0jyikpYuusEs9cepXGAG58Pvb5Sr3c579/SciPKOJpi/bStovLxhmO25ORccnC1HA26iyYh7raamX8SlXNJi8d52xwNussqCO7aLIAnujRiwZY45m+JJTY1l//9doggDyeeuLkhfVqH2PaNS83lrRUHGdM1kmZBkvhejvdWH2b2umMAeDobGdIxgvo+Jr7alshHa4/Z9vNxcSAtt4hZ647haNBxZ8sgzBaVn/clc510EQph9851OX+y4Ri7E84CsCMuneyCYr7ZmWirjcwtMms6eEBabkQZ22PTuP/jP8v9ubODvtwk5OLbyrawOJ43iqm65RaW8NW2BOZuPE5KdiFgfbMdcmMEj3QIY/Kyv/l+dxIAd7QMYmzXSCID3DSL157lFZWQlV9CoIcTAInpedz/8VYevj4MRwcdX/6ZYGvBMegU+rQOZtiNDWgS6MbKv0/x8fpj7D2RCYCiQOdGvoztFknbMGuC8+OeJM5kFzKwY5imfzNCCKuCYjPf707i043HOX7e/3aghxNJGfmcSyTCfJwZ1DGce9vVw83JWKkxXM77tyQ3ooy9iWe566PNeLs48OGDbcokLa5OhlpRm1JQbObbXSeYs/4YJzKstURuTgZ6twzmTE4hqw+cBqxvune1CmZM10ga+Lle6pR1RlZBMZ9viWPepljaR3jz8SNRAJzJLmThlli+3JZARl4xAO5OBgZcH8agjuG2JOgcVVXZFpvOJxuOs+Zgim17+3BvHu0YxqRlf5OaU0R9b2ee79WUXtcEyhB+ITT06s9/M39zHGAdKOLiqCc1p8j2806NfBjSKYJbmvhX2QABSW4uQZKbS/t21wnGL91LhwY+LB5xg9bhVKkSs4Vle08ya90xW3ecyainR4tAMvKKWH/4DAA6BQZ2CGdynxZahqup9NwiPtsUy8KtcWSXNjtH+Low44HWfPlnAj9EJ1FUYgEg1NvEkE4R3B8Viovjf/d8Hz6dzScbjvNTdBLFZuvLkb+bI/nFZtu1osK8ePGOZrSp73WpU4k6QlVV299HdkEJBcVmGvq5YnKQVr7KkpieB0CotzMAO2LTGbpwB2aLaitTcDTouKdtCIM6RtjmK6tKktxcgiQ35Ss2W3hm6V6WRZ9kYIcwXrvrGq1DqhbWPuRTfLT2GPuTrF0lRr3CrU39ySooYeuxNMZ2i2Rst8YaR1r9UrIKmLvxOF/8mUB+sfUFrXGAK92aBfDXyUw2HE617dumvifDOzegR4tA9Ffwye1UZgHzt8Ty1Z8JtiJjZwc9xWaLLenp0yqY53o1JcTTVAmPTlQ3VVUpKLaQXWgdbJBTUEJOoXWAQrbt9r+/F5+3X+n9wpILRk86O+jp1iyAO1sG0aWJn3RnXqH9JzL5eMMxlu9PpnerYIZ3bsBnm2P5ZW8yRWbrB5hAdyce6RDGg+3r4+1SfTU1ktxcgiQ35Tuakk2396zz17zWpzkDO9at5QtUVWXjkVRmrj3K9th0wNpqc2MjX8Z2a0zb0iHum46ksuLvZEbd0oggj9r9JvvZplhe++UAAC2C3bku3Jttx9OIOZUNWLvuejQPZPhNEbQLq5yC4KyCYr7ensBnm+I4lVUAWPv2z01P8OOoTrQO9ayUa4mKUVWVwhLLBQlH9rkkpDThyC7ddqmkxXylczpchII1qbGoKvnFFtt2NycDtzUPpHerIDo18q0V3elVSVVV1h0+wyfrj7P1eJptu4fJSGZ+se1+m/qeDOkUQc9rAjV5TiW5uQRJbsq34q9kRn6xG4DFw2+o07P47ohL56O1R1l36IxtW/fmATxxc0Ne/fkA0YlncTDoGNC+Pk/c3BB/d6dLnK3miEvNJT2viLal3T/5RWZGfrELPzdHNhxOISXb2sduMuq5P6oeQ26MIMzHpUpiKSqxdhvO3XCcQ6etyZROgb6tQxh+UwOaBbmzOyGDliEetjXHRMUdO5PDn8fTOJtXXKZFpEzSUliaxBSUXDD31dVQFHB1LK3lczTg6mTAzcmAq6P1u9u57aU/c3cy4OpotO339fYEth6zJtnnJ0s6BQw6na2FAcDL2UjPawLp3TKY6xv4XFGrYm224q9TvL/6cJn/MUeD3tZSa9Ap3NEyiMGdIjT/UFGjkptZs2bx9ttvk5ycTIsWLZg+fTqdO3cud/8vv/ySadOmceTIETw8POjZsyfvvPMOPj4VeyOW5KZ87606zAdrjgCw86VuZWYPrqv+Sspk1rqj/PbXKds8PdeGeFBstnCwtPXCyajjkRvCeKxLwxr7nB0+nc1Ha4/y896TNPJ3ZcVTN5F0Np95m2L5ZmcieaV97H5ujgzqGM5D19evtiGe5z5Vfrz+GH8eT7dtvy7Cmz3xGUT4uvDCHc24ubGfFB1fQrHZwo64dP6ISWHNwRTbaLbLoSjg6lA2GXEtnc7B7bxkxM3JaL1fTtLi7KD/z9+VqqocT81lZ1w6McnZTOrd3HbMsIU7+T3GWvgf4mmiRbA7MaeySEzPp119L57r1ZRf9p1k+f7kMkWvvq6O3H5tIHe2DCYqzEtmxgbmrD/G/347iKH0uTiXxHq7ODCgfX0eviHsggEBWqkxyc2SJUt45JFHmDVrFp06deLjjz/m008/5cCBA9SvX/+C/Tdt2kSXLl14//336d27N0lJSYwcOZLIyEh++OGHCl1TkpvyPfrZdtYfPoPJqOPAaz3ljeI8R1NymL3uGD9GJ9k+KTbyd0FV4dgZ65uEs4Oe53o25dGO4RpGenn+Sspk5pqjrPj7lG1buzAvvJyNrDmYYqtraBroxtAbI+jTOljTWoZ9J87y8Ybj/LY/+YKai06NfHj5zuY0DZT/63MycotYdziFP2JSWH/4jK1AG6x1ZdeFe1PPy2RLOtxsyYi1lcTaumKw3XZxMFRZQlBUYuHvk5nsjMtgR1w6O+MzSM/9JzHZ9Nwt1POyFrduOpJKWm4hUeHetvqrc8lQVn6xrfA8PbeIdlNWX3QC0UB3J+5oGUTvVsG0qudRJ17vkjPzmb85jqgwL7o1C2DDkTPM3XCczcf+6YpqGujG4E7h3NU6BCejfdUt1Zjk5vrrr6dt27bMnj3btq1Zs2b07duXqVOnXrD/O++8w+zZszl27J9JwT788EOmTZtGYmJiha4pyU35Ov1vDUln84n0d2X1uC5ah2OXEtPz+GTDcZbsTLSNDqrnZUKnKCSk5/Hhg23o3SpY4yj/298nM3ln5SHWntft1qa+J4XFZg4kZ9u2dY70ZXjnBnSOtK/V1BPS8vh003GW7EigsOSflzAF6NcuhAk9m+LvZh+fNquTqqocO5PD7zEprIlJYWd8epkk0MfFgVua+tO1qT+dG/vhWoHRbFUlu6AYJ6PeVrvx+i8HmLcptsw+jgYdrUM9uS7c+4paEE5nFfDhmiOsPXjmgjXuzhfqbeKOa4Pp3SqI5kHudvW3XhkOnsrikw3HWRZ9khKLSoinCUeDwvFU64goRYFuzQIY3CmcDg187Pbx14jkpqioCGdnZ5YuXcrdd99t2/7UU08RHR3N+vXrLzhmy5Yt3HLLLfzwww/06tWLlJQU7r//fpo1a8acOXMuep3CwkIKCwtt97OysggNDZXk5l/MFpXGL/2G2aLSu1UQHz7YVuuQ7FpKdgHzNsWWWdohwN2Rp7s15p629XAw6FiyI4HTWYUM7hRe6ZNZXa31h8/w6Gfb0SlwTYgHZ7ILSc60Fu8a9Qp3tQ5hWOcIu28FSc8tYtHWeD7bHFum8NFk1PP7MzcR4umsYXTVo6jE2t30e8xp/ohJIaF0CO85TQPd6NrMn1ubBtA61FOzmpPkzHx2xmWwMy6dHXEZHDyVxVfDb+CGBtaSguX7k3nxh/1EhXtzXbgXUeHeXBPsgYPh6uupVFXlaEoO6w6dYe2hFHbEpVNsVmlVz4MjKTm2bleAUC8Td7etR++WQTV6Ek9VVdl6PI2P1x+3TWsBoFegdPAhro4G7o8K5dGOYVVWO1eZakRyc/LkSUJCQti8eTMdO3a0bX/zzTdZuHAhhw4duuhx3377LYMHD6agoICSkhL69OnDt99+i9F48TePyZMn8+qrr16wXZKbsuLTcuny9joAXr6zGUNvbKBtQDXE2bwiFm6JZ/6WWM6WTl4X7OHEoI7hzN0Yy5mcQjydjYy4qQGPdgiv0LwvlU1VVdYeSiEtp4j7okIBOJ2Zz5OL9xBzKtvWVeFhMvLwDfV5tEN4jSuQzi8y8+3uE8xcc4TTWdYPM44GHf3a1WN45waE+zjb7afRK5GeW8S6Q9bupg2Hz9iGzgM46HXc0NCHbs38ubWpv60rRwsHT2Xx8frj7IhLt02Yeb5X7mzOkButozJLzBb0OqVafk85hSVsPppK2/peuDoaWHMwhZlrjxBzXqslQD1PE/3ahtC3bT0ifO3/zf98E7/fx+LtF+/RCD83i3BUqKatd5erRiU3W7ZsoUOHDrbtb7zxBosWLeLgwYMXHHPgwAG6devG008/TY8ePUhOTubZZ5/luuuuY968eRe9jrTcVExGbhHd31tPam4RXwy9nhsjZYXmy3FuaYdPNh7nTOnSDm6OeowGva1uwMfFgZFdGvLwDWHVMtmYxaKy8u9TfLjmKAeSs3B3MrBgcHu+2p7AsuiTthEl9b2dGdY5gnvb1cPZoea80F2M2aLy21/JfLzhOPtLl3cA62zJz/ZswiM3hGsX3FVQVZUjKTn8HnOaNTEp7E7IKNPd5OvqwK1Nra0znSN9qz2JLiwxs/9EJjviMmhZz4NOjayvH/tOnKXPzM2AdRROi2APosK9uC7cm6gwL7tKon/bn8xnm2PZFZ9xQT0XWOd3uqdtPe5sGaRpwlievNLFiV0cDRSWmJm6/CALt8aVqTe6sZEvgzuFV+kswlWpRiQ3V9It9cgjj1BQUMDSpUtt2zZt2kTnzp05efIkQUFB/3ldqbm5uMISM81eXoFFhW0vdCXAjl50apKLLe3gZNThaNDbuk18XR15q9+1dG0WUCUxlJgt/LIvmY/WHuVI6czLjgYdfm6OZT49twvzYnjnCLo3v7JJ9+yZqqpsj7WuWHz+8g6ezkaeva0JD7avb/cv7oUlZrbHWkc3/XHwNInpZVs+mgW521pnWtXzrNbHk5lXzK4Ea/fSzrh09p7ItNWg9Y8K5a17WwLWv8WZa48SFeZN6/qeNaKVILugmM1HU1n192l+jzltWwjyfA38XOjYwIfHujS0zeCrlTPZhXy+NY5Ff8YzoH19HAw6vvgzgdScf1owq3MW4apUI1YFd3BwoF27dqxevbpMcrN69Wruuuuuix6Tl5eHwVA2ZL3e+gm4jk3XU+liU3OxqNbJr/zdauZwZnvgZNTz8A1h9L8ulJ/PW9qhoNiCUa/gaNCTmlNYZcnj9th0nv12L/FpeaXx6HBxMJCWW8SJjHx0CvS8JpBhnRvY5rKpjRRF4foGPlzfwIdtsWm88P1+jp3J5WxeMS/++BfTVh5kbLdIBlxvXwtzpuUUsvbQGf6IOc2Gw2ds9VwADgYdHRv60LVZAF2b+hNcTbM0q6p1uv1ziUlmfjGtX191wQgkX1cHrgv35voG/0zmaNDratzM3m5ORnpeE0TPa4JQVZWY5Gx2xaej0yn8sjeZP2PTOH4ml+NncvliWwKezkY6R/oxonME19bzrLY4j5/JYe7GWL7bfcKWWM5ed8y2gKVWswjbC7sYCj5nzhw6dOjAJ598wty5c/n7778JCwtj4sSJJCUl8fnnnwOwYMEChg8fzgcffGDrlho7diw6nY5t27ZV6JrScnNxU5fH8PGG47QO9eDHUTdqHU6tcW5ph5lrj/JXUhZgnRTrvqhQRnZpQJiPCx/8cQQ/N0fubVfvqmf9jE3Npeu763A06NEp2N4cnR303B8VypBOEdT3sb8m9eqw9Vgqz323j4TzWkDcnAw8fnNDHro+DA9T9Rd9q6rKodPZ1taZmNPsSTxbJmnwc3Pk1ib+dG3mz42RvtXSbWi2qBw8lfXPkOy4DBr4ufDV8H/Wmuv67jpU4Lowb1s3U1gtq2sqT/LZfJ74ajd/JWXalgU5x9lBz42NfJl2b8sqmwdqV3wGH68/xuqY0xcd4t62vieDNZxFuCrViG6pc2bNmsW0adNITk7mmmuu4f333+emm24CYNCgQcTFxbFu3Trb/h9++CFz5swhNjYWT09Pbr31Vt566y1CQkIqdD1Jbi6kqipNXlpBkdlCzxaBzHmkndYh1TqqqrLhSCof/Wtph27N/Flz8AwlFpVQbxNjbo3k7jYhFZpxN6ewhC//jCc5s4DJfVoQn5bLZ5tiWbw90VZPE+DuyKCOEQxoXx8PZ/sasaWVlX+f4uUf/yIl+59aPBcHPQ+2r8+QGyOqvEWksMTMn8fT+aN0dNO/hyi3CHa3tc5cG+JRbd1N8zbFsv7wGXbHZ5BTWLYrxs3JQPQrt9m6LwuKzXY3B0p1U1WVdYfOsHBLHNvj0suMuDLoFDpH+nJnyyDyi83c2jSg0v6unvxqNz/vSy6zTa/Ana2C7WIW4apUo5Kb6ibJzYWSM/PpMHUNABN7NeWxLg01jqh2u9jSDg76f6aMj/B14amukfRuFXzRWpjM/GIWbonjs83WEVoK0KmRL5uPpdo+yTULcmd45wjubBlcKUNpaxuzReWXfScpKrHw6cZY29TzegX6tA5hROnyDpXlTHYhaw9ZW2c2Hkkt80boaNDRqZFv6XBt/ypZr6yoxMLJs/mcyMjnREYeJzLySc4s4J37WtpaWwbN3277m3R1NNA2zIvrwqxDsluHesqK2//hryTrBJN7E8+WaR08J9jDiV7XBtK9eSDtwrwq1KpSUGzm+91JXBfuhaIoLNgSy9KdJygs7YY6N4vwIx3C6kSdpCQ3lyDJzYU2HD7DwM+2A7Bg8HXc3MRf44jqhost7XD+ApGN/F2Z8UBrWgR7ANZ6jHmbYlm0Nd429NfRoLO90AF0aezHiJsa0LGh/U7EZW9UVWXF36cYs3hPmW6GzpG+jOzS8Iqey3O1Gn/EnOaPgynsPVG2u8nfzZGuzfzp2jSATo18rzpxKDZbSD5bwImMPDqcF++0FQf5fncSp7MLLtqFcf4yKyv/PsWpzAKiwr1oGuhe64rMq9PRlBx+2XeSpTsTSTpbcMHPnYw6bor0Y+TNDS9a+3Y2zzp/04ItcaTlFhHg7mib4gCscxcN6WSdMbwutaDViIJiYT8Onsqy3a7Jk1bVNNeEeDDroXYcTclm9rrj/BidZEts9DqFxPQ8AkqLu7ccS2Xogp22xeyMeoVis3WlZge9jr5tghnWuQGN5fd32RRF4foIH3q3Cub73Um27RuPpLLxSCotgt15rEtDbr8m8JLdhQXFZrYeT+OP0uHaJzPLvqldG+JhS2iuCbnyWXA3H01lW2y6tQUm3doScyqrwDZ8eddL3fApTVgKii22ldWdjDrqeTlTz8tEaOl3o+6fx9OjReAVxSMu1MjflbHdGvNU10gOnspm6c5Efoo+SVrptBAFxRZWHThNTmEJwzpHcGMjP5LO5hOflsu6Q2dYsiPR9r8OcDqrsMbMImwvpOVGMOrL3fy6PxmjTuHwG73kn0YjF1vaoVmQO6NuaUiTADfu/HATxWaL7U3M09nIIzeE8UiHsDq51EBV2HfiLFN+jbHVRZ2vnpeJoTdG0P+6UFthb0p2AWsPpvB7TAqbjqSWeUNyMuq4sZEvXZsFcGtT/0t2G5SYrUmItdson8T0vDJdSMtGd7IlLK/+/DfzN8ddcA5Hg456XibmDoyigZ8rYB1Rk5lfTD0vZ3xdHeR/W0OqqrI/KZNl0Un8uOckqeetm+VhMhLg7sjh0zkXHOfioKf/dfUZ1DG8zg4GOEe6pS5BkpsLdXt3HUfP5FLf28SGCbdqHU6dl5JdwLyNsXzxZ3yZocDnRPi6MOTGCO5tW0/qIKqAqqqsOnCaqctjiCsdUu/uZLDNd+JhMnL7tUEcOJnJ3vMmCgTr8Ntbm/nTrZk/HRv62roMzBbVmrzYkpZ8BnUKt43QKi9hOeenUZ1oVVoouvLvU6w/fIZ6XiZbS0w9LxN+ro6SvNQQFovKnsQMft6bzK/7k20Tf54vzNvE4E4RNW4W4aokyc0lSHJTlqqqNHtlBQXFFro29WfeoOu0DkmUOptXxIItcczfHEdmfjHtw70Z1jmCbs0C7H4CutqgqMTCF3/GE5uay4t3NOPbXSeYu/G4bQ6hc1rV8+CWpv60DvWkQwMfHEsTmp+ik1iyI5HEjDySzxbYuhzPWTa6Ey1L50WZtymW//0WQ4iniVBv5wsSl2ZB7jV+9mhxcWaLdcLJn/edZMPhM0T4ujCoY82dRbgqSXJzCZLclKWqKg/O/ZM/j6fzzG2NefLWSCx5eViKizF4eGgdnsC6blJmfvFlr4gsKl98Wi63vb+BYE8nWyFuSnYhJ8/mU2xW+Xn0jVxbz/p/8+nG40z5NcZ2rFGvEOz5T73LsM4RNPK31kgVlpgx6nTyZibEJUhBsagwRVHIzLc2tzcPcidtwQJS3n4HzGaM9UNx69YdU6tWmFq1xBgoBYdaMDnopfvJTvwRk0JhiYXY1DxiU8u24Bh0CmdyCgBrcnNzE398XB1sLTD+bk7ljkCyp1mShagNpOWmjjNbrN1SRSUWvoz/Du89W8vdV+fujnNUO0xt2lgTnhYt0LnUrJVyhbha22PTWb4/GS9nB1u3UT1vZwLcHCs0+aIQ4spIy42osG92WEfmOJiL8NjzJwAO4eH4PvUUlpwcCv76i/x9+yg8eBBLVhY5a9aSs2at9WBFwbFxY0wtW2Jq1RJTq1Y4NGiAopdPoaL2ah/hTfsI7//eUQihGUlu6jBVVZn3/VZQXPEozEGvgPewYQQ888w/O913LwBnZs3m7NdfU5KScv4JKDx0iMJDhzhbulK7zsUFp2uv/SfhadkSg59fdT4sIYQQdZx0S9VRxadPk/zCi/Tw7EW+0Yl2aUf54pkemJo2LfcYVVUp+Osvsn5dTtZvv1Fy+jQAOjc3HJs0oeDAAdS8vAuOMwYH49SqJaaWrTC1aoVT82bonKQ4VghRu6hFRdYBGfn51u951u9qYQGupWsmAmStWEFBzEEs+XnWn5/br6gI99698by7r3YPwo7JaKlLkOQGMr7+mpT3p5OVV8h9d0wBYPQtDRjfo1mFz6FaLOTv3k3W8uUYQ0LwGToUtaSEgoMHOfHEKHTu7qiFBRQnnrjwYIMBpyZNMLVqiVPL0u6s8HCZo0MIUeVUVUUtKDgvAclDLU1I1JISXDp2RC0pQS0uIfPHHymKPY4lN9eWqFjy87Hk54PZTODLL9n2PfPBDAr2/1Xudf3GPQ1mM2pxCVkrVlB0/PjFd1QUIn76EafGjavoGai5pOZGXFRxSgoJAx+lKC4OgNNRt9h+dm29C9c3uRRFp8M5KgrnqKh/thkMlKSmWruuSruvDMHBOLdpjd7Ti6KTJynYvx9zaioFf/9Nwd9/w1eLAdB5eGA6rzvLqWVLDF6XF5MQou4pOnGC5BdepCQ1FbW42PpVUoJaUgIlJaAoOEREoJYUQ3ExRQmJqIUXTpp3JeIffqTC+5557/2K7aiqFOz/S5KbqyTJTR2R8c03nHrtdes/O+DSqRM5w56Fnw4AEOnvWinXcenYkXqzPiLr1+Vkr1lDycmTZJ08CYBDgwYEv/M2jqGh5O/bR370XvL37aPgwAEsmZnkbtpE7qZNtnMZw+pbu7LOJTxNm6I4OFRKnEKImq/oRBIJjw6iOCnpkvsV7Nt3dRfS6UCvtw6W0OtRDAYUgwGdiwuKgxHF6ACKgqLXozg4oHN0BKMBxWC07ms8990AtvtG23kUo3VbwYEYspYvJ/nFF1GLi3C/807rNaRV+7JJt1QtZ87PJ/Gxx8jfvsO6QafDf8Kz+AwaxPPf7ePrHYnoFDg8pVelD2O15OWRs349WcuXk7N+A2pREQ1+XoZjZCQARXFxKEYjBn9/Cg4dJn/fXgr27iV/7z5b69L5FKMRp+bNz6vfaYmxXj35xxeiDio8coSEocMoSUnB4OeHMTQUnasrOkdHFJMJnckJncmE4uyM6ZprrQmEwYBaVITi4IDi7ILOyfGfxMNwXuJx/ja9vtpeY1RV5fSbU8lYtAgAva8vHnfeif9zE+R1DumWEqVyNm/hxJNP2op8DUFBhH2+EIfQUAAOJFtXA/erovk5dM7OuPfqhXuvXpizs8ndstWW2ACc+XAmWb/+iql1a9xvvx23nj3wHjAAAHNmJvn79pO/r7R1J3qvddveveTv3UsGpf/83t5lurJMLVuid5OVsYWozTKXLyf5pZdR8/JwjGxE6KefYgwI0Dqsq6YoCgEvTETn5Eja3E8xp6aSvmABalEhAS+9hKKTeZQqSlpuaiG1pIS0Tz/lzAcfgsW6urTnA/0JnDSpTPb/9sqDfLT2mCZrSqmqyonHnyBn/Xo49yeo0+Hcvj3ut/fCrXv3MjU3qqpSnJBg7c7au4/8vXspOHgQiosvOLdDw4b/JDwtrsEhIhy9a+V0uwkhtJX+5Zecft06EMKhQQPCv/oSvaentkFVMlVVSf1oFqkzZ9q2edx7L0GvTq7T84jJaKlLqO3JTVF8PCcnPEf+3r2AtaA3+K23cLku6oJ9n126l6W7TvB0t8Y81S3ygp9Xh+LTKWSvXEnW8uXkR0fbtjs1b07E999d8lhLYSGFMTFlEp7iExcZnYW1edchPAyH8HAcw8NxCA/HISwMY/361v5xIYTdS5k+g7Q5cwDrnFoRP/5ga4mujVLnzuXMu+/Z7rv36UPwm29Yu8vqIOmWqoNUVSX1w5mkfvwxmM3oXF0JfOVl3Hv3Lrev9khKDgCRAdq1ahgD/PEe+AjeAx+h6EQSWb8tJ2v5b7j17Gnbx5Kby8mXXsL9tttwvflmdCYTADpHR0ytW2Nq3dq2b0lamjXZ2bePgr37KDh8GHNqKubUVPJTU8nfuatsAIqCMTjYmuzYvqxJkDE4uE5/ShLCnpx85RUyv7FOFqr39qbBz8sw+PhoHFXV8h0+HJ2jI6ffnApA1rJlqEVFhLw9DcVo1Dg6+yYtN7VAcUoKCUOGUnT0KACGkBDCF32OMTi43GO2x6bx8KfbKTJbWP30TUQG2Fedimo22xKLzF9+5eT48QAozs643Xor7rffjsuNndBVYPSUOTuborh4iuLjKYqLK/Nlyckp9zjFaMRYv36ZhMchzPrd4OcnBX5CVANVVTkxajQ5a9YAYKxXj4ifl6Ev/ZBTF2R8vYRTkycD1harBst/rRU1RpdLuqUuobYlNxnffc+pSZNsQ7wdGkRQf/78//zDn7TsLxZuiUcBDk3phYPBfgvViuLiOPvd92QtX15myKfO3R237t3wHTnyipqmVVXFnJ5+QcJTFBdHUXwCalFRucfqnJ0vaOk596WvBX9XQtgD1WLhxFNjyVm9GgDHpk0JX/oNujrYanH2hx9JfuEFUFU87upD0Bt1r3tKkptLqC3JjTk7mxNPjSVvyxbrBkXBZ+gQ/MaNq1BFfb9ZW9iVkIGvqwM7X+pexdFWDlVVKdi7l8zly8n+bQUlZ84A0OiP3zGGhABQkpGB3sPjqkcVqGYzJadOUWhLeP5p9SlOSrIVal+M3tu7TCuP7Susviw7IUQFqUVFnJz4Alm//gqAc4cO1P9sXp1uMc1avpykZyeA2Yxbz5543tsP53btbF31tZ0kN5dQG5Kb3O3bOfHkk1gyrUO59V5ehH7yMaZrr63wOdq+vpr03CKuC/di6ciOVRVqlVHNZvJ27iJ/7158Rwy3bU98bCQFhw5Zh6DffjtO17So9BdDS1ERxSdOWJOd2HMtPdbkp8zCohdhCA6yJT2O5yU+xpCQOvcpTIjymLOyOPH0OPI2bwaDgaA338SzT2+tw7ILWatXkzTuGetIUUXBFNWO+nPmoHNx0Tq0KifJzSXU5OTGUljImRkfkD5/vnX4tKLg2q0rIW+/fVktAoUlZpq+tAIVGNIpnFd6t6i6oKuRpbCQozffgjkjw7ZN5+ZmLbxTFFw7dyb4f1NtPzvaoweYLaAooFNQUKwzkSoKprZtCJ4yxbZv/CMDseTlle6rAwUUxbqvY5PGBJX2h5tzckkaM4aS1DNY8gtQCwuw5FvXsTnXdXhRioLO2Rmdi4t1IjI3N4whIQQ8NwGDv3+d/rQq6pbi06c53ucuLJmZ4OhI6MwPce3cWeuw7ErO+vUkjhpte00xtW5N6Kdza/2UFzJaqhbKj4khacxTFCcmAuB53314DxmCY0T4ZZ8rLjWPcxltq1DPSotRazpHRxqtW0vupk3W5R/WrsWSnW37uTknu8z+xSeSwGy+6LmMgYFl7hfExFyy+PgcvasLBUcOYz6TevHzhoXh+9hjtpaenDVrUIuLQVWti/Pl5trW5SrYu5fs5ctRTCZM116L5/33437H7ZLoiFqr8PhxYvvdi5qfD0Dgyy9JYnMRrl26UH/uJyQ8NhKKisiPjibh0UHU/2weeg8PrcOzC9JyY+dUs5kzMz+yzu2gqujc3Qn+3/9wu/WW/z64HD/vPcmTi/cA8NtTnWkWZP/Pw5Ww5OdTnJSEarFYnzsXVxzqhdh+nr9/P1gstp+jqqX3VfQe7jg1bWrbN3fLFutifOfvq6qoFgt6Dw9c2re37Zu1ejVqQYHt51jO7W9B5+GBe/d/apwyf/qJkswsLFlZlKSlYk5LoyQ9A3N6OuazZzFnZpZJwHwefxz/p8ZU8TMnRPXLj44m/pGB1mRfUQh8/TW87r1X67DsWt7OnSQMG259vQEcmzSh/oL5tXbRYemWuoSalNwUnThB4uNPUHTkiHWDouD/3AR8Bg26qvO+8esB5m6MBeDg6z1xMspcLvZKLS6m8Phx4h8dhOXsWQBCpr+P+3nzAAlR0+WsX0/i409YC/V1OurN/BC3W2/VOqwaIT86mvghQ23L7Dg0akj44sW1chmay3n/tt/xv3WYqqpkLFnCsZ69bImN3s+P8G+XXnViA9C5kS8A9bxMktjYOcVoxKlJE8K/WYJSWleV9Mx469ITQtQCZ3/4gcSRj1sTG4OBsC8WSWJzGUytWxO26HN0pclMSWoalktMY1FXSHJjZ0rS0kgYPIRTkybbisXc77yDRqtWYmpROYW/sWnWDL+2dkfVRo716xP25Reg14PZTNyDAyhOT9c6LCGuSvaaNSS//AqoKoqTExE//oBz27Zah1XjmFq0IOzLL9B5eWE5e5aERx+1TZVRV0lyY0ey16zheJ+7yPvzTwAUJydCPphByDvvVOo8BkdSrIW1kf61u7K+tjG1aEG9WR+BoqDm5xN3113yCU3UWGe//4ETT46BkhJMbdvScMVvODVqpHVYNZZT48aEf/kFBn9/io4eI+7hRzg58QWKSgeh1DWS3NgBc4517aQTT4zCnJaGQ2QkXgMfoeHKFbjfdlulXisxPY8Vf50CtF1TSlwZty5dCHj5JQBKzqRy4vEnrEXLQtQgSc89b51t12zGo29fwj5feMEIRXH5HBs0IOyLRRiCgyiOjyfzhx+IG/AQRXFxWodW7SS50Vje7t0c69mTzG+tK2B7Dx1CxHffEvjCC1WydsiB5CxSc6yf9iP9a1/BWV3gPWAA3o8+CjoduZs3c3rq/6hj4wJEDaWqKgnDhpP1008AeNx3H0F1eJXrquBQvz7hX3yBoXTWdvOZM8Q9OIDC0rUH6wpJbjSiFhVxetrbxA94CHOqdU4U19u6E/DssxVaDPJK7Ttx1na7oZ+03NRUAROft01ImLFoEakzP9I4IiEuzVJcTNx995G7aRMAplatCJo86aqXShEXMgYHE/7VVxjDwgAwZ2QQ99DDFBw6pHFk1Uf+qjRQcPgwx/reTfpnn9m2edzdl5D//a/Kr70vMdN6PZMBk4OMlKrJPPr0IeAlaxdV6kcfkTp7jsYRCXFx5vx8jt9xJwV//Q2Ay81dCPt6MYpeXoOqijHAn/CvvsShYUMALJmZxD/8MPl//61xZNVDkptqpFospH42n9i776H4+HEAFGdnQj6YQfDUqeicnas8hmOp1ll263vX/nVI6gKvhwZgCAoC4MyMGWR8s1TjiIQoq+TsWY51v43ihAQAPO65m/pz5shM29XA4OND2BeLcGzSBABLdg6Jw4ZjKSzUOLKqJ8lNNSk+eZKEwUM4M22abcZZU9s2NFz+a6UXDZfHYlFJybL+UTcPknqb2kBRFELnzIHSmoVTr7xC1spVGkclhFVJejqxfe6ydb37jBhO8JtvahxV3WLw8iJs0ec4XXMNYJ25vaAOtN5IclPFVFUl86efrEO8t20Dkwm9tzd+48YRtmhRtY4QOJmZT4nFWnjapn7tnJ67LnJq0piQ996z3U8aN46cTZs1jEgI6we6+AEPUZKSAgYD/s8/j/+4cVqHVSfp3d2pv2ABpnbtUAsKSBg2nNxt21Fr8VQSktxUoZKMDE6MeYqTzz2PJScHU+vWNPzxBxqtW4vviOHV3t+ckJ5nu91UJvCrVdxv647vqCesd8xmEkeNIm/3Hm2DEnVW/t69xD7wIEVxcRiCgoj46Sd8Bj2qdVh1mt7VhfqfzsWlYwfUvDwShg3jyC23krNxk9ahVQlJbqpIzoYNHLvjDnJWrwbAtWtXwr5YhENYWJWOhrqUFkH/rBbbSCbwq3V8R43C9dyCqoWFJIwYIcs0iGqXtWoVcQ8OwJySgkPDhoR/9SVODRtoHZYAdCYT9WbPxrVLFyguxpyWRuLjj5O9dq3WoVU6SW4qmSUvj5OTJpE44jEs6RkA6Fxd8eh7l+ZzORw9Y52ZONjDCVdHmVeitlF0OoKnvY1Dw4YoJhNqTg4JQ4fVyQm8hDbSv/6apDFPgcWC4uBAvY/nYCwteBf2QefoSL0PP8C1a1frhpISTox+kqxVtatWT5KbSpS/dy/H+9xF5pJvbNtMUVE0+HkZ7t27axiZ1ZHT1pFSjQKkmLi2Otf03HDFbzg2a4Y5LY34IUMoTk7WOjRRy52ZNYvTk18FrKNAGyxbhmO9ehpHJS5GcXCg3ozpuPXqZd1gNpM09mkyf/1V28AqkSQ3lST3z23WxQxPnLBu0Ovxe/ppwhYusItPLqqq8uEa6wyV9b0qb50qYX+MQUEYAwKo/+lcHMLDKTmZTMKQoZTIQpuiiiS/9hqpH3wIgN7Lk4arVuIQHqZxVOJSFIOBkHfexv3uu60bLBZOjn+Wsz/8qGlclUWSm0ri3K4tDuHhABhD6xH+9WJ8HxthN5NUnckuJOlsPgBNA6Xlpi7Qe3vjeou1BqcoNpbEYcMxZ2drHJWoTVRV5cRTT3H2q8UAGIKCaLh6NUZfX40jExWh6PUEvzEFjwf6WzeoKqmzZqGWTldSk0lyU0kUo5GIpd9Qb+aHRPzwI6Zrr9U6pDKOpuTYbjcLlpFSdYU5Pc16Q1EoOHCAxMcfx5Kfr21QolZQLRZOT51Kdum8So6NG9Nw5Qr0rjJYoSZRdDqCJk3Ca+BAAIoTE0lf+LnGUV09SW4qkc7FBbdu3dC72t/sv/uTMm23G/lJy01doCgKga++ap28S1VBpyN/5y5OPPVUrZ7fQlQ9tbiYk88/T8bniwDwfPBBIn78QbORoOLqKIpCwMTn8XnsMQBSpk0jdfZs8vfu1TiyKyfJTR2xJ/EsAM4OejycjdoGI6qNzsmJejM/RO/rCxaLdSXxDRs5+fzztaLpWVQ/c04Ox+/sTdayn0GvJ3jaWwRNekUWwKzhFEXB/+mx+I55EoAzMz4grv8DnJlTM9esk7/GOuLIaWutRYinFBPXNcbAQOp98AEYjbYEJ2v5b5ya/CqqqmodnqhBStLSONatO0Xx8aAohHz4AR59+mgdlqhEfk88gf+z4233U6fPIOWDD2rca4UkN3XEybMFADSRYuI6ybltGwJftq4gjqqConB26VJS3nmnxr1oCW0UxsVxtPttmM+eBcB39Cjcb71V26BElfAZOpSAF1+03U+bNZuUd9+tUa8VMpNbHZBbWIJFPbemlKe2wQjNeN1/P0XHjuPQqCGKopD80sukz/sMvbsHvo+N0Do8Ycfy//qL+AEP2Wq1AiZPwvuBBzSOSlQl70ceRnF04NQrkwBI/3QeakEhAS++UCNWdJfkpg5wcTTg7+5IYno+1wR7/PcBotYKmPi87bY5O4eUt97izPvvo3d3w+vBBzWMTNirnE2bSHxsJJjNoNMR8v77uPe4TeuwRDXwuv9+dI6OnHx+IqgqGV98gVpcTODkSXaf4Ei3VB2QV1TCiQzr8N9ImZ1YlPLoexemdm0BOPXa62T+/IvGEQl7k7dz5z+JjcFA/QULJLGpYzzuuouQ996F0oLx/OhoKC7WNqgKkOSmDjh+JhdVBR8XB7xdZKimANVsJmHgQPJ37caxWTNQVU4+/zzZa2rfAnriymSvXUvC0GFgNqNzdSXiu29xaX+d1mEJDbj36kW9Dz8Ag4HCQ4c48dRYLIWFWod1SZLc1AGv/PQXAAHujhpHIuyFotfj+/jjABTGxFhbcMxmksaOJXfbdo2jE1pL++ILTox+ErWwENebbyZy4wacmjTROiyhIbeuXQmdPQvF0ZGctWtJHPEYp995B9VOW3EkuakDDpUOAw/1dtY4EmFP3G+/HZ/hwwEo+OtvTNddh1pUxInHHyd//36NoxNaOfnCC6RMeQPMZjzu6kO9Dz9AZ5IpJAS4du5M6MdzwMmJvG3bSP90HidGP4nFDicFleSmlssuKCa30DpZW5tQL42jEfbGb+xTuHS5CbWwkOKEBExt22LJyyNx2HAKjxzROjxRjVRVJWHkSDK//wEAh4hwgqZORTHKpJ/iHy433EDYZ/NQHK09ATnr15M48nEsBQUaR1aWJDe13LEzubbbLevJSClRlqLXE/LOOzhERFBy+jSq2YzjNddgzswkYegwis6tci9qNdVsJq7/A+SuWw+AU4sWRCxbJrMOi4tybtuWsEWfozhbewPytmwhcfgILHl5Gkf2D/nLreUOnDxvTakAWdBOXEjv5ka9jz5C5+qKOSOD4NdfwzEykpKUFBIGD6E4JUXrEEUVMhcWcuyOOynYtw8Al06dCP92KTppsRGXYGrZkvAvv0BXulBq3o4dJAwZijkn9z+OrB6S3NRyuxPOAuCg1+HnKgXF4uIcG0QQ+sknRHyzBKdmzQid9ynG0FCKExNJHDrMNiutqF3MWVkc796d4rg4ANz79KH+vE/tfg4TYR+cmjUjfPFX6DysvQL50dEkPfOMxlFZSXJTy8UkZwEQ6OEoL1jikpzbtkHv6QmA0d+ferNnYfD3p/DIERJGPGY3n8hE5TBnZhI/dBglKWcA8B48mJBpb2kclahpHCMjCf96MXpvbwAKjxym+ORJjaOS5KbWM1usyy408pcuKVFxGV9/TeLQYQRPnYrew4OCffs4MXq03c9tISruzIwZFO7fj87Dg8AprxPw3AStQxI1lGNEBOFLvsYQHEzJyWTiH36EosRETWOS5KaWi/B1AaBjQ1+NIxE1hVpURMaSbyg5fZqUd98l5KOZ6JydyfvzT5LGPYNaUqJ1iOIqFaekcPa77wGoN/19vO69V+OIRE3nEBpK+JdfYAyrT/HJk8Q//AjFp09rFo8kN7XckZQcABrLsguighQHB0Jnfojey4uCAwc4u/hrQmbNQnFwIOePP0h+8UVUi0XrMMVVSBr3DGphIQ6NGuF8ww1ahyNqCWNQEGGLFuHQsCEuN1yPwc9Ps1gkuanFCovNxKVa6yQiZaSUuAzGkBBCZkwHg4GsX3+l8O+/CJk+HfR6Mn9axuk3p6KWrjQvapbi06fJ37kTAJcbO0ktnqhURn9/wr/8gqA33tB0KgHNk5tZs2YRERGBk5MT7dq1Y+PGjZfcv7CwkBdffJGwsDAcHR1p2LAhn332WTVFW7O89ssBSiwqDnodge5OWocjahiX9u0JeGEiACnvvItiNBD8v6mgKGR88QWpH36ocYTiSiS/8or1hsGAv52MbBG1i97TE8Vg0DQGTZObJUuWMHbsWF588UX27NlD586d6dWrFwkJCeUec//99/PHH38wb948Dh06xOLFi2natGk1Rl1zHDhpHSnl6+Ygn87EFfF68EE877sXVJWkcc/g3L49AS+/BEDqrNmkzV+gbYDispRkZZG7wfoB0qNPH5nLRtRamqZW7733HkOHDmXYsGEATJ8+nZUrVzJ79mymTp16wf4rVqxg/fr1HD9+HO/SYWfh4eHVGXKNEp9unS2yoa90SYkroygKAS+/TGFsLK43dcHg74/3gAFYsrI5M306KW+9hd7NFU8pSK0RTr36Gqgq6HQEvviC1uEIUWU0a7kpKipi165d3HbbbWW233bbbWzZsuWixyxbtoyoqCimTZtGSEgIjRs3Zvz48eTn55d7ncLCQrKyssp81QXFZgsZudbFzFqFyrIL4srpHBwIW7AA3xHDbS2APo+NwHvoEACSX5lE1oqVWoYoKsCSX0D2ihUAuHbrhs7FReOIhKg6mrXcpKamYjabCQgIKLM9ICCAU6dOXfSY48ePs2nTJpycnPjhhx9ITU3liSeeID09vdy6m6lTp/Lqq69Wevz2Lj4tl3Plnm3ry4KZ4uqc339uyc0lZ/16/MePx5KVzdmlS0l69ll0Li64dr5RwyjFpaS8/TaYzaAoBE2epHU4QlQpzQuK/10LoqpqufUhFosFRVH48ssvad++PbfffjvvvfceCxYsKLf1ZuLEiWRmZtq+EjWeWKi6HDqVbbsdKcPARSWx5OUR9+AAksY9Q/bKlQROnoT77b2guJgTTz5J3u7dWocoLkJVVfL27AHA9ZabMZR26wtRW2mW3Pj6+qLX6y9opUlJSbmgNeecoKAgQkJC8PD4p5ulWbNmqKrKiXJWL3Z0dMTd3b3MV12wMz4DAL2iEOJp0jgaUVvonJ1x6dgRgJMTX6DwyBGC//c/XG7qjFpQQOJjIymIidE4SvFveVu3UhgTg+LkRNCUKVqHI0SV0yy5cXBwoF27dqxevbrM9tWrV9Ox9MXz3zp16sTJkyfJycmxbTt8+DA6nY569epVabw1TYnZ2ikV4O6ITicjpUTl8R//DC4dO6Lm53Ni1GjMubnUmzEDU1Q7LNnZJAwdRmFsrNZhilKqxULq3LkAeN57r7TaiDpB026pcePG8emnn/LZZ58RExPD008/TUJCAiNHjgSsXUoDBw607T9gwAB8fHwYPHgwBw4cYMOGDTz77LMMGTIEk0laJ84X6GGd1+aGBj4aRyJqG8VgIOS9d62rhiclkTT2aRSDgdDZs3Fs3gxzejoJQ4baxeJ5AtI+m0/e1j9BUfAZPEjrcISoFpomN/3792f69Om89tprtG7dmg0bNrB8+XLCwsIASE5OLjPnjaurK6tXr+bs2bNERUXx0EMP0bt3bz744AOtHoLdOnLaWnPTSGYmFlVA7+lJ6KyPrGtObdvG6Wlvo3dzo/6nn+IQEUFJcjIJQ4ZSkpamdah1mqqqpH38MWBdvdkYEqJxREJUD0WtY3OoZ2Vl4eHhQWZmZq2tvykqsXDXR5uISc5m7sAouje/eA2TEFcr+/ffOTH6SfR+vjT46ScM3t4UJycT99BDlJxMxrFZM8IWLkBfS//X7F3Gkm84Nck6Mqr+F4twiYrSOCIhrtzlvH9rPlpKVL71h1OISba23ET6S8uNqDpu3boR9MYbRHz7ra2WwxgURNhnn6H38aEwJobEkY9jucRcVKJqqKrKmRkzADCGhkpiI+oUSW5qoV1x1pFSOgVCvZ01jkbUdp797sF43ghHVVVxCA+n/rxP0bm5kb97NyfGPIVaVKRhlHVP1oqVmNPTAQiY+LzG0QhRvSS5qYX2J2UC4O3iiF5GSolqlLViBQmDBmMpLMSpaVNCP/4YxWQid+NGkiY8h2o2ax1inZEybRoAej8/3G69VeNohKhektzUQsdTcwEI95FWG1F9zNnZnJr8KnnbtnFq0mRUVcW5bRvqzfwQjEayV6wgedIk6liZnybyduykJDkZAL+nx2objBAauKLkZuPGjTz88MN06NCBpKQkABYtWsSmTZsqNThx+VRV5Ux2IQDXBEsRp6g+ejc3Qt57F3Q6Mn/8kYxFiwBw7dSJkHfesW7/9jvOLlmicaS1X96uXYC11cbz7rs1jkaI6nfZyc13331Hjx49MJlM7Nmzh8JC6xtpdnY2b775ZqUHKC7PqawCSizWT8ZR4bKmlKheLh07EvDcBABOvzWN3K1bAXDvcRv+zz4LwJkZH2CuIwvYasFSUED6558DEPDs+HKXsxGiNrvs5GbKlCnMmTOHuXPnYjQabds7duzIbllXRnOHz1tTqmmQrAYuqp/XwIF49O0LZjNJY5+mqHQ9N++HH8KhYUPMGRmkzp6jbZC1WMbXX2NOT8cYHIx7r15ahyOEJi47uTl06BA33XTTBdvd3d05e/ZsZcQkrkJxaauNToEwqbkRGlAUhcBXJ+N07bWYMzM58cQoLLm5KEYjAc8/B0D6F19QFBenbaC1UMHBg6S8ZS0k9ho8GOW8D6BC1CWXndwEBQVx9OjRC7Zv2rSJBg0aVEpQ4soZSkdHNfJ3xaiXenGhDZ2jI/VmfojezxeXG29EcXQEwLVzZ1xu6gzFxZye9rbGUdY+p157HVQVjEa87u2ndThCaOay3/0ee+wxnnrqKbZt24aiKJw8eZIvv/yS8ePH88QTT1RFjOIyHE2xLioa6e+mcSSirjMGBNBg2TICnpuAYjDYtgc89xzo9eSsWUPuli0aRli7FMbHk19aGuB5bz90st6eqMMM/71LWRMmTCAzM5NbbrmFgoICbrrpJhwdHRk/fjyjR4+uihhFBamqyq546wR+jWRmYmEHDF7/FLWrRUUUHDmCqUULvAYMIGPRIk5P/R8RP3xfJvkRV+b061OsN3Q6/MeO1TQWIbR2WS03ZrOZ9evX88wzz5Camsr27dv5888/OXPmDK+//npVxSgqKC23iN/+OgVAuK/U2wj7Yc7MJH7QYBIeGUjh8Vj8Rj2BzsODwiNHOPvtd1qHV+MVnzxJ7ubNALj17IneQwYTiLrtspIbvV5Pjx49yMzMxNnZmaioKNq3b4+rq7QS2INzK4EDNJeRUsKO6JydUfR6LHl5JL/4Ijo3N/xKW3rPzJiBOTv7P84gLuX0/96y1tooCgETntU6HCE0d9k1N9deey3Hjx+viljEVdqTcNZ2W1puhD1RjEaC3/ofOmdn8vfsIeOrxXg90B+HBg1kaPhVsuTlkf3HHwC43NgJY2CgxhEJob3LTm7eeOMNxo8fzy+//EJycjJZWVllvoR29iSeBcDDZMTRoNc2GCH+xRgcjP+z4wFIef99ik+n/DM0fNEiiuLjtQyvxio+eRJK1+zyf14WyBQCriC56dmzJ3v37qVPnz7Uq1cPLy8vvLy88PT0xMtLZsTV0rmRUqFeMkpC2CfP/v1xjopCzcvj1Cuv4NK5My6dS4eGvy1Dw69E2qfzAHDr3h2nhg01jkYI+3DZQxTWrl1bFXGISnAqswCAJoEyDFzYJ0WnI/D114jteze5W7aQ+f0PBDw3geNbtpDz+x/k/vknLjfcoHWYNUZBTAyZv/wCgM/wYRpHI4T9uOzkpkuXLlURh7hKmfnF5Bdbm6avC/fWOBohyucYEYHfk6PJWrkKp2uuwbFRI7weeICML7+0Dg3//jsUvXSr/hdzdjZx/R+AkhJM7dphatlS65CEsBtXNLnE2bNnmTdvHjExMSiKQvPmzRkyZAgeMvxQMxaLBSejjoJiC9eEyO9B2DfvQYPwHjTINr+N7+hRZP78M4WHDnH2u+/wuv9+jSO0f2nzPkMtKgLA57HHNI5GCPty2TU3O3fupGHDhrz//vukp6eTmprKe++9R8OGDWXhTA2ZVSgotqAo0NBPhuYL+6YYDGUm7tM5OuI3ehQAZ6bL0PD/YsnLI33BAgAMwcG4dr5R24CEsDOXndw8/fTT9OnTh7i4OL7//nt++OEHYmNjufPOOxkrs2Jq5sjpc8XEzpgcpElf1AyWwkJS3n2PY71ux/3223GIiMCcnk7axx9rHZpdS//yK9QCa42d/7inURRF44iEsC9X1HLz3HPPYTjvU5fBYGDChAns3LmzUoMTFbfu0GkAGvm5aByJEJdBUcheu4aS06dJeedd/J+bAED6ws8pSkjQODj7ZCkstCV/em9v3Hv10jgiIezPZSc37u7uJFzkRScxMRE3Nxmlo5Uvt1l/Jy5OskaPqDl0Dg4ET5kCikLmjz+CTodLp06oxcWkvP2O1uHZpbNLl2LJsbbU+o4aJcXXQlzEZSc3/fv3Z+jQoSxZsoTExEROnDjB119/zbBhw3jwwQerIkbxH/KKSsgptI6UigqTkVKiZjG1bo33wEcAODV5Mn5jngSdjuzVq8ndtl3j6OxP+sLPAVBcXPC8t5/G0Qhhny77Y/4777yDoigMHDiQkpISAIxGI48//jj/+9//Kj1A8d+OpeTabrcO9dQuECGukN9TT5H9+x8UJyWRuexnvB7oT8ZXizn9v/8R8e1SaZ0opVosYLS+bPsMHYLO0VHjiISwT5fdcuPg4MCMGTPIyMggOjqaPXv2kJ6ezvvvv4+j/KNpYm/psgsADf1lpJSoeXTOzgS9/hoAGV9+ictNN6Fzc6MwJobMH37QODr7kbNuHcXHY9G5uuL9yCNahyOE3brs5CYzM5P09HScnZ259tpradmyJc7OzqSnp8vaUhrZlZABgIuDHldHqbkRNZNLx4543NsPnbMzltxcfEc9AUDK+9Mxl9aY1GVFycmkzrEWEns9+CB6qXEUolyXndw88MADfP311xds/+abb3jggQcqJShxeQ6ess4JEuQha0qJmi1gwgQa/LwMjzvuwHvAABzCwjCnpdX5oeGqxULCIwMp2LcPDAZbjZIQ4uIuO7nZtm0bt9xyywXbb775ZrZt21YpQYnLk5SRB0BkgHRJiZpN7+6OMSQEAMXBAf/nSlcNX7CQosRELUPTVM7atRSfOAGAe+/eGPz8NI5ICPt22clNYWGhrZD4fMXFxeTn51dKUOLyBHtaW2yiwmVVdlF75G7dytnvv8f5huvr9NBwVVVJeX+67b7fSFlqQYj/ctnJzXXXXccnn3xywfY5c+bQrl27SglKXJ6zecUAtA6V5EbUDpbcXJKeHkfO77/jGNnYOjR81Spyt9e9oeG5mzZTdPQoAK5db8UhLEzjiISwf5ddffrGG2/QrVs39u7dS9euXQH4448/2LFjB6tWrar0AMWlZRUUcyrLOg17IxkpJWoJnYsLAS9M5OSE5zi7ZAluPXuQvfw369DwpXVraPiZGTNst/1GjdIwEiFqjstuuenUqRNbt24lNDSUb775hp9//plGjRqxb98+OnfuXBUxikv4dV8yAH6uDniYjBpHI0Tlce/dG5ebOqMWFVGceALFxYXCAzHWmYzriLwdOyj46y8ATNddh1Pz5hpHJETNcEXjhlu3bs2XX35Z2bGIK7D43LILMgRc1DKKohA0eTLH7+xNwf79uHbrRs7vv5Py/nTcevRE71r711HLXPaz7bbf6NEaRiJEzXLZLTe7d+9m//79tvs//fQTffv25YUXXqCoqKhSgxP/LbF0pJR0SYnayBgcjP+z4wHI3bwZQ0gw5tRU0i5S91cb6bysdXSOTZvi3P46jaMRoua47OTmscce4/DhwwAcP36c/v374+zszNKlS5kwYUKlByjKV2K2nFdM7KltMEJUEc/+/TFFtUPNz8e5rXXQQvqCBRSVDo2urcw5OZxdvBgA31FPoCiKxhEJUXNcdnJz+PBhWrduDcDSpUvp0qULX331FQsWLOC7776r7PjEJSSk56GW3o4KlwUzRe2k6HQEvf46Ie+/R9Bb/8O5ww2oRUWkvPOu1qFVmeLTp0lf+DmW7GwcIiJwKx28IYSomMtOblRVxWKxAPD7779z++23AxAaGkpqamrlRicu6a+kTNvtJgEyFbuovRwjInDv1QudTkfA889bh4avWEHezp1ah1YlTr/5JqkzZwLgM2wYiu6yX6qFqNMu+z8mKiqKKVOmsGjRItavX88dd9wBQGxsLAEBAZUeoCjfjjjrmlKOBh1eLg4aRyNE9TD4+2Nq1QqA029Ota6UXYsUHj9O9qrVoKrovb3x6H2n1iEJUeNcdnIzffp0du/ezejRo3nxxRdp1KgRAN9++y0dO3as9ABF+Q6ctC5U6u8mq7GLusGSn0/sXX3J37MHxcmJggMHyPzxJ63DqlSpH38CqrXD2WfEcBQH+eAixOW67PHDLVu2LDNa6py3334bfR2aWMseNPBzYVdCBq2kmFjUETqTCY977iZtzscoOh0qkPL+e7j3uA2dS80fGl504gRZP1uHfysuLnjdd5/GEQlRM1VaR66TkxNGo0wiV50y8qxD79tHSDGxqDt8n3gChwYNsOTlobi4YD6TSurcuVqHVSnS5s6F0m42n0cH1oqETQgtSJVaDXYkJQeQOW5E3aJzcCDojSmgKKi5uQCkfzaf4qQkjSO7OsWnT3P2u++tdxwc8Hr4YW0DEqIGk+Smhtp/4izxadYJ/CL9ZaSUqFuc27TB6xHrm7/i4GAdGv5uzR4anrd9O5SUAOB1//0YvKVFVogrJclNDfVjtPVTqlGv4OsqBYei7vF/6imMISGopTOjZy3/jbxduzSO6so5hEdYb+h0+AwepGksQtR0ktzUUH+XjpTyc3WUmUtFnaRzcSHo9dfwvO9e3O+6C6jZQ8PTPv0UAI/ed2IMCdE4GiFqtkpLbhITExkyZEhlnU78h7hUa5dUuK8UHIq6y6VjR4Jef52AZ8ejc3Gh4O+/yfxpmdZhXRZzVhbZ69aTvWoVAN5Dh2ockRA1X6UlN+np6SxcuLCyTicuQVVVUnMKAbg2xEPjaITQnsHXF5+RjwFw5r33sJQWGtcE6YsWcWLkSFBVXG++GafGjbUOSYgar8Lz3CxbdulPQ8ePH7/qYETFnMkupMRineTr+gZSdCiEpaCA3K1/AlBy5gypn36K/1NPaRzVfzPn5JK+4J8PhT4jhmsYjRC1R4WTm759+6IoCqqqlruP1H5UjwPJWbbbzYOk5UYInZMTend32/20eZ/hde+9dl+7cvbrxViyswFwatsW57ZtNY5IiNqhwt1SQUFBfPfdd1gslot+7d69uyrjFOfZHpsOgEGnEOAuSy8IARD40ovoPEqT/aIiUt59T9uA/oOloIC0eZ/Z7vtKq40QlabCyU27du0umcD8V6uOqDwRpUXEDfxcpLVMiFIGX18CX5hou5+1fDl5u/doGNGlnV36LeYM6+K3Do0a4dqli8YRCVF7VDi5efbZZy+5MGajRo1Yu3ZtpQQlLu1ERj4ArWVNKSHKcO/TB5fOnW33T735pl0ODbcUFdmGfoO11UY+qAhReSqU3Ozbt49OnTrRs2fPcvdxcXGhi3zyqBZHS5ddkJmJhShLURSCXp2MYjIBUPjXX7aFKO1J0bFjmEtrbQxBQbj36qVxRELULhVKbtq0aUNqaioADRo0IC0trUqDEuXLzCtmyzHr76Khv8xxI8S/GYOD8X92PHovLwBS3n0PS16exlGV5RgZid7TEwCfoUNRZNFhISpVhZIbT09PYmNjAYiLi8Nih828dcWB5Ewy8ooBaBwgLTdCXIzXAw/QYOUKjCEhlKSkkPbpPK1DKiNrxUpKTp5E7+WFZ797tA5HiFqnQkPB+/XrR5cuXQgKCkJRFKKiotDr9RfdV+a7qVrbSkdK6RQI9jBpHI0Q9knR6TC4u+P/7LMkjR1L6qef4nlvP4zBwZrGpVos5GzaROonnwDgPfARdCb5PxaislUoufnkk0+45557OHr0KGPGjGH48OG4uUmrgRb2ncgEwNvFAZ1OChCFuBTXbl0x1Auh5EQSp96cSujMDzWNJ3vVapLGjgVAMZnwGjBA03iEqK0qPInfuWLiXbt28dRTT0lyo5FjZ6zFxKHezhpHIoT9UwCdg3UuqJzffydvzx6c27TRJBZVVUmdM8d236t/f/QeMgmnEFXhsteWmj9/viQ2GjqdVQBA8yD3/9hTCKEYDIS89y6UDrM++fxEzYaG56xbR+HBg9Y7BgPegx7VJA4h6oJKWzhTVL3sgmIKiq0vzO3DZU0pISrCqWlTvB5+GIDi+HjOLl1a7TH8u9XG464+GAMDqz0OIeoKSW5qkHPz2wC0ru+pXSBC1DD+z45H7239QHB66v+qfWh43p9/UrB3n+2+z9Ch1Xp9IeoaSW5qEE+TdS4Mo16hnpfU3AhRUToHB0Let641pRYUkDxpcrVeP3X2P602bt2749igQbVeX4i6RvPkZtasWURERODk5ES7du3YuHFjhY7bvHkzBoOB1q1bV22AduTomVzAOjOxXkZKCXFZXK6/HpebrEszZP32G8XJydVyXXN2NiXp6bb7PsOHVct1hajLNE1ulixZwtixY3nxxRfZs2cPnTt3plevXiQkJFzyuMzMTAYOHEjXrl2rKVL7cCTFOl17ZICrxpEIUTOFvPcejs2bQ0kJKe+9Xy3X1Lu54dzhBgCcr78eU8uW1XJdIeoyTZOb9957j6FDhzJs2DCaNWvG9OnTCQ0NZfbs2Zc87rHHHmPAgAF06NChmiK1D9/sSAQg2MNJ40iEqJn0rq4EvfYaKApZP/9MfnR0lV+zJCODzG+/A8Bn+PAqv54QQsPkpqioiF27dnHbbbeV2X7bbbexZcuWco+bP38+x44dY9KkSRW6TmFhIVlZWWW+aqKCYjNxadYiyAhfabkR4kqZrmmBR9++ACQ8NhJzQUGVXStr1SrS5i9Azc/HsXkzXDp1rLJrCSH+oVlyk5qaitlsJiAgoMz2gIAATp06ddFjjhw5wvPPP8+XX36JwVCx+QenTp2Kh4eH7Ss0NPSqY9fC0dP/jJRqG+apXSBC1AK+o0aBomDJzOTkuGeq5BoFhw+TNOYp0ufOtV5z+HAURWrlhKgOmhcU//ufXVXVi74AmM1mBgwYwKuvvkrjxo0rfP6JEyeSmZlp+0pMTLzqmLWwI85akKgA4T6yGrgQV8OhXgjud9wOQM6aNeTt2VPp10j7xJrUoKoY69fH7V+t1EKIqlPh5Rcqm6+vL3q9/oJWmpSUlAtacwCys7PZuXMne/bsYfTo0QBYLBZUVcVgMLBq1SpuvfXWC45zdHTE0dGxah5ENdqdmAGAu8mIQa95TipEjRc0ZQrZv/+BWlDAiSfHELl2DYrRWCnnLoqLI2v5ctt9nyFDUMpZbFgIUfk0e5d0cHCgXbt2rF69usz21atX07Hjhf3S7u7u7N+/n+joaNvXyJEjadKkCdHR0Vx//fXVFbomjpR2S4V4ygrCQlQGnZMTAROfB8CcmsqZDypvUc3UuXOhdJkHva8vHnf3rbRzCyH+m2YtNwDjxo3jkUceISoqig4dOvDJJ5+QkJDAyJEjAWuXUlJSEp9//jk6nY5rrrmmzPH+/v44OTldsL02Onk2H4DGgVJMLERl8bz/ftI+m09xfDxp8+bhcffdODaIuKpzFiclkfnTMtt970cHoqsFrcdC1CSa9m/079+f6dOn89prr9G6dWs2bNjA8uXLCQsLAyA5Ofk/57ypC8wWldxCMwBR9WVNKSEqi6IoBL89zXrHYuHMzKtvvUmb9xmUlACgc3XF64EHrvqcQojLo3nxxhNPPEFcXByFhYXs2rWLm266yfazBQsWsG7dunKPnTx5MtHVME+F1nQKmIzWX9V1EV4aRyNE7eLcsiVu3bsDUJx0ElVVr/hcqqpiyf9n3SqvBx9E7+Z21TEKIS6P5smN+G+nswrJKTKj1ykyx40QVSDgpRdRTCYK9u4tUwh8uRRFwfOee6x3jEa8Bz5SSREKIS6HJDc1wLllF8J9nHEwyK9MiMpmDAiwrfl0etrbpC38/IpbcFJL57XxvOceDH5+lRajEKLi5J2yBpiz/hgAvi5SlChEVfEZPBh9YCDm06dJmTqVzB9/uqzjs3//ney1a8ndsBF0OnyGDK6iSIUQ/0WSmxrg75PWJSP83CW5EaKq6EwmAsaPt90//eablJw5U6FjzVlZnHx+IicefwIA9549cCgdGCGEqH6S3Ng5s0UlM78YgNahntoGI0Qt537H7TiVrtptyc7m1OtTKnRcxldfYcn5Z4kUn2HDqiQ+IUTFSHJj5xLTcznX9X99hI+2wQhRyymKQuCLL9juZ69aRdbKVZc8xpKbS/qChbb7LjfeiFPz5lUWoxDiv0lyY+d2J5y13Y4MkJFSQlQ1U6tWuPfpbbt/6vXXMGdmlrt/xjdLMZ89C6Vr4vkMH17VIQoh/oMkN3bu3IKZLg56nIyyNo0Q1cF/3DgonVXYnJpGyvTpF93PUlhI2mfzrHdUFaeWLXFuf101RSmEKI8kN3YuJtk6DDzA3UnjSISoO4yBgfiWtsAoTk74DL74yKez332H+Uzqea02w1BKbwshtCPJjZ07m1cEQCN/6ZISojr5DB2CITAQtaCg/In9VBXF0RFUFYeICNy6dq3eIIUQFyXJjZ0L9LC22HRr5q9xJELULTqTCf9nngEg9ZO5FJ9OofDo0TL7eN53HzpX6wcPn2HDUHTykiqEPZD/RDt3NMU6vLRZkIfGkQhR97jfeQemVq1Q8/KIf+ghjvfuQ97u3bafZ/70E+a0NAwBAXj0vlPDSIUQ55Pkxo6l5xaRmmPtlmro76JxNELUPYqiEDDxeQCKT5wAVSX5xZfIXruW7HXrSZv7KQDegwehODhoGaoQ4jwGrQMQ5Zu9zrrsgofJiLOD/KqE0IKpdWvce/cm6+efwWCgKDaWE0+OgZISAHQeHnjdd5/GUQohzictN3YsOjEDAE+TUeNIhKjb/Mc9jeLkZEtoKCmB0voa74cGoHORllUh7IkkN3YsPi0PgIYyUkoITRmDgvAZOhSwDg0HwGJBcXLC6+GHNYxMCHExktzYKVVVSc+11tu0rCfFxEJozWfoEAwBAagFBbYJ/jzvvReDt7fGkQkh/k2SGzuVlltEicW6qNQNDeTFUwit6Zyd8X9mnPVOYSHo9fgMHqRpTEKIi5Pkxk5FJ5613W4RLC03QtgD9zvvtK0a7nHnHRhDQjSOSAhxMTIEx05tO25dU8rRoMPNSQqKhbAHik5HyHvvcXbJEryl1UYIuyXJjZ1Kyy0EwN/NUeNIhBDnc6gX8k/3lBDCLkm3lJ3ydrZOCNatWYDGkQghhBA1iyQ3dupI6bILjQPdNI5ECCGEqFkkubFDFovKkdPZAETKHDdCCCHEZZHkxg5tOZ7GycwCABpJciOEEEJcFklu7NCfx9IAMOoVPJ1lMT4hhBDickhyY4f2J2UC4OsqI6WEEEKIyyXJjR06nmotJg7zcdY4EiGEEKLmkeTGDp3Jts5xIzMTCyGEEJdPkhs7k1dUQkGxBYDrZU0pIYQQ4rJJcmNnDpzMst1uV99Lw0iEEEKImkmSGztzIiMfAAe9Dh8pKBZCCCEumyQ3dqp1fU+tQxBCCCFqJElu7MyRFJmZWAghhLgaktzYmXM1N5LcCCGEEFdGkhs7UlhiZu2hMwAEejhpHI0QQghRM0lyY0cOly6WCdAm1FO7QIQQQogaTJIbO7K1dE0pvQL+7tJyI4QQQlwJSW7syJ6EswB4OjugKIq2wQghhBA1lCQ3duRoinVNqVAvk8aRCCGEEDWXJDd2JDmzAICmQe4aRyKEEELUXJLc2IkSs4XcwhIAosJlTSkhhBDiSklyYyeySxMbgBtkwUwhhBDiiklyYyfScgpRARcHPSGeUnMjhBBCXClJbuzEkdPWYuJGAW4yUkoIIYS4CgatAxBWO+LSAVl2QYjazmw2U1xcrHUYQtglBwcHdLqrb3eR5MZOfLc7CQBpsxGidlJVlVOnTnH27FmtQxHCbul0OiIiInBwcLiq80hyYwcsFpWsAusnudb1PbUNRghRJc4lNv7+/jg7O0v3sxD/YrFYOHnyJMnJydSvX/+q/kckubEDCem5qKr1dseGPtoGI4SodGaz2ZbY+PjI/7gQ5fHz8+PkyZOUlJRgNBqv+DxSUGwH/jxurbdRgDBvF22DEUJUunM1Ns7OzhpHIoR9O9cdZTabr+o8ktzYgZ3xGQC4mQzodNJULURtJV1RQlxaZf2PSHJjBw6dygYg2EPmtxFCCCGuliQ3diDpbD4gw8CFEPZHVVVGjBiBt7c3iqIQHR2tdUgADBo0iL59+2odRo0VHh7O9OnTtQ6jykhyYwecjNZfw/URsuyCEMK+rFixggULFvDLL7+QnJzMNddcw4YNG+jduzfBwcEoisKPP/74n+eZPHkyrVu3rrS4ZsyYwYIFCyrtfKJ2keRGYxaLSnpuEQCdIv00jkYIIco6duwYQUFBdOzYkcDAQAwGA7m5ubRq1YqZM2dW+vUqOsGhh4cHnp6elX79qmI2m7FYLFV+naKioiq/Rk0gyY3Gks7mU1BswcGgI9RLam6EEPZj0KBBPPnkkyQkJKAoCuHh4QD06tWLKVOmcM8991ToPAsWLODVV19l7969KIqCoii2VhdFUZgzZw533XUXLi4uTJkyBbPZzNChQ4mIiMBkMtGkSRNmzJhxQWznd0vdfPPNjBkzhgkTJuDt7U1gYCCTJ0++ZFzr1q2jffv2uLi44OnpSadOnYiPj7f9fNmyZURFReHk5ISvr2+Zx5uRkcHAgQPx8vLC2dmZXr16ceTIkTKP2dPTk19++YXmzZvj6OhIfHw8RUVFTJgwgZCQEFxcXLj++utZt26d7bj4+Hh69+6Nl5cXLi4utGjRguXLl5f7GMLDw5kyZQqDBg3Cw8OD4cOHA7BlyxZuuukmTCYToaGhjBkzhtzc3IueIy4u7oIux7Nnz6IoSpnYahKZ50ZjG4+cASDcxxmDXnJNIeoKVVVR8/M1ubZiMlVoVMqMGTNo2LAhn3zyCTt27ECv11/R9fr3789ff/3FihUr+P333wFry8s5kyZNYurUqbz//vvo9XosFgv16tXjm2++wdfXly1btjBixAiCgoK4//77y73OwoULGTduHNu2bWPr1q0MGjSITp060b179wv2LSkpoW/fvgwfPpzFixdTVFTE9u3bbc/Lr7/+yj333MOLL77IokWLKCoq4tdff7UdP2jQII4cOcKyZctwd3fnueee4/bbb+fAgQO2+Vny8vKYOnUqn376KT4+Pvj7+zN48GDi4uL4+uuvCQ4O5ocffqBnz57s37+fyMhIRo0aRVFRERs2bMDFxYUDBw7g6nrpesy3336bl19+mZdeegmA/fv306NHD15//XXmzZvHmTNnGD16NKNHj2b+/PkV/K3VbJLcaGzprhMAWFSNAxFCVCs1P59Dbdtpcu0mu3ehVGDOHQ8PD9zc3NDr9QQGBl7x9UwmE66urhgMhoueZ8CAAQwZMqTMtldffdV2OyIigi1btvDNN99cMrlp2bIlkyZNAiAyMpKZM2fyxx9/XDS5ycrKIjMzkzvvvJOGDRsC0KxZM9vP33jjDR544IEycbRq1QrAltRs3ryZjh07AvDll18SGhrKjz/+yH333QdYu9hmzZplO+7YsWMsXryYEydOEBwcDMD48eNZsWIF8+fP58033yQhIYF+/fpx7bXXAtCgQYNyH+85t956K+PHj7fdHzhwIAMGDGDs2LG25+KDDz6gS5cuzJ49Gycnp/88Z00nyY3GTqRbP7k18pORUkKIuikqKuqCbXPmzOHTTz8lPj6e/Px8ioqK/rMguWXLlmXuBwUFkZKSctF9vb29GTRoED169KB79+5069aN+++/n6CgIACio6NtXTz/FhMTg8Fg4Prrr7dt8/HxoUmTJsTExNi2OTg4lIlp9+7dqKpK48aNy5yvsLDQNnP1mDFjePzxx1m1ahXdunWjX79+Fzyuf/v387dr1y6OHj3Kl19+adumqioWi4XY2NgySVxtJcmNxjLyrMVfrUM9tQ1ECFGtFJOJJrt3aXZte+LiUnZm9m+++Yann36ad999lw4dOuDm5sbbb7/Ntm3bLnmef0/XryjKJYt458+fz5gxY1ixYgVLlizhpZdeYvXq1dxwww2YLvEcqerFm9pVVS3T3Wf6V/efxWJBr9eza9euC7r4znU9DRs2jB49evDrr7+yatUqpk6dyrvvvsuTTz5Zbjz/fv4sFguPPfYYY8aMuWDf+vXrX7Dt3Crc5z+umr5yvSQ3GkrPKaSktD+qU6SsNyNEXaIoSoW6hmoLBweHCk+pv3HjRjp27MgTTzxh23bs2LEqiatNmza0adOGiRMn0qFDB7766ituuOEGWrZsyR9//MHgwYMvOKZ58+aUlJSwbds2W7dUWloahw8fvmSrSJs2bTCbzaSkpNC5c+dy9wsNDWXkyJGMHDmSiRMnMnfu3EsmN//Wtm1b/v77bxo1alSh/f38rCN1k5OTadOmDYDdzGd0paSCVUPbYtNtt5sGumsYiRBCVFxOTg7R0dG2N8DY2Fiio6NJSEgo95jw8HDbfqmpqRQWFpa7b6NGjdi5cycrV67k8OHDvPzyy+zYsaNSH0NsbCwTJ05k69atxMfHs2rVqjLJyaRJk1i8eDGTJk0iJiaG/fv3M23aNMBaw3LXXXcxfPhwNm3axN69e3n44YcJCQnhrrvuKveajRs35qGHHmLgwIF8//33xMbGsmPHDt566y3biKixY8eycuVKYmNj2b17N2vWrLnsbqTnnnuOrVu3MmrUKKKjo201QuUlSCaTiRtuuIH//e9/HDhwgA0bNtiKk2sqSW40dC65cXbQY5SRUkKIGmLnzp22Fg+AcePG0aZNG1555ZVyj+nXrx89e/bklltuwc/Pj8WLF5e778iRI7nnnnvo378/119/PWlpaWVacSqDs7MzBw8epF+/fjRu3JgRI0YwevRoHnvsMcA6tHzp0qUsW7aM1q1bc+utt5bpFps/fz7t2rXjzjvvpEOHDqiqyvLly/9zJev58+czcOBAnnnmGZo0aUKfPn3Ytm0boaGhgHU+nFGjRtGsWTN69uxJkyZNmDVr1mU9tpYtW7J+/XqOHDlC586dadOmDS+//LKtnuhiPvvsM4qLi4mKiuKpp55iypQpl3VNe6Oo5XUeVpNZs2bx9ttvk5ycTIsWLZg+fXq5zXXff/89s2fPJjo6msLCQlq0aMHkyZPp0aNHha+XlZWFh4cHmZmZuLtr21py/5wtbI/LIMLXmbXjb9E0FiFE1SkoKCA2NpaIiIg6MVJFiCt1qf+Vy3n/1rS5YMmSJYwdO5YXX3yRPXv20LlzZ3r16lVu0+aGDRvo3r07y5cvZ9euXdxyyy307t2bPXv2VHPklcPDZM3w29aXZReEEEKIyqJpcvPee+8xdOhQhg0bRrNmzZg+fTqhoaHMnj37ovtPnz6dCRMmcN111xEZGcmbb75JZGQkP//8czVHXjnS86zV6Dc3kWUXhBBCiMqiWXJTVFTErl27uO2228psv+2229iyZUuFzmGxWMjOzsbbu/yWj8LCQrKyssp82QNVVTlyOhuAyACZ40YIIYSoLJolN6mpqZjNZgICAspsDwgI4NSpUxU6x7vvvktubu4lZ6ycOnUqHh4etq9zRVta+yspk6yCEhQgwtflP/cXQgghRMVoPkTn3+ub/HsSpPIsXryYyZMns2TJEvz9/cvdb+LEiWRmZtq+EhMTrzrmyvDzvmQAHI06HA1Xtl6LEEIIIS6k2SR+vr6+6PX6C1ppUlJSLmjN+bclS5YwdOhQli5dSrdu3S65r6OjI46Ojlcdb2X7KykTAD9X+4tNCCGEqMk0a7lxcHCgXbt2rF69usz21atX22Z8vJjFixczaNAgvvrqK+64446qDrPKxKdZl56P8JMuKSGEEKIyabr8wrhx43jkkUeIioqiQ4cOfPLJJyQkJDBy5EjA2qWUlJTE559/DlgTm4EDBzJjxgxuuOEGW6uPyWTCw8NDs8dxJVJzrGtKXRtSs+IWQggh7J2myU3//v1JS0vjtddeIzk5mWuuuYbly5cTFhYGWNe5OH/Om48//piSkhJGjRrFqFGjbNsfffRRFixYUN3hX7GCYjOFJdbF3Do0kDWlhBBCiMqk+cKZTzzxRLnTav87YVm3bl3VB1QNdsdn2G63re+lYSRCCHFpqqry2GOP8e2335KRkcGePXto3bq11mGJCrr55ptp3bo106dP1zqUaqX5aKm6aOvxNAAcDTqcHTXPL4UQolwrVqxgwYIF/PLLL7YW9g0bNtC7d2+Cg4NRFIUff/zxP88zefLkSk+KFixYgKenZ6WeU9QOktxowNnBmtA0DXTTOBIhhLi0Y8eOERQURMeOHQkMDMRgMJCbm0urVq2YOXOm1uHZHVVVKSkpqfLrFBUVVfk1ajJJbjRwKjMfgBsaSr2NEHWdJS+v/K/CworvW1BQoX0vx6BBg3jyySdJSEhAURTCw8MB6NWrF1OmTOGee+6p0HkWLFjAq6++yt69e1EUBUVRbGUHmZmZjBgxAn9/f9zd3bn11lvZu3ev7di9e/dyyy234Obmhru7O+3atWPnzp2sW7eOwYMHk5mZaTvn5MmTL3r98s5xzubNm+nSpQvOzs54eXnRo0cPMjKs5QOFhYWMGTMGf39/nJycuPHGG9mxY4ft2HXr1qEoCitXriQqKgpHR0c2btyIqqpMmzaNBg0aYDKZaNWqFd9++63tuIyMDB566CH8/PwwmUxERkYyf/78cp/Dm2++mdGjRzNu3Dh8fX3p3r07AAcOHOD222/H1dWVgIAAHnnkEVJTU8s9z8Va2jw9PWtU3WpFSJ+IBo6k5AAQ6S8tN0LUdYfativ3Zy5dbqL+xx/b7h/udCNqfv5F93W+7jrCFn1uu3+0azfMGRkX7NfsYEyFY5sxYwYNGzbkk08+YceOHej1VzbhaP/+/fnrr79YsWIFv//+OwAeHh6oqsodd9yBt7c3y5cvx8PDg48//piuXbty+PBhvL29eeihh2jTpg2zZ89Gr9cTHR2N0WikY8eOTJ8+nVdeeYVDhw4B4Op68aVsyjsHQHR0NF27dmXIkCF88MEHGAwG1q5di9lsBmDChAl89913LFy4kLCwMKZNm0aPHj04evRomaV/JkyYwDvvvEODBg3w9PTkpZde4vvvv2f27NlERkayYcMGHn74Yfz8/OjSpQsvv/wyBw4c4LfffsPX15ejR4+SX87v9pyFCxfy+OOPs3nzZlRVJTk5mS5dujB8+HDee+898vPzee6557j//vtZs2bNFf2uagtJbqpZsdnC3sSzADSQZReEEHbMw8MDNzc39Ho9gYGBV3wek8mEq6srBoOhzHnWrFnD/v37SUlJsU22+s477/Djjz/y7bffMmLECBISEnj22Wdp2rQpAJGRkWXiUxTlP2O71DmmTZtGVFQUs2bNsm1r0aIFALm5ucyePZsFCxbQq1cvAObOncvq1auZN28ezz77rO2Y1157zdaakpuby3vvvceaNWvo0KEDAA0aNGDTpk18/PHHdOnShYSEBNq0aUNUVBSArVXsUho1asS0adNs91955RXatm3Lm2++adv22WefERoayuHDh2ncuPF/nrO2kuSmmu0/cZbcIusnAlkwUwjRZPeu8n/4r5aSxps3lb+vrmyVQaM/fr+asKrFrl27yMnJwcenbBd9fn4+x44dA6zzoQ0bNoxFixbRrVs37rvvPho2bHhZ17nUOaKjo7nvvvsuetyxY8coLi6mU6dOtm1Go5H27dsTE1O2BexckgLWrqKCggJbsnNOUVERbdq0AeDxxx+nX79+7N69m9tuu42+fftecgLbf18DrM/f2rVrL9pidezYMUluRPXZcsw6UsqoV3BzMmocjRBCazpnZ8331YrFYiEoKOii03ycGwU1efJkBgwYwK+//spvv/3GpEmT+Prrr7n77rsrfJ1LncNkMpV7nKqqQMXWQHRx+acl3mKxzmP266+/EhISUma/cy1UvXr1Ij4+nl9//ZXff/+drl27MmrUKN55551y4zn/Gueu07t3b956660L9g0KCrroORRFsT2uc4qLi8u9Zk0lBcXVbO8J65pS3i4OGkcihBDVx8HBwVbHck7btm05deoUBoOBRo0alfny9fW17de4cWOefvppVq1axT333GMrvL3YOctT3jlatmzJH3/8cdFjGjVqhIODA5s2/dNiVlxczM6dO2nWrFm512revDmOjo4kJCRc8LhCQ0Nt+/n5+TFo0CC++OILpk+fzieffFKhx3JO27Zt+fvvvwkPD7/gOv9OhM6/ZnJysu3+kSNHyLvMQvOaQJKbanastJi4vrf9f6oSQoiLycnJITo6mujoaABiY2OJjo4uM6P8v4WHh9v2S01NpbCwkG7dutGhQwf69u3LypUriYuLY8uWLbz00kvs3LmT/Px8Ro8ezbp164iPj2fz5s3s2LHDlliEh4eTk5PDH3/8QWpq6kXfpP/rHBMnTmTHjh088cQT7Nu3j4MHDzJ79mxSU1NxcXHh8ccf59lnn2XFihUcOHCA4cOHk5eXx9ChQ8t9rG5ubowfP56nn36ahQsXcuzYMfbs2cNHH33EwoULAWu9zE8//cTRo0f5+++/+eWXXy6ZMF3MqFGjSE9P58EHH2T79u0cP36cVatWMWTIkHKTvltvvZWZM2eye/dudu7cyciRI23F1bWKWsdkZmaqgJqZmanJ9Zu/8psa9twv6is/7tfk+kKI6pefn68eOHBAzc/P1zqUy/b++++rYWFhZbatXbtWBS74evTRR8s9T0FBgdqvXz/V09NTBdT58+erqqqqWVlZ6pNPPqkGBwerRqNRDQ0NVR966CE1ISFBLSwsVB944AE1NDRUdXBwUIODg9XRo0eXeR5Hjhyp+vj4qIA6adKkC65bkXOsW7dO7dixo+ro6Kh6enqqPXr0UDMyMlRVtf7unnzySdXX11d1dHRUO3XqpG7fvv2C5+Lc/udYLBZ1xowZapMmTVSj0aj6+fmpPXr0UNevX6+qqqq+/vrrarNmzVSTyaR6e3urd911l3r8+PFyn78uXbqoTz311AXbDx8+rN59992qp6enajKZ1KZNm6pjx45VLRbLRY9LSkpSb7vtNtXFxUWNjIxUly9frnp4eNh+H1q71P/K5bx/K6r6r863Wi4rKwsPDw8yMzNxd3ev1mubLSoNX1gOwEcD2nJHy4v3iQohapeCggJiY2OJiIjAyclJ63CEsFuX+l+5nPdv6ZaqRodOZdlud5AJ/IQQQogqIclNNcottE7J7WkySEGxEEIIUUUkualGsWnWYrdrQjy1DUQIIYSoxSS5qUZHS0dKNfKXyfuEEEKIqiLJTTVafeAUAIEejhpHIoQQQtRektxUE1VViUu1dkv5u8loCSGEEKKqSHJTTWJTczk35v7GRr6X3FcIIYQQV06Sm2qy8UgqAHoF/N2l5UYIIYSoKpLcVJM9CRkAeJhq4TTXQgghhB2R5KaaHD5tHSkV7FX+CrRCCGFvVFVlxIgReHt7oyiKbT0prQ0aNIi+fftqHYbmwsPDmT59eqWe82qf27i4OM3/ViS5qSYnz+YD0DTQTeNIhBCi4lasWMGCBQv45ZdfSE5O5pprrmHDhg307t2b4OBgFEXhxx9//M/zTJ48mdatW1daXDNmzGDBggWVdj7xj8t5bi+WCIWGhtr+VrQiyU01ySooBqBtfS+NIxFCiIo7duwYQUFBdOzYkcDAQAwGA7m5ubRq1YqZM2dW+vWKi4srtJ+Hhweenp6Vfv2qYjabsVgsWodRIVf73Or1etvfilYkuakGBcVmzi1P2qWxv7bBCCHsgqqq5BWVaPJV0fWSBw0axJNPPklCQgKKohAeHg5Ar169mDJlCvfcc0+FzrNgwQJeffVV9u7di6IoKIpiaxlQFIU5c+Zw11134eLiwpQpUzCbzQwdOpSIiAhMJhNNmjRhxowZF8R2fovBzTffzJgxY5gwYQLe3t4EBgYyefLkS8a1bt062rdvj4uLC56ennTq1In4+Hjbz5ctW0ZUVBROTk74+vqWebwZGRkMHDgQLy8vnJ2d6dWrF0eOHCnzmD09Pfnll19o3rw5jo6OxMfHU1RUxIQJEwgJCcHFxYXrr7+edevW2Y6Lj4+nd+/eeHl54eLiQosWLVi+fHmFnmeAhIQE7rrrLlxdXXF3d+f+++/n9OnTZfaZMmUK/v7+uLm5MWzYMJ5//vkyrWr/fm6//fZbrr32WkwmEz4+PnTr1o3c3FwmT57MwoUL+emnn2y/13Xr1l20W+rvv//mjjvuwN3dHTc3Nzp37syxY8cq/Lgul3ZpVR1y/Ix1GLins5FgTxkpJYSA/GIzzV9Zqcm1D7zWA2eH/375nzFjBg0bNuSTTz5hx44d6PX6K7pe//79+euvv1ixYgW///47YG0dOGfSpElMnTqV999/H71ej8VioV69enzzzTf4+vqyZcsWRowYQVBQEPfff3+511m4cCHjxo1j27ZtbN26lUGDBtGpUye6d+9+wb4lJSX07duX4cOHs3jxYoqKiti+fTuKogDw66+/cs899/Diiy+yaNEiioqK+PXXX23HDxo0iCNHjrBs2TLc3d157rnnuP322zlw4ABGo3XgSF5eHlOnTuXTTz/Fx8cHf39/Bg8eTFxcHF9//TXBwcH88MMP9OzZk/379xMZGcmoUaMoKipiw4YNuLi4cODAAVxdKzarvaqq9O3bFxcXF9avX09JSQlPPPEE/fv3tyVQX375JW+88QazZs2iU6dOfP3117z77rtERERc9JzJyck8+OCDTJs2jbvvvpvs7Gw2btyIqqqMHz+emJgYsrKymD9/PgDe3t6cPHmyzDmSkpK46aabuPnmm1mzZg3u7u5s3ryZkpKSCj2uKyHJTTU4kpINQKS/q+0fRwgh7J2Hhwdubm62boYrZTKZcHV1xWAwXPQ8AwYMYMiQIWW2vfrqq7bbERERbNmyhW+++eaSyU3Lli2ZNGkSAJGRkcycOZM//vjjoslNVlYWmZmZ3HnnnTRs2BCAZs2a2X7+xhtv8MADD5SJo1WrVgC2pGbz5s107NgRsCYNoaGh/Pjjj9x3332AtYtt1qxZtuOOHTvG4sWLOXHiBMHBwQCMHz+eFStWMH/+fN58800SEhLo168f1157LQANGjQo9/H+2++//86+ffuIjY0lNDQUgEWLFtGiRQt27NjBddddx4cffsjQoUMZPHgwAK+88gqrVq0iJyfnoudMTk6mpKSEe+65h7CwMABbbGD93RYWFl7y7+Ojjz7Cw8ODr7/+2pb4NW7cuMKP60pIclMNvtt1AgAPk6wELoSwMhn1HHith2bXtidRUVEXbJszZw6ffvop8fHx5OfnU1RU9J8FyS1btixzPygoiJSUlIvu6+3tzaBBg+jRowfdu3enW7du3H///QQFBQEQHR3N8OHDL3psTEwMBoOB66+/3rbNx8eHJk2aEBMTY9vm4OBQJqbdu3ejquoFb+yFhYX4+PgAMGbMGB5//HFWrVpFt27d6Nev3wWPqzwxMTGEhobaEhuA5s2b4+npSUxMDNdddx2HDh3iiSeeKHNc+/btWbNmzUXP2apVK7p27cq1115Ljx49uO2227j33nvx8qp4/Wh0dDSdO3e2JTbVQWpuqsFfJ7MAcHawrxcUIYR2FEXB2cGgyZe9tSC7uLiUuf/NN9/w9NNPM2TIEFatWkV0dDSDBw+mqKjokuf595unoiiXLOKdP38+W7dupWPHjixZsoTGjRvz559/AtYWifKUV7OkqmqZ59ZkMpW5b7FY0Ov17Nq1i+joaNtXTEyMraZo2LBhHD9+nEceeYT9+/cTFRXFhx9+eMnHXd71y9v+730uVYOl1+tZvXo1v/32G82bN+fDDz+kSZMmxMbGVigmuPRzWVUkuakGmfnW6v829T21DUQIITTi4OCA2Wyu0L4bN26kY8eOPPHEE7Rp04ZGjRpVWfFpmzZtmDhxIlu2bOGaa67hq6++AqytQH/88cdFj2nevDklJSVs27bNti0tLY3Dhw+X6dq62LXMZjMpKSk0atSozNf53TqhoaGMHDmS77//nmeeeYa5c+dW6LE0b96chIQEEhMTbdsOHDhAZmamLa4mTZqwffv2Msft3LnzkudVFIVOnTrx6quvsmfPHhwcHPjhhx+Aiv1eW7ZsycaNGys8Eq4ySHJTxVKzCzFbrFnxTZF+GkcjhBBXLycnx9bqABAbG0t0dDQJCQnlHhMeHm7bLzU1lcLCwnL3bdSoETt37mTlypUcPnyYl19+mR07dlTqY4iNjWXixIls3bqV+Ph4Vq1aVSY5mTRpEosXL2bSpEnExMSwf/9+pk2bBljree666y6GDx/Opk2b2Lt3Lw8//DAhISHcdddd5V6zcePGPPTQQwwcOJDvv/+e2NhYduzYwVtvvWUbETV27FhWrlxJbGwsu3fvZs2aNZdMmM7XrVs3WrZsyUMPPcTu3bvZvn07AwcOpEuXLrauvyeffJJ58+axcOFCjhw5wpQpU9i3b1+5rXnbtm3jzTffZOfOnSQkJPD9999z5swZW0zh4eHs27ePQ4cOkZqaetEEZvTo0WRlZfHAAw+wc+dOjhw5wqJFizh06FCFHteVkOSmim06al1TSgEa+LlcemchhKgBdu7cSZs2bWjTpg0A48aNo02bNrzyyivlHtOvXz969uzJLbfcgp+fH4sXLy5335EjR3LPPffQv39/rr/+etLS0i6oE7lazs7OHDx4kH79+tG4cWNGjBjB6NGjeeyxxwDr0PKlS5eybNkyWrduza233lqmpWb+/Pm0a9eOO++8kw4dOqCqKsuXL//PupL58+czcOBAnnnmGZo0aUKfPn3Ytm2brU7GbDYzatQomjVrRs+ePWnSpAmzZs2q0GM6N6Gil5cXN910E926daNBgwYsWbLEts9DDz3ExIkTGT9+PG3btiU2NpZBgwbh5HTxkbzu7u5s2LCB22+/ncaNG/PSSy/x7rvv0qtXLwCGDx9OkyZNiIqKws/Pj82bN19wDh8fH9asWUNOTg5dunShXbt2zJ07t0prcBS1ohMe1BJZWVl4eHiQmZmJu7t7lV/vxR/28+W2BNycDOyfrE3xoBBCWwUFBcTGxhIREVHum4gQWunevTuBgYEsWrRI61Au+b9yOe/fMlqqisUkW4uJA2UlcCGEEBrLy8tjzpw59OjRA71ez+LFi/n9999ZvXq11qFVKkluqtiprAIAGvlXbBImIYQQoqooisLy5cuZMmUKhYWFNGnShO+++45u3bppHVqlkuSmirk5GoECercK1joUIYQQdZzJZLLNEl2bSUFxFSoxWzieap31sWU9j//YWwghhBCVQZKbKhSfnkexWcXZQU+wR/VPYiSEEELURZLcVKGlO63LLng6G9Hp7GtGUCGEEKK2kuSmCu1JyADA0SDLLgghhBDVRZKbKhSflgdAQ5m8TwghhKg2ktxUofRc6yJvLUM8tQ1ECCGEqEMkuakieUUlFJmtq9F2ivTROBohhLgyqqoyYsQIvL29URTFtp6UqF4333wzY8eOrdRzTp48mdatW1/VOc4t+WBvJLmpIn8eT7PdblXPU7tAhBDiKqxYsYIFCxbwyy+/kJyczDXXXMOGDRvo3bs3wcHBFX5zq4w30n9bsGABnp6elXrOumT8+PHlrnz+b+X9/pKTk23rTNkTSW6qyLbj6QCYjHoMenmahRA107FjxwgKCqJjx44EBgZiMBjIzc2lVatWzJw5U+vw7I6qqpSUlGgdRoW4urri43N1PQuBgYE4OjpWUkSVR951q0h8urWY2M/N/n7pQgj7kVdUUu5XQbG50ve9HIMGDeLJJ58kISEBRVEIDw8HoFevXkyZMoV77rmnQudZsGABr776Knv37kVRFBRFYcGCBQBkZmYyYsQI/P39cXd359Zbb2Xv3r22Y/fu3cstt9yCm5sb7u7utGvXjp07d7Ju3ToGDx5MZmam7ZyTJ0++6PXLO8c5mzdvpkuXLjg7O+Pl5UWPHj3IyLCOdi0sLGTMmDH4+/vj5OTEjTfeyI4dO2zHrlu3DkVRWLlyJVFRUTg6OrJx40ZUVWXatGk0aNAAk8lEq1at+Pbbb23HZWRk8NBDD+Hn54fJZCIyMpL58+dX6Pk8d/zAgQPx8vLC2dmZXr16ceTIkTL7zJ07l9DQUJydnbn77rt57733yrR0/bs1Zt26dbRv3x4XFxc8PT3p1KkT8fHxl/z9/bvl7sSJEzzwwAN4e3vj4uJCVFRUmdXUq4ssv1BFnB2sw7/vaSvLLgghytf8lZXl/uyWJn7MH9zedr/d67+T/68k5pzrI7xZ8lgH2/0b31prG9Rwvrj/3VHh2GbMmEHDhg355JNP2LFjB3r9lU1r0b9/f/766y9WrFhhm/rfw8MDVVW544478Pb2Zvny5Xh4ePDxxx/TtWtXDh8+jLe3Nw899BBt2rRh9uzZ6PV6oqOjMRqNdOzYkenTp/PKK69w6NAhwNoScTHlnQMgOjqarl27MmTIED744AMMBgNr167FbLY+zxMmTOC7775j4cKFhIWFMW3aNHr06MHRo0fx9va2XWPChAm88847NGjQAE9PT1566SW+//57Zs+eTWRkJBs2bODhhx/Gz8+PLl268PLLL3PgwAF+++03fH19OXr0KPn5+RV+TgcNGsSRI0dYtmwZ7u7uPPfcc9x+++0cOHAAo9HI5s2bGTlyJG+99RZ9+vTh999/5+WXXy73fCUlJf9v796DojrPP4B/V2BXQC4R0V0sclUEb+FSDajRVoQqcaQ4Rk20MkQdrBfAahW1gWpaqGNNYkaJGkUTNJoUtUQhQFQwiBFFQARElJup8COIclFhkX1+f1hOsywgRnA5+Hxmdia85z2H58vK8OTsOeeFr68vli5dii+//BJKpRIZGRmQSCQdvn9tNTQ0YMqUKRg6dCji4uIgl8tx9epVqFSqLufqLtzc9JBbVU+XXRgp52UXGGPiZGJiAiMjI+jo6EAul//i4+jr62PAgAHQ1dVVO87Zs2eRm5uLqqoq4aON7du34+TJk/jXv/6FZcuWoby8HOvWrcPIkSMBAMOHD1erTyKRPLO2zo6xbds2uLm5Yffu3cLYqFGjAAAPHz5EVFQUDh48KFxXsm/fPiQnJ2P//v1Yt26dsM+WLVswffp0Yb8dO3bg7NmzcHd/2nDa2toiLS0Ne/bswZQpU1BeXg5nZ2e4ubkBgHBWrCtam5oLFy7Aw8MDAHD48GFYWlri5MmTmDt3Lj755BPMmDEDa9euBQCMGDEC6enpOHXqVLvHrKurQ21tLd566y3Y2dkBABwdHYXt7b1/bR05cgQ//fQTLl++LDR+9vb2Xc7Vnbi56QEqFQnNzfAhvBo4Y6xj+Vu8O9zWT6L+ZPPMv3S8cnPbuWnrf/Nihb0EmZmZaGho0Lju4/Hjx7h9+zYAYM2aNViyZAm++OILeHp6Yu7cucIf367q7BjZ2dmYO3duu/vdvn0bzc3NmDhxojCmp6eH8ePHo6CgQG1ua5MCAPn5+WhsbBSanVZKpRLOzs4AgOXLl2POnDm4evUqvLy84OvrKzQqz1JQUABdXV1MmDBBGDMzM4ODg4NQV2FhIX7/+9+r7Td+/PgOm5uBAwfC398f3t7emD59Ojw9PfH2229DoVB0qSbg6c/S2dlZ7YyWtvA1Nz3gh5J7eKRsgUQCWA000HY5jLFezECq2+Grv55Ot8/tTVQqFRQKBbKzs9VehYWFwlmR8PBw5OXlwcfHB2fPnoWTkxNOnDjxXN+ns2Po63e87h8RAXh6XUnb8bZjhob/e1hr68cwp0+fVsuVn58vXHczY8YMlJWVITg4GHfv3sW0adOEsyzP0lpXe+OtdbVXY0f7tYqOjsbFixfh4eGBY8eOYcSIEfjhhx+6VBPQ+c/yZePmpgdcvP30NnCpTj++U4oxxgBIpVLhOpZWLi4uqKyshK6uLuzt7dVegwYNEuaNGDECISEhSEpKgp+fn3DhbXvH7EhHxxg7dmyHt0Pb29tDKpUiLS1NGGtubsaVK1fUPrJpy8nJCTKZDOXl5Rq5LC0thXnm5ubw9/dHTEwMPvroI+zdu7dLWZycnPDkyRO1C3Xv3buHmzdvCnWNHDkSGRkZavv9/CLqjjg7OyM0NBTp6ekYPXo0jhw5AqBrP+uxY8ciOzsbNTU1XcrRk/gvbw/I/bEWADBoAN8pxRjrexoaGoSzEQBQUlKC7OxslJeXd7iPtbW1MK+6uhpNTU3w9PSEu7s7fH19kZiYiNLSUqSnp2Pz5s24cuUKHj9+jJUrVyIlJQVlZWW4cOECLl++LPwBt7a2RkNDA86cOYPq6mo8evRI4/s+6xihoaG4fPky/vjHP+LatWu4ceMGoqKiUF1dDUNDQyxfvhzr1q3Dt99+i/z8fCxduhSPHj3Ce++912FWIyMjrF27FiEhITh06BBu376NrKws7Nq1C4cOHQIAvP/++/j3v/+NW7duIS8vD6dOneq0Yfq54cOHY/bs2Vi6dCnS0tKQk5ODhQsXYujQoZg9ezYAYNWqVYiPj8eOHTtQVFSEPXv2ICEhQeNsTquSkhKEhobi4sWLKCsrQ1JSklqz1N7719aCBQsgl8vh6+uLCxcuoLi4GLGxsbh48WKXcnUresXU1tYSAKqtre2x7/HmP86S1fpTtGDvxR77Howx8Xj8+DHl5+fT48ePtV3Kc/vwww/JyspKbezcuXMEQOO1ePHiDo/T2NhIc+bMIVNTUwJA0dHRRERUV1dHq1atIgsLC9LT0yNLS0t69913qby8nJqammj+/PlkaWlJUqmULCwsaOXKlWo/x8DAQDIzMyMAFBYWpvF9u3KMlJQU8vDwIJlMRqampuTt7U33798noqfv3apVq2jQoEEkk8lo4sSJlJGRofGzaJ3fSqVS0ccff0wODg6kp6dH5ubm5O3tTampqUREtHXrVnJ0dCR9fX0aOHAgzZ49m4qLizv8+U2ZMoWCgoKEr2tqamjRokVkYmJC+vr65O3tTTdv3lTbZ+/evTR06FDS19cnX19f+uCDD0gulwvbw8LCaNy4cUREVFlZSb6+vqRQKEgqlZKVlRW9//771NLS0un7B4BOnDghHLO0tJTmzJlDxsbGZGBgQG5ubnTp0qUOc7XV2e/K8/z9lvy3uFdGXV0dTExMUFtbC2Nj4x75Ho5/+RaPm1uwbLItNvp0rRNnjPVdjY2NKCkpgY2NDfr376/tctgraunSpbhx4wa+//57bZfSoc5+V57n73fvurqsD2hpUQnPoXjDTvtXjDPGGHs1bd++HdOnT4ehoSESEhJw6NAhtVve+zJubrpZzn+vtwGAN2x4wUzGGGPakZGRgW3btqG+vh62trbYuXMnlixZou2yXgpubrrZjco6AIBMtx8MZPzjZYwxph1fffWVtkvQGr5bqps1Nj99vsFvHAZruRLGGGPs1cTNTTcr4icTM8Y68Irdv8HYc+uu3xFubrpZ0f89/VjKfjA3N4yxp1oXaWzvOSyMsf9RKp8u9vpLF2ltxReFdCOVSoXMsgcAAFN9qXaLYYz1Gjo6OjA1NUVVVRUAwMDAoMOHqTH2qlKpVPjpp59gYGAAXd0Xa0+4uelGhZUNaD2h5jzMVJulMMZ6mdbVlFsbHMaYpn79+mHYsGEv3Pxzc9ONvr/1EwBAt58Exvp6Wq6GMdabSCQSKBQKDB48GM3Nzdouh7FeSSqVol+/F79ihpubbpRz5wEA4DUD/kiKMdY+HR2dF76egDHWOa1fULx7927hMcuurq7PfCx0amoqXF1d0b9/f9ja2uLTTz99SZU+W+udUr8a2HuWfWeMMcZeNVptbo4dO4bg4GBs2rQJWVlZmDx5MmbMmNHhyrIlJSWYOXMmJk+ejKysLGzcuBGrV69GbGzsS668fZW1jQAAR7mRlithjDHGXl1aXThzwoQJcHFxQVRUlDDm6OgIX19fREREaMxfv3494uLiUFBQIIwFBgYiJyeny0uq9+TCmTahp0EEfPj26/i9y9BuPTZjjDH2KhPFwplKpRKZmZnYsGGD2riXlxfS09Pb3efixYvw8vJSG/P29sb+/fvR3NwsPEvi55qamtDU1CR8XVv7dO2nurq6F42g5qe6RrQ0Pn2Gxbghet1+fMYYY+xV1vp3tSvnZLTW3FRXV6OlpQVDhgxRGx8yZAgqKyvb3aeysrLd+U+ePEF1dTUUCoXGPhEREfjrX/+qMW5pafkC1XfO7qMeOzRjjDH2Squvr4eJiUmnc7R+t1Tbe9mJqNP729ub3954q9DQUKxZs0b4WqVSoaamBmZmZi90H31dXR0sLS1x586dbv9462XiHL0L5+hd+koOoO9k4Ry9y8vMQUSor6+HhYXFM+dqrbkZNGgQdHR0NM7SVFVVaZydaSWXy9udr6urCzMzs3b3kclkkMlkamOmpqa/vPA2jI2NRf0PsxXn6F04R+/SV3IAfScL5+hdXlaOZ52xaaW1u6WkUilcXV2RnJysNp6cnAwPD49293F3d9eYn5SUBDc3t3avt2GMMcbYq0ert4KvWbMGn332GQ4cOICCggKEhISgvLwcgYGBAJ5+pPSHP/xBmB8YGIiysjKsWbMGBQUFOHDgAPbv34+1a9dqKwJjjDHGehmtXnMzb9483Lt3D1u2bEFFRQVGjx6N+Ph4WFlZAQAqKirUnnljY2OD+Ph4hISEYNeuXbCwsMDOnTsxZ86cl167TCZDWFiYxkdeYsM5ehfO0bv0lRxA38nCOXqX3ppDq8+5YYwxxhjrblpffoExxhhjrDtxc8MYY4yxPoWbG8YYY4z1KdzcMMYYY6xP4ebmF9i9ezdsbGzQv39/uLq64vvvv9d2Sc90/vx5zJo1CxYWFpBIJDh58qTadiJCeHg4LCwsoK+vj6lTpyIvL087xXYgIiICv/71r2FkZITBgwfD19cXhYWFanPEkCMqKgpjx44VHnrl7u6OhIQEYbsYMrQnIiICEokEwcHBwphYsoSHh0Mikai95HK5sF0sOQDgP//5DxYuXAgzMzMYGBjg9ddfR2ZmprBdDFmsra013g+JRIIVK1YAEEcGAHjy5Ak2b94MGxsb6Ovrw9bWFlu2bIFKpRLmiCVLfX09goODYWVlBX19fXh4eODy5cvC9l6Xg9hzOXr0KOnp6dG+ffsoPz+fgoKCyNDQkMrKyrRdWqfi4+Np06ZNFBsbSwDoxIkTatsjIyPJyMiIYmNjKTc3l+bNm0cKhYLq6uq0U3A7vL29KTo6mq5fv07Z2dnk4+NDw4YNo4aGBmGOGHLExcXR6dOnqbCwkAoLC2njxo2kp6dH169fJyJxZGgrIyODrK2taezYsRQUFCSMiyVLWFgYjRo1iioqKoRXVVWVsF0sOWpqasjKyor8/f3p0qVLVFJSQt999x3dunVLmCOGLFVVVWrvRXJyMgGgc+fOEZE4MhARffDBB2RmZkanTp2ikpIS+vrrr2nAgAH00UcfCXPEkuXtt98mJycnSk1NpaKiIgoLCyNjY2P68ccfiaj35eDm5jmNHz+eAgMD1cZGjhxJGzZs0FJFz69tc6NSqUgul1NkZKQw1tjYSCYmJvTpp59qocKuqaqqIgCUmppKROLNQUT02muv0WeffSbKDPX19TR8+HBKTk6mKVOmCM2NmLKEhYXRuHHj2t0mphzr16+nSZMmdbhdTFl+LigoiOzs7EilUokqg4+PDwUEBKiN+fn50cKFC4lIPO/Ho0ePSEdHh06dOqU2Pm7cONq0aVOvzMEfSz0HpVKJzMxMeHl5qY17eXkhPT1dS1W9uJKSElRWVqrlkslkmDJlSq/OVVtbCwAYOHAgAHHmaGlpwdGjR/Hw4UO4u7uLMsOKFSvg4+MDT09PtXGxZSkqKoKFhQVsbGwwf/58FBcXAxBXjri4OLi5uWHu3LkYPHgwnJ2dsW/fPmG7mLK0UiqViImJQUBAACQSiagyTJo0CWfOnMHNmzcBADk5OUhLS8PMmTMBiOf9ePLkCVpaWtC/f3+1cX19faSlpfXKHNzcPIfq6mq0tLRoLOw5ZMgQjQU9xaS1djHlIiKsWbMGkyZNwujRowGIK0dubi4GDBgAmUyGwMBAnDhxAk5OTqLKAABHjx7F1atXERERobFNTFkmTJiAzz//HImJidi3bx8qKyvh4eGBe/fuiSpHcXExoqKiMHz4cCQmJiIwMBCrV6/G559/DkBc70mrkydP4sGDB/D39wcgrgzr16/HggULMHLkSOjp6cHZ2RnBwcFYsGABAPFkMTIygru7O7Zu3Yq7d++ipaUFMTExuHTpEioqKnplDq0uvyBWEolE7Wsi0hgTIzHlWrlyJa5du4a0tDSNbWLI4eDggOzsbDx48ACxsbFYvHgxUlNThe1iyHDnzh0EBQUhKSlJ4//ofk4MWWbMmCH895gxY+Du7g47OzscOnQIb7zxBgBx5FCpVHBzc8Pf//53AICzszPy8vIQFRWltk6fGLK02r9/P2bMmAELCwu1cTFkOHbsGGJiYnDkyBGMGjUK2dnZCA4OhoWFBRYvXizME0OWL774AgEBARg6dCh0dHTg4uKCd955B1evXhXm9KYcfObmOQwaNAg6OjoanWhVVZVGxyomrXeFiCXXqlWrEBcXh3PnzuFXv/qVMC6mHFKpFPb29nBzc0NERATGjRuHjz/+WFQZMjMzUVVVBVdXV+jq6kJXVxepqanYuXMndHV1hXrFkKUtQ0NDjBkzBkVFRaJ6TxQKBZycnNTGHB0dhTX6xJQFAMrKyvDdd99hyZIlwpiYMqxbtw4bNmzA/PnzMWbMGCxatAghISHCmU4xZbGzs0NqaioaGhpw584dZGRkoLm5GTY2Nr0yBzc3z0EqlcLV1RXJyclq48nJyfDw8NBSVS+u9R/nz3MplUqkpqb2qlxEhJUrV+L48eM4e/YsbGxs1LaLJUd7iAhNTU2iyjBt2jTk5uYiOztbeLm5ueHdd99FdnY2bG1tRZOlraamJhQUFEChUIjqPZk4caLG4xFu3rwpLEYspiwAEB0djcGDB8PHx0cYE1OGR48eoV8/9T+zOjo6wq3gYsrSytDQEAqFAvfv30diYiJmz57dO3No5TJmEWu9FXz//v2Un59PwcHBZGhoSKWlpdourVP19fWUlZVFWVlZBIB27NhBWVlZwi3skZGRZGJiQsePH6fc3FxasGBBr7sdcfny5WRiYkIpKSlqt4k+evRImCOGHKGhoXT+/HkqKSmha9eu0caNG6lfv36UlJREROLI0JGf3y1FJJ4sf/rTnyglJYWKi4vphx9+oLfeeouMjIyE32ux5MjIyCBdXV3629/+RkVFRXT48GEyMDCgmJgYYY5YsrS0tNCwYcNo/fr1GtvEkmHx4sU0dOhQ4Vbw48eP06BBg+jPf/6zMEcsWb799ltKSEig4uJiSkpKonHjxtH48eNJqVQSUe/Lwc3NL7Br1y6ysrIiqVRKLi4uwq3Ivdm5c+cIgMZr8eLFRPT0lsSwsDCSy+Ukk8nozTffpNzcXO0W3UZ79QOg6OhoYY4YcgQEBAj/fszNzWnatGlCY0MkjgwdadvciCVL6zM59PT0yMLCgvz8/CgvL0/YLpYcRETffPMNjR49mmQyGY0cOZL27t2rtl0sWRITEwkAFRYWamwTS4a6ujoKCgqiYcOGUf/+/cnW1pY2bdpETU1NwhyxZDl27BjZ2tqSVColuVxOK1asoAcPHgjbe1sOCRGRVk4ZMcYYY4z1AL7mhjHGGGN9Cjc3jDHGGOtTuLlhjDHGWJ/CzQ1jjDHG+hRubhhjjDHWp3BzwxhjjLE+hZsbxhhjjPUp3NwwxrrV1KlTERwcrO0ynltKSgokEgkePHig7VIYYy+ImxvGGAPg4eGBiooKmJiYaLsUxtgL4uaGMdbnNDc3P/c+UqkUcrkcEomkBypijL1M3NwwxnpUTEwM3NzcYGRkBLlcjnfeeQdVVVUAnq6Gbm9vj+3bt6vtc/36dfTr1w+3b98GANTW1mLZsmUYPHgwjI2N8dvf/hY5OTnC/PDwcLz++us4cOAAbG1tIZPJ0N7KMmVlZZg1axZee+01GBoaYtSoUYiPjweg+bHU1KlTIZFINF6lpaVdqokxpj3c3DDGepRSqcTWrVuRk5ODkydPoqSkBP7+/gAAiUSCgIAAREdHq+1z4MABTJ48GXZ2diAi+Pj4oLKyEvHx8cjMzISLiwumTZuGmpoaYZ9bt27hq6++QmxsLLKzs9utZcWKFWhqasL58+eRm5uLf/zjHxgwYEC7c48fP46Kigrh5efnBwcHBwwZMqTLNTHGtERrS3YyxvqktiuDt5WRkUEAqL6+noiI7t69Szo6OnTp0iUiIlIqlWRubk4HDx4kIqIzZ86QsbExNTY2qh3Hzs6O9uzZQ0REYWFhpKenR1VVVZ3WNmbMGAoPD29327lz5wgA3b9/X2Pbjh07yNTUVFihuis1Mca0R1fbzRVjrG/LyspCeHg4srOzUVNTA5VKBQAoLy+Hk5MTFAoFfHx8cODAAYwfPx6nTp1CY2Mj5s6dCwDIzMxEQ0MDzMzM1I77+PFj4WMrALCysoK5uXmntaxevRrLly9HUlISPD09MWfOHIwdO7bTfRISErBhwwZ88803GDFixHPVxBjTDm5uGGM95uHDh/Dy8oKXlxdiYmJgbm6O8vJyeHt7Q6lUCvOWLFmCRYsW4cMPP0R0dDTmzZsHAwMDAIBKpYJCoUBKSorG8U1NTYX/NjQ0fGY9S5Ysgbe3N06fPo2kpCRERETgn//8J1atWtXu/Pz8fMyfPx+RkZHw8vISxrtaE2NMO7i5YYz1mBs3bqC6uhqRkZGwtLQEAFy5ckVj3syZM2FoaIioqCgkJCTg/PnzwjYXFxdUVlZCV1cX1tbWL1yTpaUlAgMDERgYiNDQUOzbt6/d5ubevXuYNWsW/Pz8EBISoratu2tijHUvvqCYMdZjhg0bBqlUik8++QTFxcWIi4vD1q1bNebp6OjA398foaGhsLe3h7u7u7DN09MT7u7u8PX1RWJiIkpLS5Geno7Nmze32yh1Jjg4GImJiSgpKcHVq1dx9uxZODo6tjvXz88P+vr6CA8PR2VlpfBqaWnp1poYY92PmxvGWI8xNzfHwYMH8fXXX8PJyQmRkZEat323eu+996BUKhEQEKA2LpFIEB8fjzfffBMBAQEYMWIE5s+fj9LSUgwZMuS56mlpacGKFSvg6OiI3/3ud3BwcMDu3bvbnXv+/Hnk5eXB2toaCoVCeN25c6dba2KMdT8JUTsPg2CMsZfswoULmDp1Kn788UduEBhjL4SbG8aYVjU1NeHOnTtYtmwZFAoFDh8+rO2SGGMixx9LMca06ssvv4SDgwNqa2uxbds2bZfDGOsD+MwNY4wxxvoUPnPDGGOMsT6FmxvGGGOM9Snc3DDGGGOsT+HmhjHGGGN9Cjc3jDHGGOtTuLlhjDHGWJ/CzQ1jjDHG+hRubhhjjDHWp3BzwxhjjLE+5f8BQmkBwqqoU2wAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(layer_size, f1_train_scores_relu, label=\"f1 train scores relu\",color='C3',)\n",
    "plt.plot(layer_size, f1_test_scores_relu, label=\"f1 test scores relu\",color='C3', linestyle='--',)\n",
    "plt.plot(layer_size, f1_train_scores_logistic, label=\"f1 train scores logistic\",color='C0',)\n",
    "plt.plot(layer_size, f1_test_scores_logistic, label=\"f1 test scores logistic\",color='C0', linestyle='--',)\n",
    "plt.xticks(np.arange(0,100,10))\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel(\"layer size\")\n",
    "plt.ylabel(\"f1 score\")\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07993c55-b936-4915-8c6e-7049e519f128",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = {\n",
    "    'activation': ['identity','logistic', 'tanh', 'relu'],\n",
    "    'hidden_layer_sizes': range(1,110,10),\n",
    "    'solver':['lbfgs', 'sgd', 'adam'],\n",
    "    'alpha':[0.0001,0.001],\n",
    "    'max_iter':[5000],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "296d4af1-1f45-453f-84bf-725be12de554",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=NN,\n",
    "    param_grid=params_grid,\n",
    "    return_train_score=True,\n",
    "    cv=4,\n",
    "    verbose=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62055a11-9904-4caa-9292-938fc4462dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 264 candidates, totalling 1056 fits\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.499, test=0.499) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.740, test=0.759) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.505, test=0.509) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.510, test=0.504) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.502) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.499) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.748, test=0.733) total time=   0.7s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.505, test=0.472) total time=   0.6s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.496, test=0.502) total time=   0.2s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.747, test=0.709) total time=   1.4s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.501, test=0.501) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.740, test=0.759) total time=   0.1s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.737, test=0.748) total time=   0.3s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.748, test=0.715) total time=   0.2s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.497) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.501) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.667, test=0.655) total time=   0.1s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.698, test=0.716) total time=   0.3s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.721, test=0.735) total time=   0.1s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.677, test=0.661) total time=   0.1s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.740, test=0.739) total time=   0.1s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.736, test=0.751) total time=   0.2s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.741, test=0.750) total time=   0.5s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.750, test=0.724) total time=   0.4s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.499) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.499) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.501) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.629, test=0.613) total time=   0.1s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.644, test=0.635) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.697, test=0.700) total time=   0.1s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.745, test=0.740) total time=   0.1s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.742, test=0.738) total time=   0.6s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.739, test=0.759) total time=   1.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.733, test=0.746) total time=   0.3s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.749, test=0.723) total time=   0.3s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.502) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.499) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.501) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.723, test=0.698) total time=   0.1s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.723, test=0.740) total time=   0.1s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.725, test=0.735) total time=   0.1s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.612, test=0.606) total time=   0.1s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.743, test=0.739) total time=   0.7s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.740, test=0.759) total time=   0.4s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.740, test=0.750) total time=   0.3s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.752, test=0.723) total time=   0.7s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.497) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.499) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.501) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.739, test=0.711) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.710, test=0.741) total time=   0.1s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.586, test=0.589) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.710, test=0.719) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.741, test=0.740) total time=   0.6s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.738, test=0.754) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.741, test=0.751) total time=   0.9s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.748, test=0.716) total time=   0.1s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.502) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.501) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.735, test=0.721) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.696, test=0.711) total time=   0.1s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.723, test=0.744) total time=   0.1s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.700, test=0.695) total time=   0.2s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.743, test=0.736) total time=   1.1s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.742, test=0.757) total time=   0.5s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.742, test=0.750) total time=   0.5s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.749, test=0.726) total time=   1.3s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.497) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.501) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.731, test=0.709) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.674, test=0.698) total time=   0.1s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.656, test=0.645) total time=   0.1s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.728, test=0.725) total time=   0.1s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.743, test=0.736) total time=   1.7s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.734, test=0.746) total time=   0.4s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.736, test=0.750) total time=   0.9s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.751, test=0.724) total time=   0.9s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.502) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.501) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.499) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.720, test=0.690) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.633, test=0.618) total time=   0.1s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.552, test=0.566) total time=   0.1s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.695, test=0.698) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.743, test=0.736) total time=   2.3s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.740, test=0.757) total time=   0.5s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.741, test=0.751) total time=   1.9s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.751, test=0.724) total time=   1.1s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.502) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.612, test=0.610) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.649, test=0.634) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.721, test=0.735) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.618, test=0.604) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.740, test=0.739) total time=   1.1s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.741, test=0.760) total time=   2.1s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.742, test=0.746) total time=   1.1s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.750, test=0.724) total time=   1.4s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.497) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.501) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.675, test=0.662) total time=   0.1s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.655, test=0.651) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.658, test=0.645) total time=   0.1s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.620, test=0.606) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.740, test=0.735) total time=   1.2s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.741, test=0.757) total time=   1.6s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.739, test=0.748) total time=   0.7s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.750, test=0.723) total time=   1.6s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.497) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.501) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.499) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.737, test=0.718) total time=   0.1s\n",
      "[CV 2/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.718, test=0.739) total time=   0.1s\n",
      "[CV 3/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.666, test=0.656) total time=   0.1s\n",
      "[CV 4/4] END activation=identity, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.733, test=0.724) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.505, test=0.501) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.502, test=0.524) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.507, test=0.506) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.750, test=0.724) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.497) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.501) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.734, test=0.719) total time=   0.6s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.730, test=0.743) total time=   0.3s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.743, test=0.756) total time=   0.6s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.748, test=0.706) total time=   0.7s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.743, test=0.739) total time=   0.2s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.499, test=0.499) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.499, test=0.499) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.501) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.501) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.740, test=0.726) total time=   0.2s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.691, test=0.716) total time=   0.2s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.738, test=0.748) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.707, test=0.701) total time=   0.2s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.743, test=0.740) total time=   0.5s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.741, test=0.759) total time=   0.4s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.736, test=0.752) total time=   0.2s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.499, test=0.500) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.499) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.501) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.703, test=0.693) total time=   0.1s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.719, test=0.723) total time=   0.1s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.720, test=0.730) total time=   0.1s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.744, test=0.730) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.501, test=0.501) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.740, test=0.757) total time=   0.5s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.740, test=0.750) total time=   0.3s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.749, test=0.724) total time=   0.3s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.497) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.501) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.722, test=0.710) total time=   0.1s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.703, test=0.715) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.723, test=0.736) total time=   0.1s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.737, test=0.733) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.742, test=0.740) total time=   0.1s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.738, test=0.761) total time=   0.8s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.740, test=0.749) total time=   0.3s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.750, test=0.725) total time=   0.3s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.501) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.708, test=0.680) total time=   0.1s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.692, test=0.715) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.694, test=0.693) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.686, test=0.670) total time=   0.1s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.743, test=0.736) total time=   0.7s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.736, test=0.752) total time=   0.2s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.733, test=0.751) total time=   0.1s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.745, test=0.713) total time=   0.2s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.497) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.501) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.697, test=0.682) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.625, test=0.618) total time=   0.1s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.732, test=0.749) total time=   0.1s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.577, test=0.569) total time=   0.1s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.743, test=0.738) total time=   0.8s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.743, test=0.757) total time=   1.8s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.736, test=0.750) total time=   2.3s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.750, test=0.723) total time=   0.4s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.497) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.501) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.736, test=0.711) total time=   0.1s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.712, test=0.736) total time=   0.1s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.723, test=0.723) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.734, test=0.724) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.743, test=0.738) total time=   0.7s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.740, test=0.752) total time=   1.3s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.736, test=0.748) total time=   0.4s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.749, test=0.730) total time=   0.9s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.501) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.724, test=0.698) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.661, test=0.664) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.662, test=0.682) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.734, test=0.723) total time=   0.1s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.743, test=0.736) total time=   0.9s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.741, test=0.757) total time=   0.6s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.743, test=0.752) total time=   0.9s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.750, test=0.725) total time=   1.9s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.499) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.499) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.691, test=0.679) total time=   0.2s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.544, test=0.557) total time=   0.1s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.713, test=0.714) total time=   0.1s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.623, test=0.623) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.740, test=0.730) total time=   0.6s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.739, test=0.752) total time=   0.8s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.740, test=0.750) total time=   2.4s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.749, test=0.726) total time=   1.5s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.502) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.625, test=0.623) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.723, test=0.745) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.708, test=0.708) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.727, test=0.706) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.744, test=0.736) total time=   0.8s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.735, test=0.746) total time=   0.7s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.742, test=0.750) total time=   3.3s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.749, test=0.723) total time=   0.9s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.501) total time=   0.0s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.501) total time=   0.0s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.501) total time=   0.0s\n",
      "[CV 1/4] END activation=identity, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.621, test=0.618) total time=   0.1s\n",
      "[CV 2/4] END activation=identity, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.713, test=0.738) total time=   0.0s\n",
      "[CV 3/4] END activation=identity, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.685, test=0.675) total time=   0.1s\n",
      "[CV 4/4] END activation=identity, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.609, test=0.596) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.749, test=0.739) total time=   0.1s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.500, test=0.502) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.510, test=0.505) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.497) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.1s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.1s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.728, test=0.706) total time=   0.5s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.500, test=0.497) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.737, test=0.741) total time=   0.5s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.502, test=0.501) total time=   0.1s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.810, test=0.787) total time=   5.5s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.745, test=0.759) total time=   0.7s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.819, test=0.811) total time=   7.4s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.755, test=0.738) total time=   0.7s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.497, test=0.496) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.502) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.502) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.779, test=0.740) total time=   0.4s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.772, test=0.777) total time=   0.5s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.750, test=0.745) total time=   0.3s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.734, test=0.708) total time=   0.3s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.821, test=0.809) total time=  10.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.854, test=0.833) total time=  10.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.812, test=0.800) total time=  18.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.829, test=0.814) total time=  13.6s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.502) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.497) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.507) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.500) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.771, test=0.757) total time=   0.6s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.733, test=0.749) total time=   0.4s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.739, test=0.746) total time=   0.4s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.710, test=0.693) total time=   0.2s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.833, test=0.843) total time=  11.7s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.820, test=0.810) total time=  11.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.874, test=0.866) total time=  25.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.838, test=0.830) total time=  15.2s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.497, test=0.495) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.504, test=0.487) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.731, test=0.695) total time=   0.2s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.763, test=0.770) total time=   0.5s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.743, test=0.749) total time=   0.4s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.730, test=0.700) total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.860, test=0.826) total time=  28.8s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.742, test=0.762) total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.840, test=0.839) total time=  22.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.845, test=0.830) total time=  18.9s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.502) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.502) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.505, test=0.499) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.513, test=0.507) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.824, test=0.821) total time=   1.5s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.802, test=0.790) total time=   1.3s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.796, test=0.802) total time=   1.2s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.752, test=0.714) total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.843, test=0.810) total time=  30.1s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.805, test=0.782) total time=  29.8s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.744, test=0.755) total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.844, test=0.824) total time=  22.8s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.503, test=0.500) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.503, test=0.496) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.497, test=0.511) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.503, test=0.501) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.774, test=0.759) total time=   0.8s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.768, test=0.787) total time=   0.8s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.777, test=0.786) total time=   1.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.774, test=0.745) total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.875, test=0.844) total time=  28.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.840, test=0.814) total time=  43.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.837, test=0.833) total time=  43.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.847, test=0.825) total time=  27.7s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.504, test=0.516) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.504, test=0.511) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.494, test=0.505) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.505) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.749, test=0.733) total time=   0.5s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.735, test=0.746) total time=   0.5s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.742, test=0.745) total time=   0.7s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.772, test=0.749) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.852, test=0.819) total time=  34.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.855, test=0.843) total time=  34.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.881, test=0.877) total time=  48.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.843, test=0.820) total time=  39.1s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.505, test=0.507) total time=   0.1s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.519, test=0.520) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.533, test=0.520) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.503, test=0.502) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.778, test=0.729) total time=   0.9s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.818, test=0.805) total time=   1.5s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.752, test=0.759) total time=   0.6s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.765, test=0.739) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.842, test=0.806) total time=  53.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.852, test=0.849) total time=  38.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.860, test=0.853) total time=  38.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.849, test=0.820) total time=  59.2s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.497, test=0.501) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.503, test=0.506) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.513, test=0.504) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.1s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.828, test=0.816) total time=   1.8s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.821, test=0.805) total time=   1.5s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.738, test=0.754) total time=   0.3s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.802, test=0.779) total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.862, test=0.815) total time=  45.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.839, test=0.809) total time=  48.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.827, test=0.825) total time=  43.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.850, test=0.838) total time=  49.2s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.505) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.502) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.499) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.503, test=0.505) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.833, test=0.800) total time=   1.9s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.728, test=0.738) total time=   0.3s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.738, test=0.751) total time=   0.4s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.745, test=0.726) total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.867, test=0.807) total time=  54.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.850, test=0.805) total time=  45.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.858, test=0.853) total time=  54.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.828, test=0.814) total time=  49.6s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.503, test=0.502) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.505, test=0.505) total time=   0.1s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.507, test=0.501) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.506) total time=   0.1s\n",
      "[CV 1/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.748, test=0.724) total time=   0.6s\n",
      "[CV 2/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.835, test=0.829) total time=   2.7s\n",
      "[CV 3/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.723, test=0.738) total time=   0.3s\n",
      "[CV 4/4] END activation=logistic, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.750, test=0.730) total time=   0.6s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.751, test=0.743) total time=   0.2s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.502, test=0.502) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.757, test=0.730) total time=   0.1s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.502) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.497) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.1s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.499, test=0.497) total time=   0.2s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.504, test=0.491) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.840, test=0.829) total time=   8.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.823, test=0.804) total time=   7.4s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.820, test=0.823) total time=   4.7s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.828, test=0.824) total time=   7.5s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.496) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.501) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.503, test=0.502) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.796, test=0.779) total time=   1.2s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.736, test=0.748) total time=   0.6s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.785, test=0.795) total time=   1.2s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.772, test=0.762) total time=   0.6s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.810, test=0.791) total time=  13.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.874, test=0.845) total time=  11.9s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.772, test=0.796) total time=   6.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.852, test=0.845) total time=  15.9s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.502) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.492) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.496, test=0.509) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.501) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.771, test=0.771) total time=   0.5s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.722, test=0.741) total time=   0.2s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.740, test=0.759) total time=   0.4s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.745, test=0.735) total time=   0.4s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.793, test=0.781) total time=   4.3s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.771, test=0.787) total time=   4.8s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.820, test=0.823) total time=  19.2s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.789, test=0.774) total time=   6.6s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.500) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.500) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.508, test=0.511) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.505, test=0.496) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.831, test=0.805) total time=   1.3s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.730, test=0.745) total time=   0.4s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.749, test=0.759) total time=   0.5s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.756, test=0.729) total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.850, test=0.835) total time=  17.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.840, test=0.829) total time=  25.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.853, test=0.864) total time=  23.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.848, test=0.843) total time=  22.9s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.503, test=0.505) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.512) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.507, test=0.499) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.763, test=0.743) total time=   0.7s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.784, test=0.797) total time=   1.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.744, test=0.757) total time=   0.4s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.748, test=0.736) total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.865, test=0.848) total time=  28.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.869, test=0.851) total time=  18.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.848, test=0.834) total time=  23.3s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.822, test=0.797) total time=  18.1s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.505, test=0.502) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.502) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.496) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.740, test=0.724) total time=   0.3s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.791, test=0.796) total time=   1.3s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.763, test=0.766) total time=   0.7s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.755, test=0.730) total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.824, test=0.804) total time=  38.5s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.825, test=0.791) total time=  33.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.843, test=0.840) total time=  38.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.855, test=0.859) total time=  46.8s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.503, test=0.506) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.503, test=0.501) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.507, test=0.507) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.499) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.743, test=0.711) total time=   0.4s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.812, test=0.794) total time=   2.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.790, test=0.799) total time=   1.5s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.811, test=0.789) total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.837, test=0.835) total time=  45.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.855, test=0.834) total time=  36.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.875, test=0.864) total time=  40.6s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.754, test=0.734) total time=   3.9s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.496, test=0.494) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.507, test=0.515) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.490, test=0.504) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.511, test=0.500) total time=   0.1s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.722, test=0.710) total time=   0.3s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.769, test=0.772) total time=   1.2s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.745, test=0.751) total time=   0.5s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.735, test=0.716) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.832, test=0.806) total time=  39.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.858, test=0.849) total time=  35.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.867, test=0.840) total time=  51.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.851, test=0.829) total time=  56.6s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.504, test=0.502) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.504) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.499) total time=   0.0s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.500) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.767, test=0.764) total time=   0.9s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.810, test=0.811) total time=   1.5s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.719, test=0.713) total time=   0.5s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.773, test=0.752) total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.847, test=0.833) total time=  42.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.857, test=0.826) total time=  42.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.853, test=0.863) total time=  56.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.830, test=0.820) total time= 1.2min\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.501) total time=   0.1s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.502) total time=   0.0s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.507, test=0.504) total time=   0.1s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.496, test=0.491) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.741, test=0.721) total time=   0.5s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.729, test=0.738) total time=   0.4s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.737, test=0.755) total time=   0.5s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.814, test=0.792) total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.843, test=0.825) total time=  58.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.813, test=0.804) total time=  51.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.827, test=0.836) total time=  55.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.847, test=0.846) total time= 1.1min\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.503, test=0.511) total time=   0.0s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.506, test=0.502) total time=   0.1s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.494) total time=   0.1s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.503, test=0.502) total time=   0.0s\n",
      "[CV 1/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.766, test=0.749) total time=   1.1s\n",
      "[CV 2/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.830, test=0.820) total time=   2.2s\n",
      "[CV 3/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.742, test=0.745) total time=   0.6s\n",
      "[CV 4/4] END activation=logistic, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.741, test=0.728) total time=   0.5s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.501, test=0.502) total time=   0.0s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.501, test=0.502) total time=   0.0s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.501) total time=   0.0s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.1s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.499) total time=   0.0s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.1s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.499, test=0.499) total time=   0.2s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.502, test=0.500) total time=   0.3s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.498, test=0.499) total time=   0.0s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.749, test=0.743) total time=   1.2s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.781, test=0.776) total time=   4.0s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.785, test=0.772) total time=   5.7s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.753, test=0.729) total time=   1.2s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.499) total time=   0.0s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.501) total time=   0.0s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.507, test=0.500) total time=   0.0s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.499) total time=   0.0s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.745, test=0.731) total time=   0.4s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.734, test=0.745) total time=   0.5s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.735, test=0.723) total time=   0.7s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.505, test=0.497) total time=   0.0s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.746, test=0.739) total time=   1.8s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.843, test=0.821) total time=  15.9s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.747, test=0.750) total time=   3.5s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.755, test=0.739) total time=   1.7s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.504, test=0.499) total time=   0.0s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.500) total time=   0.0s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.491) total time=   0.0s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.494) total time=   0.0s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.743, test=0.715) total time=   0.5s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.748, test=0.755) total time=   0.4s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.719, test=0.730) total time=   0.1s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.717, test=0.675) total time=   0.6s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.751, test=0.741) total time=   5.4s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.844, test=0.836) total time=  22.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.872, test=0.861) total time=  26.3s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.755, test=0.735) total time=   2.6s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.502) total time=   0.1s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.500) total time=   0.1s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.500) total time=   0.0s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.500) total time=   0.0s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.753, test=0.720) total time=   0.5s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.710, test=0.734) total time=   0.6s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.733, test=0.741) total time=   0.7s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.747, test=0.713) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.806, test=0.786) total time=  36.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.806, test=0.777) total time=  35.3s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.872, test=0.866) total time=  31.8s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.828, test=0.816) total time=  29.6s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.497) total time=   0.1s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.497) total time=   0.0s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.507) total time=   0.1s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.495) total time=   0.1s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.719, test=0.703) total time=   0.9s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.775, test=0.797) total time=   1.3s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.763, test=0.770) total time=   1.1s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.733, test=0.714) total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.885, test=0.860) total time=  41.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.858, test=0.838) total time=  41.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.827, test=0.829) total time=  44.3s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.845, test=0.839) total time=  39.6s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.501) total time=   0.1s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.506) total time=   0.1s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.514) total time=   0.2s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.504, test=0.501) total time=   0.1s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.742, test=0.720) total time=   0.6s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.780, test=0.799) total time=   1.9s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.752, test=0.757) total time=   1.2s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.734, test=0.731) total time=   0.6s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.747, test=0.745) total time=  10.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.856, test=0.840) total time=  58.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.855, test=0.844) total time=  59.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.840, test=0.809) total time=  59.1s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.501) total time=   0.1s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.496) total time=   0.1s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.494) total time=   0.1s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.503, test=0.492) total time=   0.1s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.756, test=0.749) total time=   1.1s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.769, test=0.769) total time=   1.4s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.730, test=0.730) total time=   1.4s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.767, test=0.759) total time=   2.1s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.805, test=0.781) total time=  36.1s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.787, test=0.812) total time=  46.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.854, test=0.844) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.856, test=0.840) total time= 1.1min\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.494) total time=   0.1s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.506, test=0.507) total time=   0.1s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.504, test=0.499) total time=   0.2s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.497, test=0.499) total time=   0.2s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.746, test=0.721) total time=   1.3s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.743, test=0.752) total time=   1.2s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.752, test=0.744) total time=   1.1s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.746, test=0.714) total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.862, test=0.835) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.867, test=0.853) total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.860, test=0.849) total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.855, test=0.851) total time= 1.3min\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.496) total time=   0.1s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.504, test=0.496) total time=   0.1s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.503, test=0.501) total time=   0.2s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.501) total time=   0.1s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.725, test=0.705) total time=   0.6s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.748, test=0.761) total time=   1.5s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.739, test=0.754) total time=   1.0s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.756, test=0.728) total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.855, test=0.814) total time= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.844, test=0.826) total time= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.852, test=0.826) total time= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.862, test=0.850) total time= 1.4min\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.502) total time=   0.4s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.497, test=0.500) total time=   0.4s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.507, test=0.506) total time=   0.3s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.496, test=0.506) total time=   0.2s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.741, test=0.724) total time=   1.1s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.762, test=0.760) total time=   2.0s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.766, test=0.770) total time=   2.0s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.727, test=0.698) total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.902, test=0.869) total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.855, test=0.838) total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.858, test=0.861) total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.856, test=0.833) total time= 1.6min\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.495) total time=   0.3s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.502) total time=   0.2s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.502) total time=   0.2s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.497, test=0.501) total time=   0.6s\n",
      "[CV 1/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.772, test=0.759) total time=   2.2s\n",
      "[CV 2/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.734, test=0.741) total time=   1.1s\n",
      "[CV 3/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.746, test=0.743) total time=   1.3s\n",
      "[CV 4/4] END activation=tanh, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.735, test=0.693) total time=   1.1s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.505, test=0.499) total time=   0.0s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.502, test=0.500) total time=   0.0s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.502, test=0.502) total time=   0.0s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.502) total time=   0.0s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.0s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.499) total time=   0.0s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.1s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.500, test=0.499) total time=   0.4s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.499, test=0.496) total time=   0.0s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.747, test=0.738) total time=   1.2s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.742, test=0.759) total time=   2.2s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.799, test=0.780) total time=   3.9s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.791, test=0.781) total time=   2.5s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.504, test=0.502) total time=   0.0s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.495) total time=   0.0s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.501) total time=   0.0s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.489) total time=   0.0s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.755, test=0.726) total time=   0.6s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.502, test=0.501) total time=   0.1s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.715, test=0.709) total time=   0.3s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.504, test=0.501) total time=   0.1s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.827, test=0.810) total time=  14.0s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.831, test=0.819) total time=  12.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.818, test=0.807) total time=  19.8s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.814, test=0.790) total time=  12.8s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.497, test=0.497) total time=   0.0s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.502) total time=   0.0s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.502) total time=   0.0s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.503, test=0.501) total time=   0.0s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.723, test=0.694) total time=   0.5s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.748, test=0.765) total time=   0.9s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.730, test=0.749) total time=   0.4s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.741, test=0.716) total time=   0.3s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.783, test=0.772) total time=  11.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.877, test=0.865) total time=  26.3s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.749, test=0.752) total time=   3.8s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.833, test=0.816) total time=  23.4s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.501) total time=   0.1s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.500) total time=   0.0s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.502) total time=   0.0s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.506, test=0.492) total time=   0.1s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.745, test=0.719) total time=   0.4s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.712, test=0.723) total time=   0.4s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.678, test=0.677) total time=   0.9s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.756, test=0.748) total time=   0.6s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.786, test=0.784) total time=  10.4s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.745, test=0.756) total time=   3.9s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.873, test=0.868) total time=  31.8s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.825, test=0.806) total time=  29.9s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.500) total time=   0.1s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.512, test=0.515) total time=   0.1s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.487) total time=   0.1s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.511) total time=   0.0s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.738, test=0.725) total time=   0.5s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.705, test=0.735) total time=   0.6s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.753, test=0.764) total time=   0.8s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.731, test=0.718) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.884, test=0.868) total time=  41.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.875, test=0.859) total time=  42.2s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.841, test=0.839) total time=  33.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.834, test=0.829) total time=  42.9s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.505, test=0.506) total time=   0.1s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.502) total time=   0.1s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.491) total time=   0.1s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.504, test=0.491) total time=   0.1s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.772, test=0.750) total time=   0.7s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.733, test=0.728) total time=   0.9s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.741, test=0.752) total time=   0.9s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.727, test=0.706) total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.840, test=0.828) total time=  58.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.853, test=0.831) total time=  57.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.864, test=0.846) total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.851, test=0.846) total time=  58.5s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.503, test=0.499) total time=   0.1s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.494) total time=   0.1s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.504) total time=   0.1s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.502) total time=   0.2s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.758, test=0.731) total time=   1.0s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.744, test=0.749) total time=   1.3s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.777, test=0.792) total time=   2.2s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.762, test=0.736) total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.865, test=0.805) total time= 1.1min\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.747, test=0.749) total time=  12.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.854, test=0.845) total time= 1.1min\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.791, test=0.777) total time=  20.5s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.504, test=0.515) total time=   0.1s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.495) total time=   0.2s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.505) total time=   0.3s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.505, test=0.501) total time=   0.2s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.757, test=0.751) total time=   1.1s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.726, test=0.746) total time=   1.3s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.765, test=0.779) total time=   1.1s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.757, test=0.750) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.842, test=0.836) total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.879, test=0.844) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.862, test=0.855) total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.856, test=0.845) total time= 1.2min\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.502) total time=   0.4s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.499) total time=   0.1s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.504) total time=   0.2s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.511) total time=   0.1s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.743, test=0.754) total time=   1.8s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.733, test=0.750) total time=   1.5s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.689, test=0.708) total time=   1.3s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.750, test=0.724) total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.881, test=0.844) total time= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.833, test=0.825) total time= 1.4min\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.831, test=0.839) total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.841, test=0.809) total time= 1.5min\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.503, test=0.497) total time=   0.3s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.505, test=0.506) total time=   0.2s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.494) total time=   0.3s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.507, test=0.505) total time=   0.1s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.701, test=0.679) total time=   0.9s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.736, test=0.755) total time=   1.6s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.750, test=0.752) total time=   1.4s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.724, test=0.720) total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.860, test=0.829) total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.845, test=0.834) total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.892, test=0.892) total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.881, test=0.861) total time= 1.6min\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.505) total time=   0.2s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.502) total time=   0.2s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.506, test=0.502) total time=   0.2s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.507, test=0.500) total time=   0.3s\n",
      "[CV 1/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.750, test=0.749) total time=   1.7s\n",
      "[CV 2/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.762, test=0.771) total time=   2.4s\n",
      "[CV 3/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.785, test=0.766) total time=   2.5s\n",
      "[CV 4/4] END activation=tanh, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.765, test=0.754) total time=   2.5s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.510, test=0.505) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.505, test=0.504) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.502, test=0.504) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.497) total time=   0.1s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.1s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.500, test=0.516) total time=   0.6s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.502, test=0.504) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.499, test=0.500) total time=   0.4s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.743, test=0.738) total time=   0.3s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.741, test=0.755) total time=   0.5s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.739, test=0.752) total time=   0.5s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.749, test=0.723) total time=   0.4s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.503, test=0.502) total time=   0.1s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.494) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.496, test=0.500) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.727, test=0.708) total time=   0.2s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.737, test=0.760) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.681, test=0.701) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.740, test=0.696) total time=   0.4s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.789, test=0.771) total time=   1.1s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.782, test=0.784) total time=   0.7s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.740, test=0.752) total time=   0.4s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.734, test=0.704) total time=   0.1s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.502) total time=   0.1s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.495) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.499) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.760, test=0.756) total time=   0.3s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.733, test=0.749) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.756, test=0.770) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.727, test=0.724) total time=   0.1s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.791, test=0.769) total time=   0.3s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.806, test=0.811) total time=   2.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.756, test=0.767) total time=   1.8s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.782, test=0.765) total time=   0.9s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.2s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.502) total time=   0.2s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.499) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.731, test=0.719) total time=   0.1s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.730, test=0.748) total time=   0.2s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.739, test=0.741) total time=   0.2s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.674, test=0.659) total time=   0.1s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.776, test=0.760) total time=   1.6s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.746, test=0.765) total time=   0.8s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.741, test=0.750) total time=   0.8s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.761, test=0.748) total time=   0.7s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.499) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.497) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.505) total time=   0.2s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.502) total time=   0.1s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.733, test=0.715) total time=   0.1s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.737, test=0.756) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.732, test=0.743) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.736, test=0.718) total time=   0.2s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.797, test=0.771) total time=   2.1s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.740, test=0.759) total time=   1.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.729, test=0.746) total time=   1.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.751, test=0.729) total time=   0.9s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.500) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.497) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.499) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.501) total time=   0.1s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.746, test=0.723) total time=   0.1s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.737, test=0.751) total time=   0.2s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.708, test=0.708) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.758, test=0.734) total time=   0.2s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.740, test=0.736) total time=   0.6s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.739, test=0.759) total time=   2.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.785, test=0.797) total time=   2.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.756, test=0.745) total time=   2.7s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.499) total time=   0.1s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.501) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.503, test=0.502) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.501) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.735, test=0.720) total time=   0.1s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.742, test=0.754) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.667, test=0.647) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.701, test=0.689) total time=   0.1s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.769, test=0.752) total time=   3.7s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.734, test=0.749) total time=   0.7s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.738, test=0.757) total time=   1.4s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.787, test=0.787) total time=   4.1s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.497) total time=   0.1s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.497) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.505) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.504, test=0.499) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.791, test=0.767) total time=   0.4s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.731, test=0.754) total time=   0.2s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.648, test=0.679) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.717, test=0.694) total time=   0.1s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.738, test=0.726) total time=   1.4s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.835, test=0.833) total time=   6.5s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.756, test=0.767) total time=   3.6s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.748, test=0.719) total time=   2.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.502) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.496) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.500) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.504) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.725, test=0.721) total time=   0.2s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.729, test=0.755) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.737, test=0.738) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.743, test=0.730) total time=   0.1s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.730, test=0.703) total time=   0.7s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.770, test=0.779) total time=   3.2s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.756, test=0.762) total time=   3.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.751, test=0.733) total time=   1.8s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.501) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.497) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.497) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.497, test=0.504) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.606, test=0.599) total time=   0.1s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.724, test=0.744) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.679, test=0.704) total time=   0.2s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.735, test=0.715) total time=   0.1s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.748, test=0.736) total time=   1.4s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.754, test=0.766) total time=   3.6s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.742, test=0.752) total time=   1.6s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.795, test=0.779) total time=   5.9s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.504, test=0.504) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.499) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.502) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.504, test=0.494) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.697, test=0.670) total time=   0.1s\n",
      "[CV 2/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.734, test=0.755) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.652, test=0.637) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.0001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.731, test=0.715) total time=   0.1s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.501, test=0.502) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.507, test=0.509) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=lbfgs;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.502) total time=   0.2s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.503, test=0.502) total time=   0.4s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.494, test=0.515) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.740, test=0.755) total time=   1.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=1, max_iter=5000, solver=adam;, score=(train=0.502, test=0.500) total time=   0.4s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.743, test=0.736) total time=   0.5s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.498, test=0.497) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.747, test=0.752) total time=   0.2s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=lbfgs;, score=(train=0.759, test=0.741) total time=   0.2s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.500) total time=   0.1s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.501) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.504) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.500) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.733, test=0.720) total time=   0.2s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.737, test=0.756) total time=   0.2s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.729, test=0.734) total time=   0.2s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=11, max_iter=5000, solver=adam;, score=(train=0.645, test=0.624) total time=   0.1s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.739, test=0.738) total time=   0.5s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.739, test=0.750) total time=   0.5s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.760, test=0.762) total time=   1.3s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=lbfgs;, score=(train=0.790, test=0.775) total time=   0.7s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.497) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.501) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.502) total time=   0.2s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.717, test=0.704) total time=   0.1s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.739, test=0.764) total time=   0.2s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.745, test=0.745) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=21, max_iter=5000, solver=adam;, score=(train=0.675, test=0.665) total time=   0.2s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.792, test=0.772) total time=   2.3s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.757, test=0.767) total time=   0.4s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.750, test=0.766) total time=   1.2s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=lbfgs;, score=(train=0.752, test=0.715) total time=   0.1s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.500) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.500) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.496) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.706, test=0.691) total time=   0.2s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.734, test=0.745) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.751, test=0.745) total time=   0.2s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=31, max_iter=5000, solver=adam;, score=(train=0.726, test=0.688) total time=   0.1s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.741, test=0.739) total time=   0.7s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.777, test=0.785) total time=   1.5s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.766, test=0.770) total time=   0.9s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=lbfgs;, score=(train=0.750, test=0.724) total time=   0.7s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.497) total time=   0.1s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.501) total time=   0.6s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.497) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.500) total time=   0.2s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.726, test=0.703) total time=   0.1s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.730, test=0.740) total time=   0.2s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.732, test=0.745) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=41, max_iter=5000, solver=adam;, score=(train=0.749, test=0.729) total time=   0.2s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.783, test=0.766) total time=   0.6s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.758, test=0.769) total time=   1.8s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.829, test=0.828) total time=   6.6s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=lbfgs;, score=(train=0.746, test=0.715) total time=   0.3s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.502) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.497) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.500) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=sgd;, score=(train=0.497, test=0.505) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.729, test=0.700) total time=   0.1s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.710, test=0.736) total time=   0.2s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.739, test=0.746) total time=   0.2s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=51, max_iter=5000, solver=adam;, score=(train=0.652, test=0.646) total time=   0.1s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.763, test=0.744) total time=   1.7s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.773, test=0.795) total time=   4.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.794, test=0.794) total time=   3.8s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=lbfgs;, score=(train=0.820, test=0.819) total time=   3.7s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.497, test=0.497) total time=   0.1s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.499) total time=   0.2s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.501) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.496) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.742, test=0.719) total time=   0.1s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.719, test=0.745) total time=   0.2s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.733, test=0.729) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=61, max_iter=5000, solver=adam;, score=(train=0.706, test=0.698) total time=   0.1s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.744, test=0.738) total time=   1.3s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.772, test=0.785) total time=   3.5s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.734, test=0.749) total time=   1.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=lbfgs;, score=(train=0.799, test=0.782) total time=   3.1s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.501) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.503, test=0.501) total time=   0.2s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.501) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=sgd;, score=(train=0.503, test=0.501) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.748, test=0.729) total time=   0.2s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.615, test=0.624) total time=   0.3s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.671, test=0.698) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=71, max_iter=5000, solver=adam;, score=(train=0.675, test=0.674) total time=   0.2s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.734, test=0.721) total time=   0.8s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.816, test=0.802) total time=   5.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.730, test=0.744) total time=   1.2s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=lbfgs;, score=(train=0.851, test=0.856) total time=  11.6s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.500, test=0.500) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.502) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.496) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=sgd;, score=(train=0.503, test=0.494) total time=   0.3s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.743, test=0.731) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.713, test=0.739) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.644, test=0.665) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=81, max_iter=5000, solver=adam;, score=(train=0.721, test=0.713) total time=   0.1s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.736, test=0.728) total time=   2.8s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.732, test=0.749) total time=   1.6s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.759, test=0.772) total time=   2.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=lbfgs;, score=(train=0.737, test=0.711) total time=   0.6s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.502, test=0.504) total time=   0.1s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.497) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.500) total time=   0.0s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=sgd;, score=(train=0.501, test=0.499) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.608, test=0.600) total time=   0.1s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.678, test=0.682) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.647, test=0.676) total time=   0.2s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=91, max_iter=5000, solver=adam;, score=(train=0.647, test=0.641) total time=   0.1s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.782, test=0.774) total time=   4.1s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.743, test=0.755) total time=   3.2s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.763, test=0.771) total time=   3.9s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=lbfgs;, score=(train=0.768, test=0.755) total time=   1.9s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.498, test=0.499) total time=   0.0s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.499, test=0.497) total time=   0.0s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.503, test=0.504) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=sgd;, score=(train=0.503, test=0.500) total time=   0.0s\n",
      "[CV 1/4] END activation=relu, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.738, test=0.719) total time=   0.2s\n",
      "[CV 2/4] END activation=relu, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.705, test=0.724) total time=   0.1s\n",
      "[CV 3/4] END activation=relu, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.726, test=0.746) total time=   0.1s\n",
      "[CV 4/4] END activation=relu, alpha=0.001, hidden_layer_sizes=101, max_iter=5000, solver=adam;, score=(train=0.736, test=0.721) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4,\n",
       "             estimator=MLPClassifier(activation=&#x27;logistic&#x27;,\n",
       "                                     hidden_layer_sizes=91, max_iter=2000),\n",
       "             param_grid={&#x27;activation&#x27;: [&#x27;identity&#x27;, &#x27;logistic&#x27;, &#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                         &#x27;alpha&#x27;: [0.0001, 0.001],\n",
       "                         &#x27;hidden_layer_sizes&#x27;: range(1, 110, 10),\n",
       "                         &#x27;max_iter&#x27;: [5000],\n",
       "                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;sgd&#x27;, &#x27;adam&#x27;]},\n",
       "             return_train_score=True, verbose=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=4,\n",
       "             estimator=MLPClassifier(activation=&#x27;logistic&#x27;,\n",
       "                                     hidden_layer_sizes=91, max_iter=2000),\n",
       "             param_grid={&#x27;activation&#x27;: [&#x27;identity&#x27;, &#x27;logistic&#x27;, &#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                         &#x27;alpha&#x27;: [0.0001, 0.001],\n",
       "                         &#x27;hidden_layer_sizes&#x27;: range(1, 110, 10),\n",
       "                         &#x27;max_iter&#x27;: [5000],\n",
       "                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;sgd&#x27;, &#x27;adam&#x27;]},\n",
       "             return_train_score=True, verbose=5)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: MLPClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, hidden_layer_sizes=91, max_iter=2000)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MLPClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, hidden_layer_sizes=91, max_iter=2000)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=4,\n",
       "             estimator=MLPClassifier(activation='logistic',\n",
       "                                     hidden_layer_sizes=91, max_iter=2000),\n",
       "             param_grid={'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
       "                         'alpha': [0.0001, 0.001],\n",
       "                         'hidden_layer_sizes': range(1, 110, 10),\n",
       "                         'max_iter': [5000],\n",
       "                         'solver': ['lbfgs', 'sgd', 'adam']},\n",
       "             return_train_score=True, verbose=5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X1_train,y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ca7a1a3-1895-42eb-8225-05c782c86220",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = grid_search.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb0dd580-cd0a-480b-a592-8293cf2eb690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([3.82063985e-02, 3.81386876e-02, 8.10539365e-01, 2.34503984e-01,\n",
       "        6.18968606e-02, 2.27121294e-01, 4.26437378e-01, 5.91836572e-02,\n",
       "        1.81339502e-01, 6.22371256e-01, 5.25789261e-02, 1.69988513e-01,\n",
       "        6.11941516e-01, 6.61829710e-02, 1.48172319e-01, 5.22558928e-01,\n",
       "        6.86417222e-02, 2.07422495e-01, 9.52369392e-01, 7.14029670e-02,\n",
       "        1.74502194e-01, 1.07588679e+00, 5.80637455e-02, 1.53011322e-01,\n",
       "        1.52885091e+00, 6.41245246e-02, 1.22339666e-01, 1.50386161e+00,\n",
       "        6.41506314e-02, 1.35604322e-01, 1.39668328e+00, 7.62841105e-02,\n",
       "        1.48469865e-01, 3.29021811e-02, 5.01502156e-02, 6.39268219e-01,\n",
       "        8.34055543e-02, 4.93279099e-02, 2.34677196e-01, 3.23097408e-01,\n",
       "        4.55102921e-02, 1.72164559e-01, 3.33960116e-01, 4.81677651e-02,\n",
       "        1.53690159e-01, 4.50394630e-01, 5.88775873e-02, 1.46052122e-01,\n",
       "        3.87191534e-01, 6.14075065e-02, 1.46342993e-01, 1.39696443e+00,\n",
       "        7.29018450e-02, 1.66296303e-01, 9.12469745e-01, 5.81027269e-02,\n",
       "        1.14196837e-01, 1.17363757e+00, 1.01151109e-01, 1.98164344e-01,\n",
       "        1.40969187e+00, 6.07007146e-02, 1.30817890e-01, 1.51431733e+00,\n",
       "        6.58013821e-02, 1.49455190e-01, 6.45241141e-02, 1.11049354e-01,\n",
       "        3.87258410e-01, 3.69581765e+00, 8.15946460e-02, 4.91348922e-01,\n",
       "        1.31107861e+01, 7.94048309e-02, 5.14166296e-01, 1.61946611e+01,\n",
       "        7.56422877e-02, 5.09396553e-01, 1.81894092e+01, 9.34096575e-02,\n",
       "        1.18841338e+00, 2.13201270e+01, 8.68225694e-02, 9.43111181e-01,\n",
       "        3.56911173e+01, 8.88386369e-02, 7.51604199e-01, 3.91634414e+01,\n",
       "        1.34032726e-01, 1.08186436e+00, 4.74109424e+01, 1.09260917e-01,\n",
       "        1.44484365e+00, 4.66536022e+01, 1.06053531e-01, 8.92318010e-01,\n",
       "        5.12134172e+01, 1.32381737e-01, 1.13007975e+00, 1.29137814e-01,\n",
       "        1.15652144e-01, 1.24910593e-01, 6.99352175e+00, 8.46411586e-02,\n",
       "        9.90176618e-01, 1.20170741e+01, 8.46666098e-02, 4.71223056e-01,\n",
       "        8.84730291e+00, 7.85191059e-02, 7.51340389e-01, 2.24046072e+01,\n",
       "        8.55195522e-02, 7.61099458e-01, 2.21483451e+01, 1.01391733e-01,\n",
       "        7.91943908e-01, 3.94117634e+01, 1.14281058e-01, 1.58344358e+00,\n",
       "        3.17916731e+01, 1.17170393e-01, 6.56606317e-01, 4.59197987e+01,\n",
       "        1.13476992e-01, 1.08043438e+00, 5.38110769e+01, 1.46418154e-01,\n",
       "        7.78504133e-01, 5.75147953e+01, 1.49410188e-01, 1.18768644e+00,\n",
       "        8.26632977e-03, 1.28800690e-01, 2.37139463e-01, 3.13357741e+00,\n",
       "        9.85236764e-02, 4.85248744e-01, 5.83578038e+00, 1.15647852e-01,\n",
       "        4.89233434e-01, 1.42133249e+01, 1.32451594e-01, 7.66033351e-01,\n",
       "        3.33724137e+01, 1.80186570e-01, 1.21801615e+00, 4.18297424e+01,\n",
       "        2.12665796e-01, 1.16209060e+00, 4.69822890e+01, 1.89573586e-01,\n",
       "        1.62451327e+00, 5.40729502e+01, 2.60392427e-01, 1.17987311e+00,\n",
       "        7.54962793e+01, 2.31331408e-01, 1.10982203e+00, 8.46816175e+01,\n",
       "        4.08463001e-01, 1.54898971e+00, 9.31780069e+01, 4.07244682e-01,\n",
       "        1.50782347e+00, 2.16405392e-02, 1.44521713e-01, 2.00491250e-01,\n",
       "        2.54089212e+00, 9.11387205e-02, 3.47170234e-01, 1.49034912e+01,\n",
       "        1.08748496e-01, 6.32242322e-01, 1.63558274e+01, 1.46967351e-01,\n",
       "        6.63884819e-01, 1.90824303e+01, 1.68135703e-01, 8.12236011e-01,\n",
       "        3.99738332e+01, 2.05440879e-01, 8.73161495e-01, 5.90377356e+01,\n",
       "        2.43419766e-01, 1.69904530e+00, 4.18338186e+01, 2.65437424e-01,\n",
       "        1.25903082e+00, 7.62567198e+01, 3.00529838e-01, 1.42767942e+00,\n",
       "        8.02001219e+01, 3.04644823e-01, 1.24928880e+00, 9.45671484e+01,\n",
       "        3.53107393e-01, 2.36404645e+00, 3.41994762e-02, 1.83800578e-01,\n",
       "        3.60622108e-01, 5.18367290e-01, 1.58965766e-01, 2.77988732e-01,\n",
       "        6.91509604e-01, 1.03867412e-01, 2.65069187e-01, 1.37770683e+00,\n",
       "        1.59475565e-01, 2.30664670e-01, 1.07142609e+00, 2.07807899e-01,\n",
       "        2.19029903e-01, 1.37972587e+00, 1.53636813e-01, 2.38988996e-01,\n",
       "        1.92584789e+00, 1.37774587e-01, 1.95826709e-01, 2.58696592e+00,\n",
       "        1.62859678e-01, 2.91364670e-01, 3.47855926e+00, 8.42590928e-02,\n",
       "        2.18594432e-01, 2.26270241e+00, 1.23116553e-01, 2.01028228e-01,\n",
       "        3.20435798e+00, 7.28139281e-02, 1.74970448e-01, 1.63823366e-02,\n",
       "        2.05815375e-01, 5.69200993e-01, 3.16784561e-01, 1.23548210e-01,\n",
       "        2.49830067e-01, 8.48347247e-01, 2.02338576e-01, 2.45439529e-01,\n",
       "        1.08854395e+00, 5.56229353e-02, 2.61342943e-01, 1.05804354e+00,\n",
       "        3.60412061e-01, 2.55457819e-01, 2.44015664e+00, 1.06685042e-01,\n",
       "        2.61543274e-01, 3.37457442e+00, 1.97359145e-01, 2.06189513e-01,\n",
       "        2.34545499e+00, 1.62482440e-01, 3.03730369e-01, 4.74872053e+00,\n",
       "        2.21788287e-01, 1.92065537e-01, 1.89041203e+00, 1.41408026e-01,\n",
       "        2.04855204e-01, 3.36824840e+00, 9.90292430e-02, 1.83535695e-01]),\n",
       " 'std_fit_time': array([3.06643784e-02, 5.17512570e-03, 4.29354432e-01, 1.44308755e-01,\n",
       "        2.96156190e-03, 8.09051270e-02, 1.55265958e-01, 6.62248313e-03,\n",
       "        3.67771875e-02, 3.07590915e-01, 3.84569655e-03, 1.42610623e-02,\n",
       "        1.66804887e-01, 1.48646993e-02, 2.83370459e-02, 3.69922191e-01,\n",
       "        5.85455148e-03, 5.34502647e-02, 3.43327005e-01, 1.25980810e-02,\n",
       "        3.04641186e-02, 4.60983838e-01, 1.15883057e-03, 1.94412077e-02,\n",
       "        6.70775901e-01, 7.30289924e-03, 1.37056935e-02, 3.94056558e-01,\n",
       "        1.94288359e-03, 3.98411020e-02, 3.72195293e-01, 3.27122250e-03,\n",
       "        1.87129433e-02, 2.51619336e-02, 6.36058225e-03, 1.16181505e-01,\n",
       "        1.12152894e-01, 3.91432027e-03, 6.22510929e-02, 2.08512689e-01,\n",
       "        2.76835505e-03, 2.57828909e-02, 1.96407405e-01, 3.11236456e-03,\n",
       "        3.27598570e-02, 2.40717375e-01, 3.00201283e-03, 3.68265175e-02,\n",
       "        2.34481355e-01, 2.51986773e-03, 5.18651188e-03, 7.37975968e-01,\n",
       "        4.88360857e-03, 4.41696471e-02, 3.50682141e-01, 4.28302644e-03,\n",
       "        3.22177737e-02, 4.99982743e-01, 1.29161439e-02, 7.24376267e-02,\n",
       "        7.06071002e-01, 5.37951186e-03, 8.74762048e-03, 1.07720748e+00,\n",
       "        9.15275152e-03, 1.77340752e-02, 6.74138077e-02, 5.37081276e-02,\n",
       "        2.20021679e-01, 2.94404490e+00, 1.53234020e-02, 8.36504676e-02,\n",
       "        3.20664295e+00, 1.69410910e-02, 1.19361289e-01, 5.80402443e+00,\n",
       "        1.34294419e-02, 1.20866823e-01, 9.79460091e+00, 1.29118910e-02,\n",
       "        4.39203173e-01, 1.13602480e+01, 5.71567837e-03, 6.94292833e-02,\n",
       "        7.56170644e+00, 1.32536968e-02, 1.76099323e-01, 5.54398765e+00,\n",
       "        2.05874764e-02, 3.11733017e-01, 9.13501850e+00, 3.45168612e-02,\n",
       "        6.20685346e-01, 2.29361888e+00, 4.34131704e-03, 6.31248650e-01,\n",
       "        3.60352293e+00, 2.50876899e-02, 9.73465651e-01, 1.15898369e-01,\n",
       "        6.58158379e-02, 8.24305762e-02, 1.31887118e+00, 9.41738304e-03,\n",
       "        2.64945550e-01, 3.28328263e+00, 2.54735352e-03, 1.05296103e-01,\n",
       "        6.11981501e+00, 9.82771738e-03, 3.53420372e-01, 2.77775384e+00,\n",
       "        5.03593191e-03, 2.01678183e-01, 4.45535962e+00, 2.25881374e-02,\n",
       "        3.52245796e-01, 4.88960612e+00, 1.69870766e-02, 6.70762769e-01,\n",
       "        1.63434767e+01, 1.93800651e-02, 3.60022794e-01, 8.60872336e+00,\n",
       "        8.51884902e-03, 3.68871690e-01, 1.25846693e+01, 4.28039100e-02,\n",
       "        3.79403271e-01, 4.81031264e+00, 3.90989272e-02, 6.89160456e-01,\n",
       "        1.30749368e-03, 4.98463763e-02, 1.24443178e-01, 1.91804874e+00,\n",
       "        1.23921582e-02, 2.36690370e-01, 5.90568819e+00, 1.33830653e-02,\n",
       "        1.73244833e-01, 1.02668745e+01, 2.38521701e-02, 1.38258183e-01,\n",
       "        2.73291133e+00, 2.66675468e-02, 1.62442525e-01, 1.69218157e+00,\n",
       "        4.65788275e-02, 5.59624589e-01, 2.12265947e+01, 2.04928701e-02,\n",
       "        3.69830301e-01, 1.31469019e+01, 4.87023503e-02, 2.42083918e-01,\n",
       "        3.62995998e-01, 1.72641313e-02, 3.19147768e-01, 1.03566211e+00,\n",
       "        8.10705749e-02, 5.65366764e-01, 8.34065849e-01, 1.67293058e-01,\n",
       "        4.35895873e-01, 6.57015340e-03, 1.67435336e-02, 1.55509903e-01,\n",
       "        9.66546190e-01, 1.97282582e-02, 2.05250992e-01, 2.91300404e+00,\n",
       "        1.11299805e-02, 2.32705361e-01, 9.06350211e+00, 1.82479324e-02,\n",
       "        1.94117838e-01, 1.20887811e+01, 3.61361420e-02, 1.60582831e-01,\n",
       "        3.97874610e+00, 3.49115331e-02, 1.15629039e-01, 1.05366847e+00,\n",
       "        3.75959065e-02, 5.05593635e-01, 2.54686617e+01, 6.61149839e-02,\n",
       "        8.53247297e-02, 1.80427067e+00, 8.84508063e-02, 3.95432665e-01,\n",
       "        1.06541152e+01, 7.00092526e-02, 3.65596116e-01, 9.79390627e-01,\n",
       "        4.41039697e-02, 3.48365686e-01, 1.82590034e-02, 3.77036288e-02,\n",
       "        2.39189821e-01, 7.78683354e-02, 6.38056888e-02, 1.04904822e-01,\n",
       "        3.64253879e-01, 7.16055229e-02, 6.95682268e-02, 7.24333841e-01,\n",
       "        9.79827124e-02, 4.50511013e-02, 3.41984646e-01, 5.67558051e-02,\n",
       "        2.78654471e-02, 4.63369159e-01, 5.69348850e-02, 5.39114716e-02,\n",
       "        7.74290715e-01, 3.43252423e-02, 2.70649854e-02, 1.45751630e+00,\n",
       "        6.07227140e-02, 1.41536620e-01, 1.98471806e+00, 1.48444258e-02,\n",
       "        3.26799895e-02, 1.00400325e+00, 5.40485002e-02, 4.32412518e-02,\n",
       "        1.81289831e+00, 9.09617968e-03, 3.09559614e-02, 1.39629662e-02,\n",
       "        6.35568449e-02, 3.77322451e-01, 2.18397392e-01, 4.54127872e-02,\n",
       "        5.19631314e-02, 3.14211087e-01, 5.51121604e-02, 5.80049307e-02,\n",
       "        8.30809805e-01, 1.23105574e-02, 6.16619788e-02, 3.43847774e-01,\n",
       "        1.92495339e-01, 3.75126181e-02, 2.51591137e+00, 4.97394365e-02,\n",
       "        5.86911542e-02, 9.29868323e-01, 7.45758888e-02, 4.00020993e-02,\n",
       "        1.08566732e+00, 6.69375888e-02, 8.18079870e-02, 4.33652243e+00,\n",
       "        1.24512276e-01, 3.97672291e-02, 8.04361976e-01, 7.32068861e-02,\n",
       "        3.11842306e-02, 8.77754056e-01, 4.78364908e-02, 5.33364514e-02]),\n",
       " 'mean_score_time': array([0.00276738, 0.00262862, 0.00261199, 0.00272661, 0.00375205,\n",
       "        0.0027529 , 0.00324935, 0.003613  , 0.0032416 , 0.00275445,\n",
       "        0.00301075, 0.00397795, 0.00250024, 0.00299275, 0.00224483,\n",
       "        0.00299978, 0.00375593, 0.00350118, 0.00387847, 0.00324357,\n",
       "        0.00325513, 0.00325418, 0.00324792, 0.0029996 , 0.00321692,\n",
       "        0.0032599 , 0.00347894, 0.00303286, 0.00300068, 0.00301111,\n",
       "        0.00249875, 0.00325286, 0.0037508 , 0.00285721, 0.00406379,\n",
       "        0.00225341, 0.00225091, 0.00249672, 0.00298125, 0.00238425,\n",
       "        0.00325143, 0.00249726, 0.00274831, 0.00251871, 0.00300467,\n",
       "        0.00300074, 0.0037533 , 0.00275022, 0.00275183, 0.00323951,\n",
       "        0.00249952, 0.00325125, 0.00300252, 0.00324816, 0.00338185,\n",
       "        0.00300086, 0.00350684, 0.00300062, 0.00450289, 0.00427359,\n",
       "        0.00299841, 0.00250214, 0.00350422, 0.00374824, 0.00373876,\n",
       "        0.00299567, 0.0029946 , 0.00262684, 0.00250357, 0.00375867,\n",
       "        0.0030219 , 0.00247842, 0.00322384, 0.00325108, 0.00197715,\n",
       "        0.0036363 , 0.0034982 , 0.00294584, 0.00400174, 0.0031265 ,\n",
       "        0.00324464, 0.0046339 , 0.00299299, 0.00299925, 0.00449103,\n",
       "        0.00325418, 0.00300205, 0.00453019, 0.00327957, 0.00325513,\n",
       "        0.00475782, 0.00363266, 0.00377744, 0.00450003, 0.00341022,\n",
       "        0.00425106, 0.0042488 , 0.00374001, 0.00487834, 0.00251544,\n",
       "        0.00325972, 0.00275022, 0.00274998, 0.00320566, 0.00322127,\n",
       "        0.00325179, 0.00225431, 0.00292623, 0.00399977, 0.00350177,\n",
       "        0.00293207, 0.00397217, 0.00324374, 0.00399625, 0.00425529,\n",
       "        0.00324988, 0.00324643, 0.00399834, 0.0032534 , 0.00475055,\n",
       "        0.00453627, 0.00349921, 0.00374871, 0.00474906, 0.00349724,\n",
       "        0.00374889, 0.00449914, 0.00399119, 0.00375146, 0.00502002,\n",
       "        0.00397766, 0.00350386, 0.00199497, 0.00302398, 0.00251549,\n",
       "        0.00350505, 0.00300139, 0.00296521, 0.00362164, 0.00400227,\n",
       "        0.00318217, 0.0044927 , 0.00349975, 0.00370681, 0.00449252,\n",
       "        0.00461751, 0.00487471, 0.00537574, 0.00514781, 0.00477213,\n",
       "        0.00509959, 0.00523049, 0.00575155, 0.00637484, 0.00674713,\n",
       "        0.00599957, 0.00699371, 0.00562602, 0.00649947, 0.00672853,\n",
       "        0.00663143, 0.00750631, 0.00683147, 0.0063864 , 0.00702184,\n",
       "        0.00225049, 0.00275207, 0.00274771, 0.00375122, 0.00325012,\n",
       "        0.00322562, 0.00348502, 0.00339812, 0.00372851, 0.00400633,\n",
       "        0.00450045, 0.00375062, 0.00477314, 0.00447702, 0.00471926,\n",
       "        0.00526184, 0.00497627, 0.00500083, 0.00475353, 0.00500119,\n",
       "        0.00587827, 0.00575101, 0.00800604, 0.00574994, 0.00609285,\n",
       "        0.00625277, 0.00601768, 0.00662297, 0.00615239, 0.00699723,\n",
       "        0.00776058, 0.00650114, 0.00738406, 0.00425458, 0.00300145,\n",
       "        0.00246942, 0.00249934, 0.00298291, 0.00264734, 0.00270581,\n",
       "        0.00323039, 0.00243407, 0.00300086, 0.00322264, 0.00271505,\n",
       "        0.00235897, 0.00227219, 0.0025025 , 0.00318825, 0.00312704,\n",
       "        0.00299948, 0.00325048, 0.00350887, 0.00325322, 0.0032711 ,\n",
       "        0.0030055 , 0.00275028, 0.00325328, 0.0027324 , 0.00275379,\n",
       "        0.00314319, 0.00300133, 0.00275713, 0.00248647, 0.00425315,\n",
       "        0.00347531, 0.00175077, 0.0025084 , 0.00203365, 0.00324488,\n",
       "        0.00299937, 0.00222874, 0.0032503 , 0.00248039, 0.00268167,\n",
       "        0.0032509 , 0.00247842, 0.00274253, 0.00302142, 0.00288284,\n",
       "        0.0027504 , 0.00299293, 0.00275153, 0.00325114, 0.00287884,\n",
       "        0.00298572, 0.00300109, 0.00300241, 0.00304842, 0.00237745,\n",
       "        0.0037232 , 0.00299978, 0.0028789 , 0.00299996, 0.00275314,\n",
       "        0.00301266, 0.00299978, 0.00275171, 0.00274438]),\n",
       " 'std_score_time': array([4.48897150e-04, 6.50299347e-04, 3.95869210e-04, 4.21085394e-04,\n",
       "        8.24729538e-04, 4.35397973e-04, 4.33930538e-04, 4.17134239e-04,\n",
       "        4.35107583e-04, 4.35605914e-04, 7.01221305e-04, 1.24337383e-03,\n",
       "        4.99799369e-04, 7.07267951e-04, 4.22107907e-04, 7.05033208e-04,\n",
       "        8.24943400e-04, 4.99017206e-04, 8.93485840e-04, 4.33117306e-04,\n",
       "        4.31738986e-04, 4.41999207e-04, 4.36550713e-04, 7.07140751e-04,\n",
       "        4.41479219e-04, 1.09903749e-03, 4.76560792e-04, 4.35886856e-05,\n",
       "        1.25453265e-06, 6.89800338e-04, 4.99129865e-04, 4.31450501e-04,\n",
       "        4.30850937e-04, 5.45490846e-04, 1.31813017e-03, 4.31745848e-04,\n",
       "        4.34564446e-04, 4.96204769e-04, 7.09296402e-04, 4.25090578e-04,\n",
       "        4.32025468e-04, 5.01587287e-04, 4.31870409e-04, 4.80676583e-04,\n",
       "        1.21295086e-05, 3.95372485e-06, 8.30537160e-04, 4.33635367e-04,\n",
       "        4.34852646e-04, 4.27292807e-04, 8.66410400e-04, 8.29224589e-04,\n",
       "        7.12961361e-04, 4.18148717e-04, 6.40068690e-04, 7.08330614e-04,\n",
       "        4.92976332e-04, 7.06297576e-04, 5.01085341e-04, 8.04597488e-04,\n",
       "        7.06803939e-04, 5.02180515e-04, 4.95678745e-04, 4.34598761e-04,\n",
       "        8.24971944e-04, 7.06928604e-04, 7.07365452e-04, 4.11422204e-04,\n",
       "        5.02889934e-04, 1.14809577e-03, 7.43344958e-04, 4.80690389e-04,\n",
       "        8.06768124e-04, 4.34569417e-04, 3.69126998e-05, 6.48631019e-04,\n",
       "        5.01777418e-04, 3.68008847e-05, 7.08321225e-04, 7.40698582e-04,\n",
       "        4.26307120e-04, 6.59202516e-04, 7.02455798e-04, 9.99152749e-04,\n",
       "        8.73078230e-04, 1.08888217e-03, 7.06808123e-04, 3.84053518e-04,\n",
       "        4.33811056e-04, 4.42548139e-04, 8.32816273e-04, 4.04253606e-04,\n",
       "        1.00223379e-03, 5.01156888e-04, 7.08421993e-04, 8.28251566e-04,\n",
       "        4.30477813e-04, 8.37229770e-04, 1.02774200e-03, 9.16370989e-04,\n",
       "        4.42950228e-04, 4.32947113e-04, 4.33084654e-04, 6.77645277e-04,\n",
       "        4.49697133e-04, 4.35666328e-04, 4.41550770e-04, 4.42953553e-05,\n",
       "        2.14824930e-06, 4.99013802e-04, 3.99125092e-05, 4.16313590e-05,\n",
       "        4.36714292e-04, 6.40743001e-06, 1.08724128e-03, 4.33050154e-04,\n",
       "        4.33895302e-04, 7.06975360e-04, 4.39004402e-04, 8.30445373e-04,\n",
       "        5.40150867e-04, 4.99071093e-04, 4.43764690e-04, 4.32784134e-04,\n",
       "        5.07051034e-04, 4.34151395e-04, 4.99190957e-04, 1.11055146e-05,\n",
       "        4.34261440e-04, 7.07514565e-04, 7.11297457e-04, 5.02844916e-04,\n",
       "        6.83247084e-06, 4.23612521e-05, 4.68227848e-04, 4.96141455e-04,\n",
       "        5.98671319e-05, 3.61670061e-05, 4.08395242e-04, 1.79483234e-05,\n",
       "        4.23256204e-04, 1.12150950e-03, 5.01521203e-04, 4.09846478e-04,\n",
       "        5.05927062e-04, 1.75779065e-03, 5.45945724e-04, 9.60193784e-04,\n",
       "        5.31531364e-04, 4.53295118e-04, 1.71069058e-04, 4.45781361e-04,\n",
       "        4.33705394e-04, 4.21502774e-04, 1.08767816e-03, 1.22587374e-03,\n",
       "        1.71915877e-03, 6.52962730e-04, 5.00146019e-04, 8.24169379e-04,\n",
       "        4.04987815e-04, 1.46324372e-03, 7.43356753e-04, 4.07479550e-04,\n",
       "        1.02029509e-03, 4.32603117e-04, 4.37073053e-04, 3.81407113e-04,\n",
       "        8.30844131e-04, 4.33190287e-04, 4.49260555e-04, 4.85211518e-04,\n",
       "        4.20640156e-04, 4.69047988e-04, 7.07984891e-04, 4.99904248e-04,\n",
       "        4.32122851e-04, 8.04497190e-04, 4.78164940e-04, 8.02971245e-04,\n",
       "        5.66070991e-04, 6.73423079e-04, 1.22382926e-03, 4.35577804e-04,\n",
       "        7.07477767e-04, 1.02826603e-03, 4.33687803e-04, 1.88152869e-03,\n",
       "        4.32912569e-04, 5.52390852e-04, 8.26689048e-04, 6.74725737e-04,\n",
       "        6.69844696e-04, 5.34013471e-04, 7.10236592e-04, 8.21782938e-04,\n",
       "        4.99547844e-04, 9.70837600e-04, 1.77364049e-03, 7.06634359e-04,\n",
       "        4.88326315e-04, 4.99131872e-04, 4.50987429e-05, 4.07600509e-04,\n",
       "        8.19877174e-04, 4.47969457e-04, 5.17772135e-04, 7.07310988e-04,\n",
       "        1.65067615e-03, 4.78798776e-04, 4.38178725e-04, 4.71696303e-04,\n",
       "        8.52880317e-04, 7.61522686e-04, 5.44913848e-04, 3.33093453e-06,\n",
       "        1.29867112e-03, 5.18679150e-04, 4.34024538e-04, 4.70632931e-04,\n",
       "        7.00995690e-04, 8.31905570e-04, 4.40174918e-04, 4.23589859e-04,\n",
       "        8.32762162e-04, 9.20255589e-04, 7.08404661e-04, 8.36512580e-04,\n",
       "        5.14733178e-04, 2.17516436e-03, 5.25689084e-04, 4.33776753e-04,\n",
       "        4.92086157e-04, 6.90796909e-04, 4.32258637e-04, 7.06213507e-04,\n",
       "        4.46584252e-04, 4.33635204e-04, 4.90292649e-04, 3.94144037e-04,\n",
       "        8.29474245e-04, 5.26632841e-04, 4.28917144e-04, 3.72003184e-05,\n",
       "        1.02253063e-03, 8.27622716e-04, 1.09469898e-05, 4.33295198e-04,\n",
       "        8.30627069e-04, 7.37718622e-04, 7.05961781e-04, 3.03691368e-06,\n",
       "        7.12118301e-04, 8.09695260e-05, 6.39481995e-04, 4.18486257e-04,\n",
       "        3.89214223e-06, 5.48674479e-04, 7.07308434e-04, 4.34789553e-04,\n",
       "        1.00687754e-05, 2.09889613e-06, 4.34088331e-04, 4.29953729e-04]),\n",
       " 'param_activation': masked_array(data=['identity', 'identity', 'identity', 'identity',\n",
       "                    'identity', 'identity', 'identity', 'identity',\n",
       "                    'identity', 'identity', 'identity', 'identity',\n",
       "                    'identity', 'identity', 'identity', 'identity',\n",
       "                    'identity', 'identity', 'identity', 'identity',\n",
       "                    'identity', 'identity', 'identity', 'identity',\n",
       "                    'identity', 'identity', 'identity', 'identity',\n",
       "                    'identity', 'identity', 'identity', 'identity',\n",
       "                    'identity', 'identity', 'identity', 'identity',\n",
       "                    'identity', 'identity', 'identity', 'identity',\n",
       "                    'identity', 'identity', 'identity', 'identity',\n",
       "                    'identity', 'identity', 'identity', 'identity',\n",
       "                    'identity', 'identity', 'identity', 'identity',\n",
       "                    'identity', 'identity', 'identity', 'identity',\n",
       "                    'identity', 'identity', 'identity', 'identity',\n",
       "                    'identity', 'identity', 'identity', 'identity',\n",
       "                    'identity', 'identity', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_alpha': masked_array(data=[0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_hidden_layer_sizes': masked_array(data=[1, 1, 1, 11, 11, 11, 21, 21, 21, 31, 31, 31, 41, 41,\n",
       "                    41, 51, 51, 51, 61, 61, 61, 71, 71, 71, 81, 81, 81, 91,\n",
       "                    91, 91, 101, 101, 101, 1, 1, 1, 11, 11, 11, 21, 21, 21,\n",
       "                    31, 31, 31, 41, 41, 41, 51, 51, 51, 61, 61, 61, 71, 71,\n",
       "                    71, 81, 81, 81, 91, 91, 91, 101, 101, 101, 1, 1, 1, 11,\n",
       "                    11, 11, 21, 21, 21, 31, 31, 31, 41, 41, 41, 51, 51, 51,\n",
       "                    61, 61, 61, 71, 71, 71, 81, 81, 81, 91, 91, 91, 101,\n",
       "                    101, 101, 1, 1, 1, 11, 11, 11, 21, 21, 21, 31, 31, 31,\n",
       "                    41, 41, 41, 51, 51, 51, 61, 61, 61, 71, 71, 71, 81, 81,\n",
       "                    81, 91, 91, 91, 101, 101, 101, 1, 1, 1, 11, 11, 11, 21,\n",
       "                    21, 21, 31, 31, 31, 41, 41, 41, 51, 51, 51, 61, 61, 61,\n",
       "                    71, 71, 71, 81, 81, 81, 91, 91, 91, 101, 101, 101, 1,\n",
       "                    1, 1, 11, 11, 11, 21, 21, 21, 31, 31, 31, 41, 41, 41,\n",
       "                    51, 51, 51, 61, 61, 61, 71, 71, 71, 81, 81, 81, 91, 91,\n",
       "                    91, 101, 101, 101, 1, 1, 1, 11, 11, 11, 21, 21, 21, 31,\n",
       "                    31, 31, 41, 41, 41, 51, 51, 51, 61, 61, 61, 71, 71, 71,\n",
       "                    81, 81, 81, 91, 91, 91, 101, 101, 101, 1, 1, 1, 11, 11,\n",
       "                    11, 21, 21, 21, 31, 31, 31, 41, 41, 41, 51, 51, 51, 61,\n",
       "                    61, 61, 71, 71, 71, 81, 81, 81, 91, 91, 91, 101, 101,\n",
       "                    101],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_iter': masked_array(data=[5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "                    5000, 5000, 5000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_solver': masked_array(data=['lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 1,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 11,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 21,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 31,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 41,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 51,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 61,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 71,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 81,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 91,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 101,\n",
       "   'max_iter': 5000,\n",
       "   'solver': 'adam'}],\n",
       " 'split0_test_score': array([0.49875, 0.5025 , 0.7325 , 0.50125, 0.4975 , 0.655  , 0.73875,\n",
       "        0.49875, 0.6125 , 0.7375 , 0.5025 , 0.6975 , 0.73875, 0.4975 ,\n",
       "        0.71125, 0.74   , 0.5025 , 0.72125, 0.73625, 0.4975 , 0.70875,\n",
       "        0.73625, 0.5025 , 0.69   , 0.73625, 0.5025 , 0.61   , 0.73875,\n",
       "        0.4975 , 0.6625 , 0.735  , 0.4975 , 0.7175 , 0.50125, 0.4975 ,\n",
       "        0.71875, 0.73875, 0.50125, 0.72625, 0.74   , 0.49875, 0.6925 ,\n",
       "        0.50125, 0.4975 , 0.71   , 0.74   , 0.50125, 0.68   , 0.73625,\n",
       "        0.4975 , 0.6825 , 0.7375 , 0.4975 , 0.71125, 0.7375 , 0.50125,\n",
       "        0.6975 , 0.73625, 0.49875, 0.67875, 0.73   , 0.5025 , 0.6225 ,\n",
       "        0.73625, 0.50125, 0.6175 , 0.73875, 0.4975 , 0.70625, 0.7875 ,\n",
       "        0.49625, 0.74   , 0.80875, 0.5025 , 0.7575 , 0.8425 , 0.495  ,\n",
       "        0.695  , 0.82625, 0.5025 , 0.82125, 0.81   , 0.5    , 0.75875,\n",
       "        0.84375, 0.51625, 0.7325 , 0.81875, 0.5075 , 0.72875, 0.80625,\n",
       "        0.50125, 0.81625, 0.815  , 0.505  , 0.8    , 0.8075 , 0.5025 ,\n",
       "        0.72375, 0.7425 , 0.5025 , 0.4975 , 0.82875, 0.49625, 0.77875,\n",
       "        0.79125, 0.5025 , 0.77125, 0.78125, 0.5    , 0.805  , 0.835  ,\n",
       "        0.50125, 0.7425 , 0.8475 , 0.5025 , 0.72375, 0.80375, 0.50625,\n",
       "        0.71125, 0.835  , 0.49375, 0.71   , 0.80625, 0.5025 , 0.76375,\n",
       "        0.8325 , 0.50125, 0.72125, 0.825  , 0.51125, 0.74875, 0.5025 ,\n",
       "        0.50125, 0.49875, 0.7425 , 0.49875, 0.73125, 0.73875, 0.49875,\n",
       "        0.715  , 0.74125, 0.5025 , 0.72   , 0.78625, 0.4975 , 0.7025 ,\n",
       "        0.86   , 0.50125, 0.72   , 0.745  , 0.50125, 0.74875, 0.78125,\n",
       "        0.49375, 0.72125, 0.835  , 0.49625, 0.705  , 0.81375, 0.5025 ,\n",
       "        0.72375, 0.86875, 0.495  , 0.75875, 0.49875, 0.5025 , 0.49875,\n",
       "        0.7375 , 0.5025 , 0.72625, 0.81   , 0.4975 , 0.69375, 0.7725 ,\n",
       "        0.50125, 0.71875, 0.78375, 0.5    , 0.725  , 0.8675 , 0.50625,\n",
       "        0.75   , 0.8275 , 0.49875, 0.73125, 0.805  , 0.515  , 0.75125,\n",
       "        0.83625, 0.5025 , 0.75375, 0.84375, 0.4975 , 0.67875, 0.82875,\n",
       "        0.505  , 0.74875, 0.505  , 0.4975 , 0.51625, 0.7375 , 0.5025 ,\n",
       "        0.7075 , 0.77125, 0.5025 , 0.75625, 0.76875, 0.49875, 0.71875,\n",
       "        0.76   , 0.49875, 0.715  , 0.77125, 0.5    , 0.7225 , 0.73625,\n",
       "        0.49875, 0.72   , 0.7525 , 0.4975 , 0.7675 , 0.72625, 0.5025 ,\n",
       "        0.72125, 0.7025 , 0.50125, 0.59875, 0.73625, 0.50375, 0.67   ,\n",
       "        0.5025 , 0.5025 , 0.5025 , 0.73625, 0.5    , 0.72   , 0.7375 ,\n",
       "        0.4975 , 0.70375, 0.7725 , 0.5    , 0.69125, 0.73875, 0.4975 ,\n",
       "        0.7025 , 0.76625, 0.5025 , 0.7    , 0.74375, 0.4975 , 0.71875,\n",
       "        0.7375 , 0.50125, 0.72875, 0.72125, 0.5    , 0.73125, 0.7275 ,\n",
       "        0.50375, 0.6    , 0.77375, 0.49875, 0.71875]),\n",
       " 'split1_test_score': array([0.75875, 0.49875, 0.4725 , 0.75875, 0.49875, 0.71625, 0.75125,\n",
       "        0.49875, 0.635  , 0.75875, 0.50125, 0.74   , 0.75875, 0.50125,\n",
       "        0.74125, 0.75375, 0.50125, 0.71125, 0.7575 , 0.49875, 0.6975 ,\n",
       "        0.74625, 0.50125, 0.6175 , 0.7575 , 0.50125, 0.63375, 0.76   ,\n",
       "        0.50125, 0.65125, 0.7575 , 0.50125, 0.73875, 0.52375, 0.49875,\n",
       "        0.7425 , 0.50125, 0.50125, 0.71625, 0.75875, 0.49875, 0.7225 ,\n",
       "        0.7575 , 0.50125, 0.715  , 0.76125, 0.50125, 0.715  , 0.7525 ,\n",
       "        0.50125, 0.6175 , 0.7575 , 0.50125, 0.73625, 0.7525 , 0.49875,\n",
       "        0.66375, 0.7575 , 0.50125, 0.5575 , 0.7525 , 0.49875, 0.745  ,\n",
       "        0.74625, 0.50125, 0.7375 , 0.5025 , 0.49875, 0.4975 , 0.75875,\n",
       "        0.5025 , 0.7775 , 0.8325 , 0.4975 , 0.74875, 0.81   , 0.50125,\n",
       "        0.77   , 0.7625 , 0.5025 , 0.79   , 0.7825 , 0.49625, 0.7875 ,\n",
       "        0.81375, 0.51125, 0.74625, 0.8425 , 0.52   , 0.805  , 0.84875,\n",
       "        0.50625, 0.805  , 0.80875, 0.5025 , 0.7375 , 0.805  , 0.505  ,\n",
       "        0.82875, 0.5025 , 0.4975 , 0.50125, 0.80375, 0.50125, 0.7475 ,\n",
       "        0.845  , 0.4925 , 0.74125, 0.7875 , 0.5    , 0.745  , 0.82875,\n",
       "        0.505  , 0.7975 , 0.85125, 0.50125, 0.79625, 0.79125, 0.50125,\n",
       "        0.79375, 0.83375, 0.515  , 0.7725 , 0.84875, 0.50375, 0.81125,\n",
       "        0.82625, 0.5025 , 0.7375 , 0.80375, 0.5025 , 0.82   , 0.5025 ,\n",
       "        0.49875, 0.50125, 0.77625, 0.50125, 0.745  , 0.82125, 0.5    ,\n",
       "        0.755  , 0.83625, 0.5    , 0.73375, 0.7775 , 0.4975 , 0.7975 ,\n",
       "        0.8375 , 0.50625, 0.79875, 0.84   , 0.49625, 0.76875, 0.8125 ,\n",
       "        0.5075 , 0.7525 , 0.8525 , 0.49625, 0.76125, 0.82625, 0.5    ,\n",
       "        0.76   , 0.8375 , 0.5025 , 0.74125, 0.5    , 0.49875, 0.49625,\n",
       "        0.75875, 0.495  , 0.50125, 0.81875, 0.5025 , 0.765  , 0.865  ,\n",
       "        0.5    , 0.7225 , 0.75625, 0.515  , 0.735  , 0.85875, 0.5025 ,\n",
       "        0.7275 , 0.83125, 0.49375, 0.74875, 0.74875, 0.495  , 0.74625,\n",
       "        0.84375, 0.49875, 0.75   , 0.825  , 0.50625, 0.755  , 0.83375,\n",
       "        0.5025 , 0.77125, 0.50125, 0.50125, 0.50375, 0.755  , 0.50125,\n",
       "        0.76   , 0.78375, 0.49875, 0.74875, 0.81125, 0.50125, 0.7475 ,\n",
       "        0.765  , 0.4975 , 0.75625, 0.75875, 0.4975 , 0.75125, 0.75875,\n",
       "        0.50125, 0.75375, 0.74875, 0.4975 , 0.75375, 0.8325 , 0.49625,\n",
       "        0.755  , 0.77875, 0.4975 , 0.74375, 0.76625, 0.49875, 0.755  ,\n",
       "        0.50125, 0.50125, 0.515  , 0.4975 , 0.50125, 0.75625, 0.75   ,\n",
       "        0.50125, 0.76375, 0.7675 , 0.5    , 0.745  , 0.785  , 0.50125,\n",
       "        0.74   , 0.76875, 0.4975 , 0.73625, 0.795  , 0.49875, 0.745  ,\n",
       "        0.785  , 0.50125, 0.62375, 0.8025 , 0.5025 , 0.73875, 0.74875,\n",
       "        0.4975 , 0.6825 , 0.755  , 0.4975 , 0.72375]),\n",
       " 'split2_test_score': array([0.50875, 0.49875, 0.5025 , 0.7475 , 0.50125, 0.735  , 0.75   ,\n",
       "        0.49875, 0.7    , 0.74625, 0.49875, 0.735  , 0.75   , 0.49875,\n",
       "        0.58875, 0.75125, 0.49875, 0.74375, 0.75   , 0.49875, 0.645  ,\n",
       "        0.75   , 0.49875, 0.56625, 0.75125, 0.49875, 0.735  , 0.74625,\n",
       "        0.50125, 0.645  , 0.7475 , 0.50125, 0.65625, 0.50625, 0.49875,\n",
       "        0.75625, 0.49875, 0.50125, 0.7475 , 0.7525 , 0.49875, 0.73   ,\n",
       "        0.75   , 0.49875, 0.73625, 0.74875, 0.50125, 0.6925 , 0.75125,\n",
       "        0.49875, 0.74875, 0.75   , 0.50125, 0.7225 , 0.7475 , 0.50125,\n",
       "        0.6825 , 0.7525 , 0.49875, 0.71375, 0.75   , 0.50125, 0.7075 ,\n",
       "        0.75   , 0.50125, 0.675  , 0.505  , 0.50125, 0.74125, 0.81125,\n",
       "        0.50125, 0.745  , 0.8    , 0.5075 , 0.74625, 0.86625, 0.49875,\n",
       "        0.74875, 0.83875, 0.49875, 0.8025 , 0.755  , 0.51125, 0.78625,\n",
       "        0.8325 , 0.505  , 0.745  , 0.8775 , 0.52   , 0.75875, 0.8525 ,\n",
       "        0.50375, 0.75375, 0.825  , 0.49875, 0.75125, 0.8525 , 0.50125,\n",
       "        0.7375 , 0.50125, 0.50125, 0.50125, 0.8225 , 0.5025 , 0.795  ,\n",
       "        0.79625, 0.50875, 0.75875, 0.8225 , 0.51125, 0.75875, 0.86375,\n",
       "        0.5125 , 0.7575 , 0.83375, 0.5025 , 0.76625, 0.84   , 0.5075 ,\n",
       "        0.79875, 0.86375, 0.50375, 0.75125, 0.84   , 0.49875, 0.7125 ,\n",
       "        0.8625 , 0.50375, 0.755  , 0.83625, 0.49375, 0.745  , 0.50125,\n",
       "        0.49875, 0.5    , 0.7725 , 0.5    , 0.7225 , 0.75   , 0.49125,\n",
       "        0.73   , 0.86125, 0.5    , 0.74125, 0.86625, 0.5075 , 0.77   ,\n",
       "        0.82875, 0.51375, 0.7575 , 0.84375, 0.49375, 0.73   , 0.84375,\n",
       "        0.49875, 0.74375, 0.84875, 0.50125, 0.75375, 0.82625, 0.50625,\n",
       "        0.77   , 0.86125, 0.5025 , 0.7425 , 0.5025 , 0.49875, 0.50125,\n",
       "        0.78   , 0.50125, 0.70875, 0.8075 , 0.5025 , 0.74875, 0.7525 ,\n",
       "        0.5025 , 0.6775 , 0.8675 , 0.4875 , 0.76375, 0.83875, 0.49125,\n",
       "        0.7525 , 0.84625, 0.50375, 0.7925 , 0.845  , 0.505  , 0.77875,\n",
       "        0.855  , 0.50375, 0.7075 , 0.83875, 0.49375, 0.7525 , 0.8925 ,\n",
       "        0.5025 , 0.76625, 0.50375, 0.50125, 0.50125, 0.7525 , 0.49375,\n",
       "        0.70125, 0.7525 , 0.495  , 0.77   , 0.7675 , 0.5025 , 0.74125,\n",
       "        0.75   , 0.505  , 0.7425 , 0.74625, 0.49875, 0.7075 , 0.7975 ,\n",
       "        0.5025 , 0.6475 , 0.7575 , 0.505  , 0.67875, 0.7675 , 0.5    ,\n",
       "        0.7375 , 0.7625 , 0.4975 , 0.70375, 0.7525 , 0.5025 , 0.6375 ,\n",
       "        0.50875, 0.49875, 0.755  , 0.7525 , 0.50375, 0.73375, 0.7625 ,\n",
       "        0.50125, 0.745  , 0.76625, 0.49625, 0.745  , 0.77   , 0.4975 ,\n",
       "        0.745  , 0.8275 , 0.5    , 0.74625, 0.79375, 0.50125, 0.72875,\n",
       "        0.74875, 0.50125, 0.6975 , 0.74375, 0.49625, 0.665  , 0.7725 ,\n",
       "        0.5    , 0.67625, 0.77125, 0.50375, 0.74625]),\n",
       " 'split3_test_score': array([0.50375, 0.49875, 0.70875, 0.715  , 0.50125, 0.66125, 0.72375,\n",
       "        0.50125, 0.74   , 0.7225 , 0.50125, 0.60625, 0.7225 , 0.50125,\n",
       "        0.71875, 0.71625, 0.50125, 0.695  , 0.72625, 0.50125, 0.725  ,\n",
       "        0.72375, 0.49875, 0.6975 , 0.72375, 0.50125, 0.60375, 0.72375,\n",
       "        0.49875, 0.60625, 0.7225 , 0.49875, 0.72375, 0.72375, 0.50125,\n",
       "        0.70625, 0.49875, 0.50125, 0.70125, 0.5    , 0.50125, 0.73   ,\n",
       "        0.72375, 0.50125, 0.7325 , 0.725  , 0.49875, 0.67   , 0.7125 ,\n",
       "        0.50125, 0.56875, 0.7225 , 0.49875, 0.72375, 0.73   , 0.49875,\n",
       "        0.7225 , 0.725  , 0.49875, 0.6225 , 0.72625, 0.49875, 0.70625,\n",
       "        0.7225 , 0.50125, 0.59625, 0.50125, 0.49875, 0.50125, 0.7375 ,\n",
       "        0.5025 , 0.7075 , 0.81375, 0.5    , 0.6925 , 0.83   , 0.4875 ,\n",
       "        0.7    , 0.83   , 0.5075 , 0.71375, 0.82375, 0.50125, 0.745  ,\n",
       "        0.825  , 0.505  , 0.74875, 0.82   , 0.5025 , 0.73875, 0.82   ,\n",
       "        0.50125, 0.77875, 0.8375 , 0.505  , 0.72625, 0.81375, 0.50625,\n",
       "        0.73   , 0.73   , 0.50125, 0.49125, 0.82375, 0.50125, 0.7625 ,\n",
       "        0.845  , 0.50125, 0.735  , 0.77375, 0.49625, 0.72875, 0.8425 ,\n",
       "        0.49875, 0.73625, 0.7975 , 0.49625, 0.73   , 0.85875, 0.49875,\n",
       "        0.78875, 0.73375, 0.5    , 0.71625, 0.82875, 0.5    , 0.7525 ,\n",
       "        0.82   , 0.49125, 0.7925 , 0.84625, 0.5025 , 0.7275 , 0.50125,\n",
       "        0.49875, 0.49875, 0.72875, 0.49875, 0.4975 , 0.73875, 0.49375,\n",
       "        0.675  , 0.735  , 0.5    , 0.7125 , 0.81625, 0.495  , 0.71375,\n",
       "        0.83875, 0.50125, 0.73125, 0.80875, 0.4925 , 0.75875, 0.84   ,\n",
       "        0.49875, 0.71375, 0.85125, 0.50125, 0.7275 , 0.85   , 0.50625,\n",
       "        0.6975 , 0.8325 , 0.50125, 0.6925 , 0.50125, 0.49875, 0.50125,\n",
       "        0.78125, 0.48875, 0.50125, 0.79   , 0.50125, 0.71625, 0.81625,\n",
       "        0.4925 , 0.7475 , 0.80625, 0.51125, 0.7175 , 0.82875, 0.49125,\n",
       "        0.70625, 0.84625, 0.5025 , 0.73625, 0.7775 , 0.50125, 0.75   ,\n",
       "        0.845  , 0.51125, 0.72375, 0.80875, 0.505  , 0.72   , 0.86125,\n",
       "        0.5    , 0.75375, 0.50375, 0.50125, 0.5    , 0.7225 , 0.5    ,\n",
       "        0.69625, 0.70375, 0.49875, 0.72375, 0.765  , 0.49875, 0.65875,\n",
       "        0.7475 , 0.5025 , 0.7175 , 0.72875, 0.50125, 0.73375, 0.745  ,\n",
       "        0.50125, 0.68875, 0.7875 , 0.49875, 0.69375, 0.71875, 0.50375,\n",
       "        0.73   , 0.7325 , 0.50375, 0.715  , 0.77875, 0.49375, 0.715  ,\n",
       "        0.50125, 0.49875, 0.5    , 0.74125, 0.5    , 0.62375, 0.775  ,\n",
       "        0.5025 , 0.665  , 0.715  , 0.50125, 0.6875 , 0.72375, 0.5    ,\n",
       "        0.72875, 0.715  , 0.505  , 0.64625, 0.81875, 0.49625, 0.6975 ,\n",
       "        0.7825 , 0.50125, 0.67375, 0.85625, 0.49375, 0.7125 , 0.71125,\n",
       "        0.49875, 0.64125, 0.755  , 0.5    , 0.72125]),\n",
       " 'mean_test_score': array([0.5675   , 0.4996875, 0.6040625, 0.680625 , 0.4996875, 0.691875 ,\n",
       "        0.7409375, 0.499375 , 0.671875 , 0.74125  , 0.5009375, 0.6946875,\n",
       "        0.7425   , 0.4996875, 0.69     , 0.7403125, 0.5009375, 0.7178125,\n",
       "        0.7425   , 0.4990625, 0.6940625, 0.7390625, 0.5003125, 0.6428125,\n",
       "        0.7421875, 0.5009375, 0.645625 , 0.7421875, 0.4996875, 0.64125  ,\n",
       "        0.740625 , 0.4996875, 0.7090625, 0.56375  , 0.4990625, 0.7309375,\n",
       "        0.559375 , 0.50125  , 0.7228125, 0.6878125, 0.499375 , 0.71875  ,\n",
       "        0.683125 , 0.4996875, 0.7234375, 0.74375  , 0.500625 , 0.689375 ,\n",
       "        0.738125 , 0.4996875, 0.654375 , 0.741875 , 0.4996875, 0.7234375,\n",
       "        0.741875 , 0.5      , 0.6915625, 0.7428125, 0.499375 , 0.643125 ,\n",
       "        0.7396875, 0.5003125, 0.6953125, 0.73875  , 0.50125  , 0.6565625,\n",
       "        0.561875 , 0.4990625, 0.6115625, 0.77375  , 0.500625 , 0.7425   ,\n",
       "        0.81375  , 0.501875 , 0.73625  , 0.8371875, 0.495625 , 0.7284375,\n",
       "        0.814375 , 0.5028125, 0.781875 , 0.7928125, 0.5021875, 0.769375 ,\n",
       "        0.82875  , 0.509375 , 0.743125 , 0.8396875, 0.5125   , 0.7578125,\n",
       "        0.831875 , 0.503125 , 0.7884375, 0.8215625, 0.5028125, 0.75375  ,\n",
       "        0.8196875, 0.50375  , 0.755    , 0.6190625, 0.500625 , 0.4978125,\n",
       "        0.8196875, 0.5003125, 0.7709375, 0.819375 , 0.50125  , 0.7515625,\n",
       "        0.79125  , 0.501875 , 0.759375 , 0.8425   , 0.504375 , 0.7584375,\n",
       "        0.8325   , 0.500625 , 0.7540625, 0.8234375, 0.5034375, 0.773125 ,\n",
       "        0.8165625, 0.503125 , 0.7375   , 0.8309375, 0.50125  , 0.76     ,\n",
       "        0.8353125, 0.4996875, 0.7515625, 0.8278125, 0.5025   , 0.7603125,\n",
       "        0.501875 , 0.499375 , 0.4996875, 0.755    , 0.4996875, 0.6740625,\n",
       "        0.7621875, 0.4959375, 0.71875  , 0.7934375, 0.500625 , 0.726875 ,\n",
       "        0.8115625, 0.499375 , 0.7459375, 0.84125  , 0.505625 , 0.751875 ,\n",
       "        0.809375 , 0.4959375, 0.7515625, 0.819375 , 0.4996875, 0.7328125,\n",
       "        0.846875 , 0.49875  , 0.736875 , 0.8290625, 0.50375  , 0.7378125,\n",
       "        0.85     , 0.5003125, 0.73375  , 0.500625 , 0.4996875, 0.499375 ,\n",
       "        0.764375 , 0.496875 , 0.609375 , 0.8065625, 0.5009375, 0.7309375,\n",
       "        0.8015625, 0.4990625, 0.7165625, 0.8034375, 0.5034375, 0.7353125,\n",
       "        0.8484375, 0.4978125, 0.7340625, 0.8378125, 0.4996875, 0.7521875,\n",
       "        0.7940625, 0.5040625, 0.7565625, 0.845    , 0.5040625, 0.73375  ,\n",
       "        0.8290625, 0.500625 , 0.7265625, 0.8540625, 0.5025   , 0.76     ,\n",
       "        0.5034375, 0.5003125, 0.5053125, 0.741875 , 0.499375 , 0.71625  ,\n",
       "        0.7528125, 0.49875  , 0.7496875, 0.778125 , 0.5003125, 0.7165625,\n",
       "        0.755625 , 0.5009375, 0.7328125, 0.75125  , 0.499375 , 0.72875  ,\n",
       "        0.759375 , 0.5009375, 0.7025   , 0.7615625, 0.4996875, 0.7234375,\n",
       "        0.76125  , 0.500625 , 0.7359375, 0.7440625, 0.5      , 0.6903125,\n",
       "        0.7584375, 0.4996875, 0.694375 , 0.5034375, 0.5003125, 0.568125 ,\n",
       "        0.681875 , 0.50125  , 0.7084375, 0.75625  , 0.500625 , 0.719375 ,\n",
       "        0.7553125, 0.499375 , 0.7171875, 0.754375 , 0.4990625, 0.7290625,\n",
       "        0.769375 , 0.50125  , 0.7071875, 0.7878125, 0.4984375, 0.7225   ,\n",
       "        0.7634375, 0.50125  , 0.6809375, 0.7809375, 0.498125 , 0.711875 ,\n",
       "        0.74     , 0.5      , 0.65     , 0.76375  , 0.5      , 0.7275   ]),\n",
       " 'std_test_score': array([0.11047483, 0.0016238 , 0.11734489, 0.10480078, 0.0016238 ,\n",
       "        0.03446579, 0.01105296, 0.00108253, 0.05078678, 0.0131992 ,\n",
       "        0.00136216, 0.05363633, 0.01354968, 0.0016238 , 0.05949002,\n",
       "        0.01482647, 0.00136216, 0.01766385, 0.01208692, 0.00136216,\n",
       "        0.0299658 , 0.01016946, 0.0016238 , 0.05412929, 0.01315102,\n",
       "        0.00136216, 0.05280048, 0.01309148, 0.0016238 , 0.02115789,\n",
       "        0.01315473, 0.0016238 , 0.03145402, 0.09275303, 0.00136216,\n",
       "        0.01957308, 0.10356723, 0.        , 0.01680251, 0.10864354,\n",
       "        0.00108253, 0.01546165, 0.10575066, 0.0016238 , 0.01115848,\n",
       "        0.0131992 , 0.00108253, 0.01680541, 0.01611725, 0.0016238 ,\n",
       "        0.06780314, 0.01327298, 0.0016238 , 0.00885539, 0.00872765,\n",
       "        0.00125   , 0.02149446, 0.01294142, 0.00108253, 0.0591905 ,\n",
       "        0.01167178, 0.0016238 , 0.04482932, 0.01064337, 0.        ,\n",
       "        0.05489603, 0.10212775, 0.00136216, 0.11287567, 0.02799274,\n",
       "        0.00257694, 0.02481179, 0.01189144, 0.00369755, 0.02560212,\n",
       "        0.02039407, 0.00519164, 0.03188572, 0.03029155, 0.00310934,\n",
       "        0.04087424, 0.02640394, 0.00554632, 0.01816805, 0.01093303,\n",
       "        0.00471865, 0.00628117, 0.02378903, 0.00770552, 0.02930677,\n",
       "        0.01941528, 0.00207289, 0.0242122 , 0.01087482, 0.00255792,\n",
       "        0.02813194, 0.01921049, 0.00197642, 0.04285696, 0.11727164,\n",
       "        0.001875  , 0.00408647, 0.00949404, 0.00240036, 0.01775209,\n",
       "        0.0256859 , 0.00579601, 0.01431714, 0.0186874 , 0.005625  ,\n",
       "        0.02840142, 0.0131992 , 0.00519164, 0.02383824, 0.02123161,\n",
       "        0.00257694, 0.02926676, 0.02713357, 0.00357673, 0.03589808,\n",
       "        0.04929483, 0.00773082, 0.02560212, 0.01591911, 0.00197642,\n",
       "        0.03518922, 0.01630699, 0.00495093, 0.02647781, 0.01579594,\n",
       "        0.00618718, 0.03538157, 0.000625  , 0.00108253, 0.00103645,\n",
       "        0.02001952, 0.00103645, 0.10225342, 0.03440765, 0.00357673,\n",
       "        0.02902047, 0.05605783, 0.00108253, 0.01126735, 0.03469032,\n",
       "        0.00480072, 0.03924458, 0.01149049, 0.00511585, 0.03029155,\n",
       "        0.03957292, 0.00335119, 0.01431714, 0.02510136, 0.00495093,\n",
       "        0.01584532, 0.00698771, 0.0025    , 0.02226439, 0.01312128,\n",
       "        0.00265165, 0.02894465, 0.01533481, 0.00310934, 0.02479604,\n",
       "        0.00139754, 0.0016238 , 0.00207289, 0.01790819, 0.00548435,\n",
       "        0.10830188, 0.01043488, 0.0020492 , 0.02773162, 0.04327758,\n",
       "        0.00389059, 0.02511497, 0.04100662, 0.01073018, 0.01755293,\n",
       "        0.01542054, 0.00669509, 0.01877862, 0.00854103, 0.00389059,\n",
       "        0.02413139, 0.03550281, 0.00725512, 0.01294142, 0.00667317,\n",
       "        0.00453932, 0.01905994, 0.01358926, 0.00519164, 0.03086481,\n",
       "        0.02540877, 0.00176777, 0.00910014, 0.00136216, 0.0016238 ,\n",
       "        0.00645749, 0.01303541, 0.00336573, 0.02557159, 0.03043147,\n",
       "        0.00265165, 0.01680251, 0.01917233, 0.0016238 , 0.03504879,\n",
       "        0.00715345, 0.00298106, 0.01728382, 0.01571226, 0.00139754,\n",
       "        0.01598339, 0.02342708, 0.00136216, 0.039201  , 0.01529336,\n",
       "        0.00310934, 0.03787701, 0.04513002, 0.00286411, 0.0124177 ,\n",
       "        0.02917318, 0.00265165, 0.05483908, 0.01582065, 0.00389059,\n",
       "        0.0445244 , 0.00310934, 0.0016238 , 0.10804188, 0.10661152,\n",
       "        0.00153093, 0.05057772, 0.01397542, 0.001875  , 0.03816596,\n",
       "        0.02339162, 0.001875  , 0.02784408, 0.02431081, 0.0016238 ,\n",
       "        0.01642633, 0.03982873, 0.00279508, 0.03916487, 0.02732008,\n",
       "        0.00184877, 0.01720737, 0.02071712, 0.        , 0.03834847,\n",
       "        0.05263654, 0.00336573, 0.02870241, 0.02299796, 0.00233854,\n",
       "        0.03287048, 0.00879453, 0.00233854, 0.01096871]),\n",
       " 'rank_test_score': array([165, 225, 163, 150, 225, 141,  92, 241, 152,  91, 199, 138,  83,\n",
       "        225, 144,  94, 199, 127,  85, 250, 140,  97, 214, 158,  86, 199,\n",
       "        156,  86, 225, 159,  93, 225, 133, 166, 250, 111, 168, 192, 122,\n",
       "        146, 241, 125, 147, 225, 120,  80, 205, 145,  99, 225, 154,  88,\n",
       "        225, 120,  90, 221, 142,  82, 241, 157,  96, 214, 137,  98, 192,\n",
       "        153, 167, 250, 161,  42, 205,  83,  27, 189, 103,  10, 264, 115,\n",
       "         26, 184,  39,  35, 188,  45,  17, 170,  81,   8, 169,  60,  13,\n",
       "        182,  37,  20, 184,  69,  22, 177,  65, 160, 205, 259,  21, 214,\n",
       "         44,  23, 192,  73,  36, 189,  57,   6, 173,  58,  12, 205,  68,\n",
       "         19, 179,  43,  25, 182, 101,  14, 192,  54,  11, 239,  73,  18,\n",
       "        186,  53, 189, 241, 225,  66, 225, 151,  50, 262, 125,  34, 205,\n",
       "        117,  28, 241,  78,   7, 171,  72,  29, 263,  73,  23, 225, 110,\n",
       "          4, 255, 102,  15, 176, 100,   2, 214, 107, 205, 225, 241,  47,\n",
       "        261, 162,  30, 199, 111,  32, 254, 129,  31, 179, 105,   3, 259,\n",
       "        106,   9, 225,  71,  33, 174,  61,   5, 175, 107,  16, 205, 118,\n",
       "          1, 186,  54, 178, 214, 172,  88, 241, 131,  70, 255,  77,  41,\n",
       "        214, 130,  63, 199, 109,  76, 241, 114,  56, 199, 136,  51, 225,\n",
       "        119,  52, 205, 104,  79, 221, 143,  58, 239, 139, 179, 214, 164,\n",
       "        148, 192, 134,  62, 205, 124,  64, 241, 128,  67, 250, 113,  45,\n",
       "        192, 135,  38, 257, 123,  49, 192, 149,  40, 258, 132,  95, 221,\n",
       "        155,  48, 221, 116]),\n",
       " 'split0_train_score': array([0.49916667, 0.50125   , 0.74833333, 0.50083333, 0.49875   ,\n",
       "        0.66708333, 0.74      , 0.49875   , 0.62916667, 0.74166667,\n",
       "        0.50125   , 0.7225    , 0.74333333, 0.49875   , 0.73916667,\n",
       "        0.74125   , 0.50125   , 0.73458333, 0.74333333, 0.49875   ,\n",
       "        0.73083333, 0.7425    , 0.50125   , 0.72      , 0.74333333,\n",
       "        0.50125   , 0.61208333, 0.74      , 0.49875   , 0.67541667,\n",
       "        0.73958333, 0.49875   , 0.73666667, 0.50458333, 0.49875   ,\n",
       "        0.73375   , 0.7425    , 0.50125   , 0.73958333, 0.7425    ,\n",
       "        0.49875   , 0.70333333, 0.50125   , 0.49875   , 0.72166667,\n",
       "        0.74166667, 0.50125   , 0.7075    , 0.7425    , 0.49875   ,\n",
       "        0.69708333, 0.74333333, 0.49875   , 0.73625   , 0.74291667,\n",
       "        0.50125   , 0.72375   , 0.74333333, 0.49875   , 0.69083333,\n",
       "        0.74      , 0.50125   , 0.62458333, 0.74375   , 0.50125   ,\n",
       "        0.62125   , 0.74875   , 0.49791667, 0.72791667, 0.81      ,\n",
       "        0.49708333, 0.77875   , 0.82083333, 0.50125   , 0.77083333,\n",
       "        0.83291667, 0.49708333, 0.73083333, 0.86041667, 0.50125   ,\n",
       "        0.82375   , 0.84333333, 0.50291667, 0.77416667, 0.875     ,\n",
       "        0.50375   , 0.74875   , 0.85208333, 0.505     , 0.77791667,\n",
       "        0.84208333, 0.4975    , 0.8275    , 0.86208333, 0.50166667,\n",
       "        0.8325    , 0.86666667, 0.50291667, 0.74791667, 0.75083333,\n",
       "        0.50125   , 0.49875   , 0.83958333, 0.49791667, 0.79625   ,\n",
       "        0.80958333, 0.50041667, 0.77125   , 0.79333333, 0.49791667,\n",
       "        0.83125   , 0.84958333, 0.50166667, 0.76291667, 0.865     ,\n",
       "        0.50541667, 0.74      , 0.82375   , 0.50291667, 0.7425    ,\n",
       "        0.83708333, 0.49625   , 0.72208333, 0.83208333, 0.50375   ,\n",
       "        0.76708333, 0.84666667, 0.50083333, 0.74083333, 0.84291667,\n",
       "        0.50333333, 0.76583333, 0.50125   , 0.49875   , 0.49916667,\n",
       "        0.74875   , 0.49958333, 0.745     , 0.74583333, 0.50375   ,\n",
       "        0.74291667, 0.75083333, 0.49958333, 0.75333333, 0.80625   ,\n",
       "        0.50083333, 0.71916667, 0.88458333, 0.49791667, 0.74208333,\n",
       "        0.74666667, 0.50083333, 0.75625   , 0.805     , 0.49958333,\n",
       "        0.74625   , 0.86208333, 0.50208333, 0.725     , 0.85541667,\n",
       "        0.50125   , 0.74083333, 0.90208333, 0.50166667, 0.77166667,\n",
       "        0.505     , 0.50125   , 0.5       , 0.74708333, 0.50375   ,\n",
       "        0.75541667, 0.82708333, 0.49708333, 0.72291667, 0.78291667,\n",
       "        0.50083333, 0.74458333, 0.78625   , 0.50125   , 0.73833333,\n",
       "        0.88416667, 0.50541667, 0.7725    , 0.84041667, 0.50291667,\n",
       "        0.75791667, 0.865     , 0.50416667, 0.75708333, 0.84208333,\n",
       "        0.5025    , 0.74291667, 0.88125   , 0.50291667, 0.70125   ,\n",
       "        0.86      , 0.50166667, 0.75      , 0.51      , 0.49875   ,\n",
       "        0.50041667, 0.7425    , 0.50291667, 0.72708333, 0.78916667,\n",
       "        0.50125   , 0.76041667, 0.79083333, 0.49791667, 0.73125   ,\n",
       "        0.77625   , 0.50083333, 0.73291667, 0.7975    , 0.50083333,\n",
       "        0.74583333, 0.74      , 0.49958333, 0.73458333, 0.76916667,\n",
       "        0.50083333, 0.79083333, 0.73833333, 0.5025    , 0.725     ,\n",
       "        0.73041667, 0.50083333, 0.60583333, 0.74833333, 0.50375   ,\n",
       "        0.69666667, 0.50125   , 0.50125   , 0.50291667, 0.74333333,\n",
       "        0.50166667, 0.7325    , 0.73916667, 0.49875   , 0.71666667,\n",
       "        0.7925    , 0.50208333, 0.70625   , 0.74125   , 0.49875   ,\n",
       "        0.72583333, 0.78333333, 0.50166667, 0.72875   , 0.76291667,\n",
       "        0.49666667, 0.74208333, 0.74416667, 0.50083333, 0.7475    ,\n",
       "        0.73375   , 0.5       , 0.74291667, 0.73583333, 0.50208333,\n",
       "        0.60791667, 0.78208333, 0.49791667, 0.7375    ]),\n",
       " 'split1_train_score': array([0.74041667, 0.49833333, 0.50541667, 0.74041667, 0.49833333,\n",
       "        0.6975    , 0.73625   , 0.49875   , 0.64416667, 0.73875   ,\n",
       "        0.50166667, 0.72291667, 0.73958333, 0.50166667, 0.71041667,\n",
       "        0.73833333, 0.50166667, 0.69583333, 0.74208333, 0.49833333,\n",
       "        0.67375   , 0.73375   , 0.50125   , 0.63291667, 0.74      ,\n",
       "        0.50166667, 0.64875   , 0.74083333, 0.50125   , 0.65541667,\n",
       "        0.74083333, 0.50166667, 0.71791667, 0.50166667, 0.49833333,\n",
       "        0.73      , 0.50208333, 0.50125   , 0.69125   , 0.74083333,\n",
       "        0.49833333, 0.71916667, 0.73958333, 0.50166667, 0.7025    ,\n",
       "        0.7375    , 0.50166667, 0.69166667, 0.73583333, 0.50125   ,\n",
       "        0.62541667, 0.7425    , 0.50166667, 0.71208333, 0.74041667,\n",
       "        0.49833333, 0.66125   , 0.74083333, 0.50166667, 0.54416667,\n",
       "        0.73875   , 0.49833333, 0.72333333, 0.735     , 0.50166667,\n",
       "        0.71291667, 0.5       , 0.49833333, 0.5       , 0.745     ,\n",
       "        0.5025    , 0.7725    , 0.85375   , 0.5       , 0.73291667,\n",
       "        0.82041667, 0.50166667, 0.76333333, 0.74166667, 0.50208333,\n",
       "        0.80166667, 0.80541667, 0.50291667, 0.76833333, 0.84      ,\n",
       "        0.50375   , 0.73541667, 0.855     , 0.51916667, 0.81833333,\n",
       "        0.85166667, 0.50333333, 0.82083333, 0.83875   , 0.50125   ,\n",
       "        0.72791667, 0.85041667, 0.50458333, 0.83541667, 0.50166667,\n",
       "        0.49916667, 0.50166667, 0.82333333, 0.49958333, 0.73625   ,\n",
       "        0.87375   , 0.5       , 0.72166667, 0.77083333, 0.49916667,\n",
       "        0.73041667, 0.84      , 0.50333333, 0.78416667, 0.86916667,\n",
       "        0.50166667, 0.79083333, 0.82541667, 0.50333333, 0.81166667,\n",
       "        0.85458333, 0.50708333, 0.76916667, 0.85833333, 0.49916667,\n",
       "        0.81      , 0.85666667, 0.50208333, 0.72875   , 0.81291667,\n",
       "        0.50583333, 0.83      , 0.50125   , 0.49833333, 0.50166667,\n",
       "        0.78125   , 0.50083333, 0.73375   , 0.8425    , 0.5025    ,\n",
       "        0.74791667, 0.84416667, 0.5       , 0.71      , 0.80583333,\n",
       "        0.50166667, 0.77541667, 0.8575    , 0.50208333, 0.77958333,\n",
       "        0.85583333, 0.49833333, 0.76875   , 0.7875    , 0.50625   ,\n",
       "        0.7425    , 0.86708333, 0.50416667, 0.74833333, 0.84375   ,\n",
       "        0.4975    , 0.7625    , 0.855     , 0.50083333, 0.73416667,\n",
       "        0.5025    , 0.49833333, 0.49875   , 0.74208333, 0.49833333,\n",
       "        0.50166667, 0.83083333, 0.50208333, 0.7475    , 0.87666667,\n",
       "        0.49875   , 0.71208333, 0.745     , 0.51208333, 0.705     ,\n",
       "        0.875     , 0.50041667, 0.73291667, 0.85291667, 0.50041667,\n",
       "        0.74375   , 0.74708333, 0.50125   , 0.72625   , 0.87916667,\n",
       "        0.50083333, 0.7325    , 0.8325    , 0.505     , 0.73625   ,\n",
       "        0.84458333, 0.5025    , 0.76208333, 0.50166667, 0.50166667,\n",
       "        0.50166667, 0.74083333, 0.50208333, 0.73708333, 0.7825    ,\n",
       "        0.49833333, 0.73291667, 0.80583333, 0.50166667, 0.73      ,\n",
       "        0.74583333, 0.49875   , 0.73708333, 0.74041667, 0.5       ,\n",
       "        0.73666667, 0.73916667, 0.50125   , 0.74166667, 0.73416667,\n",
       "        0.50041667, 0.73125   , 0.835     , 0.50125   , 0.72875   ,\n",
       "        0.77      , 0.49833333, 0.72375   , 0.75375   , 0.5       ,\n",
       "        0.73416667, 0.50166667, 0.50166667, 0.49375   , 0.49833333,\n",
       "        0.50041667, 0.73666667, 0.73875   , 0.50041667, 0.73875   ,\n",
       "        0.75666667, 0.49958333, 0.73375   , 0.77708333, 0.49958333,\n",
       "        0.73      , 0.75833333, 0.5       , 0.71041667, 0.77333333,\n",
       "        0.50041667, 0.71875   , 0.7725    , 0.50333333, 0.61541667,\n",
       "        0.81625   , 0.49916667, 0.71333333, 0.73166667, 0.49833333,\n",
       "        0.67791667, 0.7425    , 0.49916667, 0.70458333]),\n",
       " 'split2_train_score': array([0.50458333, 0.49833333, 0.49583333, 0.73708333, 0.50125   ,\n",
       "        0.72125   , 0.74125   , 0.49833333, 0.69666667, 0.73291667,\n",
       "        0.49875   , 0.72541667, 0.74041667, 0.49875   , 0.58625   ,\n",
       "        0.74083333, 0.49833333, 0.72333333, 0.74166667, 0.49833333,\n",
       "        0.65625   , 0.73583333, 0.49875   , 0.55208333, 0.74125   ,\n",
       "        0.49833333, 0.72125   , 0.74166667, 0.50166667, 0.65833333,\n",
       "        0.73916667, 0.50125   , 0.66583333, 0.50666667, 0.49833333,\n",
       "        0.74333333, 0.49916667, 0.50166667, 0.7375    , 0.73625   ,\n",
       "        0.49833333, 0.72      , 0.74041667, 0.49833333, 0.72333333,\n",
       "        0.74041667, 0.50166667, 0.69416667, 0.7325    , 0.49833333,\n",
       "        0.73208333, 0.73625   , 0.50125   , 0.7225    , 0.73625   ,\n",
       "        0.50166667, 0.66208333, 0.7425    , 0.49875   , 0.71333333,\n",
       "        0.74041667, 0.50166667, 0.70833333, 0.74166667, 0.50125   ,\n",
       "        0.68541667, 0.51041667, 0.50166667, 0.73708333, 0.81916667,\n",
       "        0.50166667, 0.75041667, 0.81208333, 0.5025    , 0.73875   ,\n",
       "        0.87416667, 0.49833333, 0.7425    , 0.84      , 0.50458333,\n",
       "        0.79583333, 0.74416667, 0.4975    , 0.77708333, 0.83708333,\n",
       "        0.49375   , 0.74208333, 0.88125   , 0.53291667, 0.75166667,\n",
       "        0.86041667, 0.51333333, 0.7375    , 0.82708333, 0.49875   ,\n",
       "        0.73833333, 0.8575    , 0.50708333, 0.72291667, 0.50166667,\n",
       "        0.50166667, 0.50208333, 0.81958333, 0.50291667, 0.78541667,\n",
       "        0.77166667, 0.49583333, 0.74041667, 0.81958333, 0.50791667,\n",
       "        0.74875   , 0.8525    , 0.50083333, 0.74375   , 0.84833333,\n",
       "        0.49875   , 0.76291667, 0.8425    , 0.50666667, 0.79041667,\n",
       "        0.875     , 0.48958333, 0.74458333, 0.86708333, 0.50125   ,\n",
       "        0.71875   , 0.85291667, 0.50666667, 0.73708333, 0.82708333,\n",
       "        0.50083333, 0.74208333, 0.50166667, 0.49916667, 0.50166667,\n",
       "        0.785     , 0.50666667, 0.73458333, 0.74666667, 0.5       ,\n",
       "        0.71916667, 0.87208333, 0.50083333, 0.7325    , 0.87208333,\n",
       "        0.50125   , 0.76291667, 0.82666667, 0.50125   , 0.75208333,\n",
       "        0.85541667, 0.5       , 0.72958333, 0.85375   , 0.50375   ,\n",
       "        0.75208333, 0.85958333, 0.50333333, 0.73916667, 0.85208333,\n",
       "        0.50708333, 0.76625   , 0.85791667, 0.50083333, 0.74583333,\n",
       "        0.5025    , 0.49875   , 0.50166667, 0.79916667, 0.49875   ,\n",
       "        0.71541667, 0.81791667, 0.49875   , 0.72958333, 0.74875   ,\n",
       "        0.50041667, 0.67791667, 0.87291667, 0.5       , 0.75333333,\n",
       "        0.84083333, 0.49875   , 0.74125   , 0.86375   , 0.49791667,\n",
       "        0.7775    , 0.85416667, 0.50208333, 0.76541667, 0.86166667,\n",
       "        0.50083333, 0.68875   , 0.83083333, 0.50041667, 0.75      ,\n",
       "        0.89166667, 0.50583333, 0.785     , 0.50541667, 0.50166667,\n",
       "        0.50166667, 0.73916667, 0.49875   , 0.68083333, 0.74      ,\n",
       "        0.5       , 0.75625   , 0.75583333, 0.50125   , 0.73916667,\n",
       "        0.74083333, 0.50166667, 0.73208333, 0.72875   , 0.49958333,\n",
       "        0.70791667, 0.785     , 0.50291667, 0.66666667, 0.73833333,\n",
       "        0.50041667, 0.64833333, 0.75625   , 0.50125   , 0.73666667,\n",
       "        0.75625   , 0.50125   , 0.67875   , 0.74166667, 0.50083333,\n",
       "        0.6525    , 0.5075    , 0.49833333, 0.73958333, 0.74666667,\n",
       "        0.50208333, 0.72916667, 0.75958333, 0.50208333, 0.74541667,\n",
       "        0.75041667, 0.50125   , 0.75125   , 0.76583333, 0.49958333,\n",
       "        0.73166667, 0.82916667, 0.49875   , 0.73916667, 0.79375   ,\n",
       "        0.50166667, 0.73291667, 0.73375   , 0.50125   , 0.67125   ,\n",
       "        0.73      , 0.49833333, 0.64375   , 0.75875   , 0.50125   ,\n",
       "        0.64708333, 0.76333333, 0.50333333, 0.72625   ]),\n",
       " 'split3_train_score': array([0.51      , 0.49875   , 0.74666667, 0.74833333, 0.50166667,\n",
       "        0.6775    , 0.74958333, 0.50125   , 0.74541667, 0.74916667,\n",
       "        0.50125   , 0.61208333, 0.7525    , 0.50125   , 0.70958333,\n",
       "        0.74791667, 0.50125   , 0.70041667, 0.74875   , 0.50125   ,\n",
       "        0.72791667, 0.75083333, 0.49833333, 0.695     , 0.75083333,\n",
       "        0.50166667, 0.6175    , 0.74958333, 0.49833333, 0.62041667,\n",
       "        0.74958333, 0.49875   , 0.73333333, 0.74958333, 0.50125   ,\n",
       "        0.7475    , 0.49875   , 0.50166667, 0.70708333, 0.49875   ,\n",
       "        0.50125   , 0.74375   , 0.74916667, 0.50125   , 0.73708333,\n",
       "        0.75041667, 0.49833333, 0.68583333, 0.74458333, 0.50166667,\n",
       "        0.57666667, 0.75041667, 0.49833333, 0.73416667, 0.74916667,\n",
       "        0.49833333, 0.73375   , 0.75      , 0.49833333, 0.62333333,\n",
       "        0.74916667, 0.49833333, 0.72708333, 0.74916667, 0.50125   ,\n",
       "        0.60875   , 0.50166667, 0.49791667, 0.50166667, 0.75458333,\n",
       "        0.5025    , 0.73375   , 0.82875   , 0.50125   , 0.71      ,\n",
       "        0.8375    , 0.50375   , 0.73      , 0.84541667, 0.51291667,\n",
       "        0.75208333, 0.84416667, 0.50333333, 0.77416667, 0.84708333,\n",
       "        0.5025    , 0.77208333, 0.84333333, 0.50291667, 0.76541667,\n",
       "        0.84916667, 0.50166667, 0.80166667, 0.85041667, 0.50333333,\n",
       "        0.74541667, 0.82791667, 0.50125   , 0.75041667, 0.7575    ,\n",
       "        0.50166667, 0.50375   , 0.8275    , 0.50208333, 0.77166667,\n",
       "        0.85208333, 0.50041667, 0.74541667, 0.78916667, 0.50541667,\n",
       "        0.75583333, 0.8475    , 0.5075    , 0.74833333, 0.82166667,\n",
       "        0.5       , 0.75541667, 0.85541667, 0.49958333, 0.81083333,\n",
       "        0.75375   , 0.51083333, 0.73541667, 0.85125   , 0.50125   ,\n",
       "        0.77291667, 0.83041667, 0.49583333, 0.81416667, 0.84708333,\n",
       "        0.50291667, 0.74125   , 0.50166667, 0.49833333, 0.49833333,\n",
       "        0.75291667, 0.50166667, 0.50541667, 0.755     , 0.50041667,\n",
       "        0.71666667, 0.75541667, 0.50166667, 0.74666667, 0.82833333,\n",
       "        0.5025    , 0.7325    , 0.84458333, 0.50375   , 0.73375   ,\n",
       "        0.84      , 0.50291667, 0.7675    , 0.85583333, 0.4975    ,\n",
       "        0.74583333, 0.855     , 0.49916667, 0.75583333, 0.86166667,\n",
       "        0.49625   , 0.72666667, 0.85625   , 0.4975    , 0.73541667,\n",
       "        0.50166667, 0.49833333, 0.50166667, 0.79083333, 0.50083333,\n",
       "        0.50416667, 0.81375   , 0.50291667, 0.74083333, 0.8325    ,\n",
       "        0.50583333, 0.75625   , 0.825     , 0.5       , 0.73083333,\n",
       "        0.83375   , 0.50416667, 0.72666667, 0.85083333, 0.49791667,\n",
       "        0.76166667, 0.79125   , 0.50541667, 0.75708333, 0.85625   ,\n",
       "        0.50166667, 0.75      , 0.84125   , 0.50708333, 0.72416667,\n",
       "        0.88125   , 0.5075    , 0.765     , 0.5025    , 0.50166667,\n",
       "        0.49875   , 0.74916667, 0.49625   , 0.73958333, 0.73416667,\n",
       "        0.49875   , 0.72708333, 0.78166667, 0.49875   , 0.67416667,\n",
       "        0.76125   , 0.49916667, 0.73625   , 0.75083333, 0.50125   ,\n",
       "        0.75833333, 0.75625   , 0.50125   , 0.70125   , 0.7875    ,\n",
       "        0.50375   , 0.71666667, 0.74833333, 0.49875   , 0.74333333,\n",
       "        0.75125   , 0.49666667, 0.73458333, 0.79458333, 0.50416667,\n",
       "        0.73125   , 0.50166667, 0.49833333, 0.50166667, 0.75875   ,\n",
       "        0.49916667, 0.64458333, 0.79      , 0.50125   , 0.67541667,\n",
       "        0.75166667, 0.50166667, 0.72583333, 0.74958333, 0.49791667,\n",
       "        0.74916667, 0.74583333, 0.49666667, 0.65166667, 0.82      ,\n",
       "        0.5       , 0.70583333, 0.79875   , 0.50291667, 0.67458333,\n",
       "        0.85083333, 0.50333333, 0.72125   , 0.73708333, 0.50125   ,\n",
       "        0.6475    , 0.76833333, 0.50291667, 0.73583333]),\n",
       " 'mean_train_score': array([0.56354167, 0.49916667, 0.6240625 , 0.68166667, 0.5       ,\n",
       "        0.69083333, 0.74177083, 0.49927083, 0.67885417, 0.740625  ,\n",
       "        0.50072917, 0.69572917, 0.74395833, 0.50010417, 0.68635417,\n",
       "        0.74208333, 0.500625  , 0.71354167, 0.74395833, 0.49916667,\n",
       "        0.6971875 , 0.74072917, 0.49989583, 0.65      , 0.74385417,\n",
       "        0.50072917, 0.64989583, 0.74302083, 0.5       , 0.65239583,\n",
       "        0.74229167, 0.50010417, 0.7134375 , 0.565625  , 0.49916667,\n",
       "        0.73864583, 0.560625  , 0.50145833, 0.71885417, 0.67958333,\n",
       "        0.49916667, 0.7215625 , 0.68260417, 0.5       , 0.72114583,\n",
       "        0.7425    , 0.50072917, 0.69479167, 0.73885417, 0.5       ,\n",
       "        0.6578125 , 0.743125  , 0.5       , 0.72625   , 0.7421875 ,\n",
       "        0.49989583, 0.69520833, 0.74416667, 0.499375  , 0.64291667,\n",
       "        0.74208333, 0.49989583, 0.69583333, 0.74239583, 0.50135417,\n",
       "        0.65708333, 0.56520833, 0.49895833, 0.61666667, 0.7821875 ,\n",
       "        0.5009375 , 0.75885417, 0.82885417, 0.50125   , 0.738125  ,\n",
       "        0.84125   , 0.50020833, 0.74166667, 0.821875  , 0.50520833,\n",
       "        0.79333333, 0.80927083, 0.50166667, 0.7734375 , 0.84979167,\n",
       "        0.5009375 , 0.74958333, 0.85791667, 0.515     , 0.77833333,\n",
       "        0.85083333, 0.50395833, 0.796875  , 0.84458333, 0.50125   ,\n",
       "        0.76104167, 0.850625  , 0.50395833, 0.76416667, 0.62791667,\n",
       "        0.5009375 , 0.5015625 , 0.8275    , 0.500625  , 0.77239583,\n",
       "        0.82677083, 0.49916667, 0.7446875 , 0.79322917, 0.50260417,\n",
       "        0.7665625 , 0.84739583, 0.50333333, 0.75979167, 0.85104167,\n",
       "        0.50145833, 0.76229167, 0.83677083, 0.503125  , 0.78885417,\n",
       "        0.83010417, 0.5009375 , 0.7428125 , 0.8521875 , 0.50135417,\n",
       "        0.7671875 , 0.84666667, 0.50135417, 0.75520833, 0.8325    ,\n",
       "        0.50322917, 0.76979167, 0.50145833, 0.49864583, 0.50020833,\n",
       "        0.76697917, 0.5021875 , 0.6796875 , 0.7725    , 0.50166667,\n",
       "        0.73166667, 0.805625  , 0.50052083, 0.735625  , 0.828125  ,\n",
       "        0.5015625 , 0.7475    , 0.85333333, 0.50125   , 0.751875  ,\n",
       "        0.82447917, 0.50052083, 0.75552083, 0.82552083, 0.50177083,\n",
       "        0.74666667, 0.8609375 , 0.5021875 , 0.74208333, 0.85322917,\n",
       "        0.50052083, 0.7490625 , 0.8678125 , 0.50020833, 0.74677083,\n",
       "        0.50291667, 0.49916667, 0.50052083, 0.76979167, 0.50041667,\n",
       "        0.61916667, 0.82239583, 0.50020833, 0.73520833, 0.81020833,\n",
       "        0.50145833, 0.72270833, 0.80729167, 0.50333333, 0.731875  ,\n",
       "        0.8584375 , 0.5021875 , 0.74333333, 0.85197917, 0.49979167,\n",
       "        0.76020833, 0.814375  , 0.50322917, 0.75145833, 0.85979167,\n",
       "        0.50145833, 0.72854167, 0.84645833, 0.50385417, 0.72791667,\n",
       "        0.869375  , 0.504375  , 0.76552083, 0.50489583, 0.5009375 ,\n",
       "        0.500625  , 0.74291667, 0.5       , 0.72114583, 0.76145833,\n",
       "        0.49958333, 0.74416667, 0.78354167, 0.49989583, 0.71864583,\n",
       "        0.75604167, 0.50010417, 0.73458333, 0.754375  , 0.50041667,\n",
       "        0.7371875 , 0.75510417, 0.50125   , 0.71104167, 0.75729167,\n",
       "        0.50135417, 0.72177083, 0.76947917, 0.5009375 , 0.7334375 ,\n",
       "        0.75197917, 0.49927083, 0.68572917, 0.75958333, 0.5021875 ,\n",
       "        0.70364583, 0.50302083, 0.49989583, 0.55947917, 0.68677083,\n",
       "        0.50083333, 0.71072917, 0.756875  , 0.500625  , 0.7190625 ,\n",
       "        0.7628125 , 0.50114583, 0.72927083, 0.7584375 , 0.49895833,\n",
       "        0.73416667, 0.77916667, 0.49927083, 0.7075    , 0.7875    ,\n",
       "        0.4996875 , 0.72489583, 0.76229167, 0.50208333, 0.6771875 ,\n",
       "        0.78270833, 0.50020833, 0.7053125 , 0.74083333, 0.50072917,\n",
       "        0.64510417, 0.7640625 , 0.50083333, 0.72604167]),\n",
       " 'std_train_score': array([0.10219063, 0.00121478, 0.1234854 , 0.1044841 , 0.00147314,\n",
       "        0.02068489, 0.00487139, 0.00115526, 0.04588007, 0.0058519 ,\n",
       "        0.00115526, 0.04830582, 0.00512432, 0.00136216, 0.05900975,\n",
       "        0.00354779, 0.00133398, 0.01600374, 0.00283364, 0.00121478,\n",
       "        0.03279298, 0.00666911, 0.00136216, 0.06481611, 0.00420168,\n",
       "        0.00139366, 0.04350863, 0.00383441, 0.00147314, 0.01998127,\n",
       "        0.00425429, 0.00136216, 0.02837983, 0.10622324, 0.00121478,\n",
       "        0.00705494, 0.10501343, 0.00020833, 0.02048114, 0.10442925,\n",
       "        0.00121478, 0.01442887, 0.10477215, 0.00147314, 0.01231592,\n",
       "        0.00481426, 0.00139366, 0.00793583, 0.00488918, 0.00147314,\n",
       "        0.06060629, 0.00502165, 0.00147314, 0.00971379, 0.00468055,\n",
       "        0.00156943, 0.03372877, 0.00348608, 0.00133398, 0.06593478,\n",
       "        0.0041353 , 0.00156943, 0.04173016, 0.00507218, 0.00018042,\n",
       "        0.04341739, 0.10604167, 0.00157288, 0.11588016, 0.03273337,\n",
       "        0.00225106, 0.01791273, 0.01553551, 0.00088388, 0.02172768,\n",
       "        0.02000651, 0.00264345, 0.01345001, 0.04690832, 0.00461636,\n",
       "        0.02599245, 0.04071664, 0.00241163, 0.00317836, 0.01500145,\n",
       "        0.00418097, 0.01381927, 0.01413907, 0.01208692, 0.02489038,\n",
       "        0.00655506, 0.0058147 , 0.03556769, 0.01304373, 0.00164042,\n",
       "        0.0417234 , 0.01432055, 0.00215502, 0.04251838, 0.126272  ,\n",
       "        0.00103645, 0.00180121, 0.00751734, 0.00198737, 0.02261425,\n",
       "        0.03930536, 0.001932  , 0.01770803, 0.01741142, 0.00418097,\n",
       "        0.03848179, 0.00462458, 0.00256851, 0.01575226, 0.01866532,\n",
       "        0.00250867, 0.01843367, 0.01302833, 0.00250867, 0.02808311,\n",
       "        0.04608018, 0.00846446, 0.01719066, 0.01289102, 0.0016238 ,\n",
       "        0.03244971, 0.01003899, 0.00385698, 0.0343194 , 0.01354647,\n",
       "        0.00177695, 0.03613548, 0.00020833, 0.00034548, 0.0014878 ,\n",
       "        0.01626702, 0.00269024, 0.1007129 , 0.04057315, 0.00153093,\n",
       "        0.01389132, 0.0534443 , 0.00080012, 0.01659751, 0.02696207,\n",
       "        0.00061626, 0.02260969, 0.02110449, 0.00212459, 0.01726403,\n",
       "        0.04537591, 0.00165031, 0.0157464 , 0.02992667, 0.00342802,\n",
       "        0.00344853, 0.00436383, 0.00189515, 0.01149426, 0.00646421,\n",
       "        0.00421199, 0.01616531, 0.01981331, 0.00160024, 0.01507036,\n",
       "        0.00125   , 0.00121478, 0.00122811, 0.02544142, 0.00214492,\n",
       "        0.11711039, 0.00685524, 0.00238448, 0.00955839, 0.04856848,\n",
       "        0.00264345, 0.03050714, 0.04728432, 0.00507752, 0.01750372,\n",
       "        0.02153884, 0.00270633, 0.01761618, 0.00828305, 0.00207289,\n",
       "        0.01201309, 0.04798229, 0.00165031, 0.01494637, 0.01327624,\n",
       "        0.00069096, 0.02380203, 0.02047292, 0.00247163, 0.01790455,\n",
       "        0.01830609, 0.00238448, 0.012574  , 0.00325927, 0.00126295,\n",
       "        0.00119678, 0.00379601, 0.00266797, 0.02373972, 0.02457539,\n",
       "        0.00114109, 0.0143916 , 0.01817522, 0.00159684, 0.02591951,\n",
       "        0.01388351, 0.00119224, 0.00212459, 0.02609495, 0.00065881,\n",
       "        0.01856711, 0.01855541, 0.00117851, 0.02982079, 0.02206662,\n",
       "        0.00139366, 0.05069172, 0.03835753, 0.00136216, 0.00709787,\n",
       "        0.01421675, 0.0018721 , 0.0506566 , 0.02065549, 0.00180121,\n",
       "        0.03300802, 0.00259164, 0.00156943, 0.10404258, 0.10894554,\n",
       "        0.00114109, 0.03828164, 0.02089678, 0.00123252, 0.02735342,\n",
       "        0.01729888, 0.000949  , 0.01616263, 0.01392993, 0.00069096,\n",
       "        0.00891706, 0.03186887, 0.00182515, 0.03383862, 0.02179649,\n",
       "        0.00184877, 0.01379215, 0.02537993, 0.0010623 , 0.04690821,\n",
       "        0.05229997, 0.00189801, 0.03715627, 0.01053681, 0.00142446,\n",
       "        0.02484566, 0.01421675, 0.00233854, 0.01311177])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a266acdf-bf49-4bf0-a5b9-c06aa993e69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'tanh',\n",
       " 'alpha': 0.001,\n",
       " 'hidden_layer_sizes': 101,\n",
       " 'max_iter': 5000,\n",
       " 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1dc7f9a4-3aa2-412c-9674-d5402a4bb88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(X1_test,y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2290d0ba-f439-4f7e-8d59-e41158e8a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.score(X1_train,y1_train)\n",
    "model=grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec4154a4-2b7b-4e76-bda4-cbcf68f51004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve, validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "893d2be4-79e0-49f0-89e9-d92f2170267a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_best = MLPClassifier(activation='tanh', alpha=0.001, hidden_layer_sizes = 101, max_iter=50000, solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a0e45cce-e78b-4bf4-b855-7a540d8cb693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Student\\Desktop\\ML\\Udemy\\first_assignment\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "train_sizes, train_scores, test_scores, fit_times, score_times = learning_curve(\n",
    "        estimator=NN_best,\n",
    "        X=X1_train,\n",
    "        y=y1_train,\n",
    "        train_sizes=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,1 ],\n",
    "        return_times = True \n",
    ")\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "fit_time_mean = np.mean(fit_times, axis=1)\n",
    "fit_time_std = np.std(fit_times, axis=1)\n",
    "score_time_mean = np.mean(score_times, axis=1)\n",
    "score_time_std = np.std(score_times, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28fe35c4-8ca6-4b99-87c7-df579eec7f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_sizes, train_mean,\n",
    "             color='C2', marker='o',\n",
    "             markersize=5, label='train')\n",
    "\n",
    "plt.fill_between(train_sizes,\n",
    "                     train_mean + train_std,\n",
    "                     train_mean - train_std,\n",
    "                     alpha=0.15, color='C2')\n",
    "\n",
    "plt.plot(train_sizes, test_mean,\n",
    "             color='C3', linestyle='--',\n",
    "             marker='s', markersize=5,\n",
    "             label='test')\n",
    "\n",
    "plt.fill_between(train_sizes,\n",
    "                     test_mean + test_std,\n",
    "                     test_mean - test_std,\n",
    "                     alpha=0.15, color='C3')\n",
    "plt.grid()\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('# of training samples')\n",
    "plt.ylabel('Model Scores')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13d9383a-9a2b-4139-a3df-7f271f61d075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "# plt.title(\"Modeling Time: \"+ title)\n",
    "plt.xlabel(\"# 0f training Examples\")\n",
    "plt.ylabel(\"Time (s)\")\n",
    "plt.plot(train_sizes, fit_time_mean, 'o-', color=\"b\", label=\"fit Time (s)\")\n",
    "plt.plot(train_sizes, score_time_mean, 'o-', color=\"r\", label=\"score Time (s)\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944a2c77-188b-4861-9848-633abd961676",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
